{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Deep Learning<br><br>Assignment-1 (ANN)<br><br>Churn Prediction for Bank Customer<br><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset in which there are details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.\n",
    "\n",
    "The features in the given dataset are:\n",
    "- **rownumber:** Row Numbers from 1 to 10000.\n",
    "- **customerid:** A unique ID that identifies each customer.\n",
    "- **surname:** The customer’s surname.\n",
    "- **creditscore:** A credit score is a number between 300–850 that depicts a consumer's creditworthiness.\n",
    "- **geography:** The country from which the customer belongs to.\n",
    "- **Gender:** The customer’s gender: Male, Female\n",
    "- **Age:** The customer’s current age, in years, at the time of being customer.\n",
    "- **tenure:** The number of years for which the customer has been with the bank.\n",
    "- **balance:** Bank balance of the customer.\n",
    "- **numofproducts:** the number of bank products the customer is utilising.\n",
    "- **hascrcard:** The number of credit cards given to the customer by the bank.\n",
    "- **isactivemember:** Binary Flag for indicating if the client is active or not with the bank before the moment where the client exits the company (recorded in the variable \"exited\")\n",
    "- **exited:** Binary flag 1 if the customer closed account with bank and 0 if the customer is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Set it None to display all rows in the dataframe\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement basic steps to see how is your data looks like\n",
    "2. Check for missing values\n",
    "3. Drop the features that not suitable for modelling\n",
    "4. Implement basic visualization steps such as histogram, countplot, heatmap\n",
    "5. Convert categorical variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2      0.000              1          1               1   \n",
       "1       1  83807.860              1          0               1   \n",
       "2       8 159660.800              3          1               0   \n",
       "3       1      0.000              2          0               0   \n",
       "4       2 125510.820              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0       101348.880       1  \n",
       "1       112542.580       0  \n",
       "2       113931.570       1  \n",
       "3        93826.630       0  \n",
       "4        79084.100       0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# Examining data, we can say that RowNumber columns is useless for us. There are 3 object type features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber','CustomerId','Surname'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>650.529</td>\n",
       "      <td>96.653</td>\n",
       "      <td>350.000</td>\n",
       "      <td>584.000</td>\n",
       "      <td>652.000</td>\n",
       "      <td>718.000</td>\n",
       "      <td>850.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>38.922</td>\n",
       "      <td>10.488</td>\n",
       "      <td>18.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>44.000</td>\n",
       "      <td>92.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.013</td>\n",
       "      <td>2.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>76485.889</td>\n",
       "      <td>62397.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97198.540</td>\n",
       "      <td>127644.240</td>\n",
       "      <td>250898.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>1.530</td>\n",
       "      <td>0.582</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>100090.240</td>\n",
       "      <td>57510.493</td>\n",
       "      <td>11.580</td>\n",
       "      <td>51002.110</td>\n",
       "      <td>100193.915</td>\n",
       "      <td>149388.247</td>\n",
       "      <td>199992.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean       std     min       25%        50%  \\\n",
       "CreditScore     10000.000    650.529    96.653 350.000   584.000    652.000   \n",
       "Age             10000.000     38.922    10.488  18.000    32.000     37.000   \n",
       "Tenure          10000.000      5.013     2.892   0.000     3.000      5.000   \n",
       "Balance         10000.000  76485.889 62397.405   0.000     0.000  97198.540   \n",
       "NumOfProducts   10000.000      1.530     0.582   1.000     1.000      1.000   \n",
       "HasCrCard       10000.000      0.706     0.456   0.000     0.000      1.000   \n",
       "IsActiveMember  10000.000      0.515     0.500   0.000     0.000      1.000   \n",
       "EstimatedSalary 10000.000 100090.240 57510.493  11.580 51002.110 100193.915   \n",
       "Exited          10000.000      0.204     0.403   0.000     0.000      0.000   \n",
       "\n",
       "                       75%        max  \n",
       "CreditScore        718.000    850.000  \n",
       "Age                 44.000     92.000  \n",
       "Tenure               7.000     10.000  \n",
       "Balance         127644.240 250898.090  \n",
       "NumOfProducts        2.000      4.000  \n",
       "HasCrCard            1.000      1.000  \n",
       "IsActiveMember       1.000      1.000  \n",
       "EstimatedSalary 149388.247 199992.480  \n",
       "Exited               0.000      1.000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"Exited\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr(), annot=True);\n",
    "#Since there is no big correlation between features, it can be excluded that there is not multicolinearity problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,10))\n",
    "df.corr()['Exited'].sort_values().drop(\"Exited\").plot(kind = \"barh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Geography  Gender\n",
       "0    France  Female\n",
       "1     Spain  Female\n",
       "2    France  Female\n",
       "3    France  Female\n",
       "4     Spain  Female"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_object = df.select_dtypes(include =\"object\").head()\n",
    "df_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography    3\n",
       "Gender       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Geography','Gender']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.800</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.820</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2      0.000              1          1   \n",
       "1          608   41       1  83807.860              1          0   \n",
       "2          502   42       8 159660.800              3          1   \n",
       "3          699   39       1      0.000              2          0   \n",
       "4          850   43       2 125510.820              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1       101348.880       1                  0   \n",
       "1               1       112542.580       0                  0   \n",
       "2               0       113931.570       1                  0   \n",
       "3               0        93826.630       0                  0   \n",
       "4               1        79084.100       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Data\n",
    "- Train | Test Split, Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha9hDt_AoGaE"
   },
   "source": [
    "# Modelling & Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without class_weigth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.001)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.4977 - recall: 0.0133 - val_loss: 0.4500 - val_recall: 0.0000e+00\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.4561 - recall: 0.0738 - val_loss: 0.4170 - val_recall: 0.1713\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4272 - recall: 0.1792 - val_loss: 0.3848 - val_recall: 0.3260\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.4013 - recall: 0.2863 - val_loss: 0.3488 - val_recall: 0.3978\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3815 - recall: 0.3553 - val_loss: 0.3300 - val_recall: 0.4420\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3679 - recall: 0.3838 - val_loss: 0.3381 - val_recall: 0.5635\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3627 - recall: 0.4140 - val_loss: 0.3159 - val_recall: 0.5083\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3569 - recall: 0.4231 - val_loss: 0.3152 - val_recall: 0.5635\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3555 - recall: 0.4225 - val_loss: 0.3083 - val_recall: 0.5083\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3544 - recall: 0.4304 - val_loss: 0.3157 - val_recall: 0.5635\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3514 - recall: 0.4328 - val_loss: 0.3034 - val_recall: 0.4972\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3475 - recall: 0.4437 - val_loss: 0.3099 - val_recall: 0.5746\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3477 - recall: 0.4340 - val_loss: 0.3010 - val_recall: 0.4862\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3468 - recall: 0.4322 - val_loss: 0.2990 - val_recall: 0.5525\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3439 - recall: 0.4443 - val_loss: 0.2997 - val_recall: 0.5138\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3435 - recall: 0.4455 - val_loss: 0.2998 - val_recall: 0.5470\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3417 - recall: 0.4383 - val_loss: 0.3010 - val_recall: 0.6022\n",
      "Epoch 18/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3416 - recall: 0.4546 - val_loss: 0.2980 - val_recall: 0.5138\n",
      "Epoch 19/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3402 - recall: 0.4473 - val_loss: 0.3005 - val_recall: 0.6243\n",
      "Epoch 20/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3386 - recall: 0.4594 - val_loss: 0.2983 - val_recall: 0.5304\n",
      "Epoch 21/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3376 - recall: 0.4570 - val_loss: 0.2931 - val_recall: 0.5414\n",
      "Epoch 22/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3361 - recall: 0.4564 - val_loss: 0.3218 - val_recall: 0.6519\n",
      "Epoch 23/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3382 - recall: 0.4709 - val_loss: 0.2989 - val_recall: 0.5193\n",
      "Epoch 24/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3362 - recall: 0.4631 - val_loss: 0.3020 - val_recall: 0.5083\n",
      "Epoch 25/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3347 - recall: 0.4679 - val_loss: 0.2926 - val_recall: 0.5525\n",
      "Epoch 26/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3366 - recall: 0.4643 - val_loss: 0.2984 - val_recall: 0.5249\n",
      "Epoch 27/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3332 - recall: 0.4613 - val_loss: 0.2984 - val_recall: 0.5801\n",
      "Epoch 28/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3328 - recall: 0.4625 - val_loss: 0.2988 - val_recall: 0.6409\n",
      "Epoch 29/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3337 - recall: 0.4837 - val_loss: 0.3019 - val_recall: 0.5525\n",
      "Epoch 30/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3331 - recall: 0.4613 - val_loss: 0.3035 - val_recall: 0.5801\n",
      "Epoch 31/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3325 - recall: 0.4734 - val_loss: 0.2905 - val_recall: 0.5801\n",
      "Epoch 32/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3312 - recall: 0.4824 - val_loss: 0.3039 - val_recall: 0.5691\n",
      "Epoch 33/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3321 - recall: 0.4746 - val_loss: 0.3025 - val_recall: 0.5470\n",
      "Epoch 34/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3305 - recall: 0.4764 - val_loss: 0.2921 - val_recall: 0.5967\n",
      "Epoch 35/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3313 - recall: 0.4800 - val_loss: 0.2926 - val_recall: 0.5028\n",
      "Epoch 36/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3294 - recall: 0.4788 - val_loss: 0.2904 - val_recall: 0.5635\n",
      "Epoch 37/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3302 - recall: 0.4776 - val_loss: 0.2968 - val_recall: 0.5746\n",
      "Epoch 38/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3292 - recall: 0.4691 - val_loss: 0.2908 - val_recall: 0.5912\n",
      "Epoch 39/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3320 - recall: 0.4867 - val_loss: 0.2938 - val_recall: 0.5580\n",
      "Epoch 40/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3289 - recall: 0.4818 - val_loss: 0.2949 - val_recall: 0.5028\n",
      "Epoch 41/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3289 - recall: 0.4782 - val_loss: 0.2974 - val_recall: 0.6077\n",
      "Epoch 42/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3288 - recall: 0.4800 - val_loss: 0.3078 - val_recall: 0.6077\n",
      "Epoch 43/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3286 - recall: 0.4770 - val_loss: 0.2919 - val_recall: 0.5691\n",
      "Epoch 44/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3285 - recall: 0.4837 - val_loss: 0.2951 - val_recall: 0.5525\n",
      "Epoch 45/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3261 - recall: 0.4867 - val_loss: 0.3000 - val_recall: 0.5414\n",
      "Epoch 46/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3279 - recall: 0.4843 - val_loss: 0.2949 - val_recall: 0.5746\n",
      "Epoch 47/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3259 - recall: 0.4861 - val_loss: 0.2998 - val_recall: 0.5801\n",
      "Epoch 48/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3283 - recall: 0.4933 - val_loss: 0.2968 - val_recall: 0.6077\n",
      "Epoch 49/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3254 - recall: 0.4800 - val_loss: 0.3036 - val_recall: 0.6298\n",
      "Epoch 50/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3271 - recall: 0.4824 - val_loss: 0.2974 - val_recall: 0.5746\n",
      "Epoch 51/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3263 - recall: 0.4824 - val_loss: 0.2897 - val_recall: 0.5801\n",
      "Epoch 52/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3264 - recall: 0.4976 - val_loss: 0.3012 - val_recall: 0.4917\n",
      "Epoch 53/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3244 - recall: 0.4891 - val_loss: 0.3055 - val_recall: 0.4751\n",
      "Epoch 54/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3265 - recall: 0.4855 - val_loss: 0.3013 - val_recall: 0.4751\n",
      "Epoch 55/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3253 - recall: 0.4800 - val_loss: 0.2982 - val_recall: 0.5801\n",
      "Epoch 56/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3260 - recall: 0.4855 - val_loss: 0.2962 - val_recall: 0.5193\n",
      "Epoch 57/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3266 - recall: 0.4752 - val_loss: 0.2939 - val_recall: 0.6133\n",
      "Epoch 58/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3264 - recall: 0.4843 - val_loss: 0.2938 - val_recall: 0.5414\n",
      "Epoch 59/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3250 - recall: 0.4849 - val_loss: 0.3006 - val_recall: 0.4807\n",
      "Epoch 60/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3235 - recall: 0.4855 - val_loss: 0.2929 - val_recall: 0.5691\n",
      "Epoch 61/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3231 - recall: 0.4903 - val_loss: 0.2967 - val_recall: 0.6133\n",
      "Epoch 62/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3238 - recall: 0.4903 - val_loss: 0.2891 - val_recall: 0.5635\n",
      "Epoch 63/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3240 - recall: 0.4849 - val_loss: 0.2983 - val_recall: 0.5746\n",
      "Epoch 64/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3235 - recall: 0.4794 - val_loss: 0.2934 - val_recall: 0.5304\n",
      "Epoch 65/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3233 - recall: 0.4927 - val_loss: 0.2999 - val_recall: 0.5304\n",
      "Epoch 66/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3235 - recall: 0.4915 - val_loss: 0.3135 - val_recall: 0.6409\n",
      "Epoch 67/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3243 - recall: 0.4915 - val_loss: 0.3086 - val_recall: 0.4420\n",
      "Epoch 68/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3225 - recall: 0.4861 - val_loss: 0.2956 - val_recall: 0.5635\n",
      "Epoch 69/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3219 - recall: 0.4903 - val_loss: 0.2933 - val_recall: 0.6022\n",
      "Epoch 70/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3218 - recall: 0.4903 - val_loss: 0.3019 - val_recall: 0.4751\n",
      "Epoch 71/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3229 - recall: 0.4879 - val_loss: 0.2948 - val_recall: 0.5138\n",
      "Epoch 72/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3211 - recall: 0.4831 - val_loss: 0.2954 - val_recall: 0.5746\n",
      "Epoch 73/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3210 - recall: 0.4933 - val_loss: 0.3039 - val_recall: 0.6022\n",
      "Epoch 74/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3206 - recall: 0.4970 - val_loss: 0.3008 - val_recall: 0.5028\n",
      "Epoch 75/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3222 - recall: 0.4976 - val_loss: 0.2968 - val_recall: 0.5746\n",
      "Epoch 76/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3199 - recall: 0.5000 - val_loss: 0.2946 - val_recall: 0.5967\n",
      "Epoch 77/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3197 - recall: 0.4885 - val_loss: 0.2956 - val_recall: 0.5414\n",
      "Epoch 78/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3202 - recall: 0.4903 - val_loss: 0.3000 - val_recall: 0.5635\n",
      "Epoch 79/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3194 - recall: 0.4873 - val_loss: 0.2969 - val_recall: 0.5304\n",
      "Epoch 80/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3199 - recall: 0.4946 - val_loss: 0.2991 - val_recall: 0.6133\n",
      "Epoch 81/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3194 - recall: 0.4958 - val_loss: 0.3015 - val_recall: 0.5967\n",
      "Epoch 82/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3201 - recall: 0.4946 - val_loss: 0.3014 - val_recall: 0.5580\n",
      "Epoch 83/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3190 - recall: 0.4939 - val_loss: 0.2975 - val_recall: 0.5580\n",
      "Epoch 84/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3187 - recall: 0.5000 - val_loss: 0.2998 - val_recall: 0.5138\n",
      "Epoch 85/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3177 - recall: 0.4909 - val_loss: 0.3026 - val_recall: 0.4751\n",
      "Epoch 86/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3201 - recall: 0.4927 - val_loss: 0.2927 - val_recall: 0.6243\n",
      "Epoch 87/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3187 - recall: 0.4964 - val_loss: 0.2991 - val_recall: 0.6077\n",
      "Epoch 88/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3196 - recall: 0.5018 - val_loss: 0.3004 - val_recall: 0.5304\n",
      "Epoch 89/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3177 - recall: 0.4903 - val_loss: 0.3014 - val_recall: 0.5249\n",
      "Epoch 90/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3188 - recall: 0.4897 - val_loss: 0.2950 - val_recall: 0.5691\n",
      "Epoch 91/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3177 - recall: 0.4921 - val_loss: 0.3015 - val_recall: 0.4862\n",
      "Epoch 92/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3183 - recall: 0.4933 - val_loss: 0.2937 - val_recall: 0.5304\n",
      "Epoch 93/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3172 - recall: 0.4939 - val_loss: 0.2984 - val_recall: 0.5304\n",
      "Epoch 94/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3175 - recall: 0.4958 - val_loss: 0.3009 - val_recall: 0.5359\n",
      "Epoch 95/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3178 - recall: 0.4933 - val_loss: 0.3042 - val_recall: 0.6519\n",
      "Epoch 96/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3170 - recall: 0.5079 - val_loss: 0.2989 - val_recall: 0.5193\n",
      "Epoch 97/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3186 - recall: 0.4891 - val_loss: 0.3039 - val_recall: 0.5967\n",
      "Epoch 98/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3177 - recall: 0.4909 - val_loss: 0.3162 - val_recall: 0.6188\n",
      "Epoch 99/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3155 - recall: 0.4952 - val_loss: 0.2979 - val_recall: 0.5414\n",
      "Epoch 100/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3153 - recall: 0.5000 - val_loss: 0.3010 - val_recall: 0.5249\n",
      "Epoch 101/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3143 - recall: 0.4976 - val_loss: 0.2953 - val_recall: 0.5801\n",
      "Epoch 102/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3155 - recall: 0.4958 - val_loss: 0.2956 - val_recall: 0.5856\n",
      "Epoch 103/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3146 - recall: 0.4982 - val_loss: 0.3031 - val_recall: 0.5691\n",
      "Epoch 104/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3156 - recall: 0.5030 - val_loss: 0.2990 - val_recall: 0.5580\n",
      "Epoch 105/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3147 - recall: 0.4946 - val_loss: 0.3018 - val_recall: 0.5580\n",
      "Epoch 106/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3164 - recall: 0.5042 - val_loss: 0.3046 - val_recall: 0.5580\n",
      "Epoch 107/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3139 - recall: 0.5000 - val_loss: 0.3088 - val_recall: 0.6133\n",
      "Epoch 108/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3157 - recall: 0.5024 - val_loss: 0.3036 - val_recall: 0.5414\n",
      "Epoch 109/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3147 - recall: 0.4939 - val_loss: 0.3061 - val_recall: 0.5470\n",
      "Epoch 110/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3144 - recall: 0.4994 - val_loss: 0.2989 - val_recall: 0.5801\n",
      "Epoch 111/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3133 - recall: 0.5103 - val_loss: 0.3073 - val_recall: 0.4641\n",
      "Epoch 112/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3136 - recall: 0.5061 - val_loss: 0.3046 - val_recall: 0.5470\n",
      "Epoch 113/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3136 - recall: 0.4988 - val_loss: 0.3070 - val_recall: 0.6077\n",
      "Epoch 114/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3129 - recall: 0.5036 - val_loss: 0.3046 - val_recall: 0.6077\n",
      "Epoch 115/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3134 - recall: 0.5036 - val_loss: 0.3016 - val_recall: 0.5304\n",
      "Epoch 116/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3132 - recall: 0.4946 - val_loss: 0.3029 - val_recall: 0.5304\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3144 - recall: 0.4939 - val_loss: 0.3009 - val_recall: 0.5580\n",
      "Epoch 118/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3109 - recall: 0.5030 - val_loss: 0.3022 - val_recall: 0.4862\n",
      "Epoch 119/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3146 - recall: 0.5030 - val_loss: 0.3011 - val_recall: 0.5691\n",
      "Epoch 120/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3114 - recall: 0.5097 - val_loss: 0.3236 - val_recall: 0.6519\n",
      "Epoch 121/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3144 - recall: 0.5200 - val_loss: 0.3082 - val_recall: 0.4972\n",
      "Epoch 122/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3120 - recall: 0.5024 - val_loss: 0.3005 - val_recall: 0.5746\n",
      "Epoch 123/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3113 - recall: 0.5061 - val_loss: 0.3062 - val_recall: 0.5912\n",
      "Epoch 124/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3114 - recall: 0.5109 - val_loss: 0.3082 - val_recall: 0.4751\n",
      "Epoch 125/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3113 - recall: 0.4982 - val_loss: 0.3044 - val_recall: 0.5967\n",
      "Epoch 126/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3115 - recall: 0.5091 - val_loss: 0.3029 - val_recall: 0.5635\n",
      "Epoch 127/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3109 - recall: 0.5091 - val_loss: 0.3030 - val_recall: 0.5304\n",
      "Epoch 128/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3110 - recall: 0.5061 - val_loss: 0.3045 - val_recall: 0.5304\n",
      "Epoch 129/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3129 - recall: 0.4994 - val_loss: 0.3080 - val_recall: 0.5138\n",
      "Epoch 130/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3101 - recall: 0.5085 - val_loss: 0.2989 - val_recall: 0.5249\n",
      "Epoch 131/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3121 - recall: 0.5012 - val_loss: 0.3023 - val_recall: 0.5746\n",
      "Epoch 132/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3103 - recall: 0.5145 - val_loss: 0.3077 - val_recall: 0.5304\n",
      "Epoch 133/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3119 - recall: 0.5085 - val_loss: 0.3030 - val_recall: 0.5249\n",
      "Epoch 134/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3112 - recall: 0.5091 - val_loss: 0.3079 - val_recall: 0.6077\n",
      "Epoch 135/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3094 - recall: 0.5024 - val_loss: 0.3079 - val_recall: 0.5525\n",
      "Epoch 136/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3106 - recall: 0.5103 - val_loss: 0.3020 - val_recall: 0.5580\n",
      "Epoch 137/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3109 - recall: 0.5030 - val_loss: 0.3013 - val_recall: 0.5746\n",
      "Epoch 138/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3114 - recall: 0.5176 - val_loss: 0.3016 - val_recall: 0.5525\n",
      "Epoch 139/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3099 - recall: 0.5061 - val_loss: 0.3010 - val_recall: 0.5746\n",
      "Epoch 140/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3083 - recall: 0.5115 - val_loss: 0.2983 - val_recall: 0.5967\n",
      "Epoch 141/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3084 - recall: 0.5121 - val_loss: 0.3059 - val_recall: 0.5304\n",
      "Epoch 142/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3094 - recall: 0.5157 - val_loss: 0.3058 - val_recall: 0.5912\n",
      "Epoch 143/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3098 - recall: 0.4976 - val_loss: 0.3005 - val_recall: 0.5691\n",
      "Epoch 144/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3088 - recall: 0.5127 - val_loss: 0.3108 - val_recall: 0.5304\n",
      "Epoch 145/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3109 - recall: 0.5000 - val_loss: 0.3053 - val_recall: 0.5525\n",
      "Epoch 146/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3081 - recall: 0.5103 - val_loss: 0.3086 - val_recall: 0.6133\n",
      "Epoch 147/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3082 - recall: 0.5121 - val_loss: 0.3010 - val_recall: 0.5525\n",
      "Epoch 148/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3069 - recall: 0.5097 - val_loss: 0.3034 - val_recall: 0.5912\n",
      "Epoch 149/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3081 - recall: 0.5176 - val_loss: 0.3034 - val_recall: 0.5359\n",
      "Epoch 150/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3055 - recall: 0.5103 - val_loss: 0.3010 - val_recall: 0.5691\n",
      "Epoch 151/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3086 - recall: 0.5115 - val_loss: 0.3116 - val_recall: 0.5359\n",
      "Epoch 152/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3098 - recall: 0.5121 - val_loss: 0.3019 - val_recall: 0.5801\n",
      "Epoch 153/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3081 - recall: 0.5139 - val_loss: 0.3039 - val_recall: 0.5525\n",
      "Epoch 154/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3105 - recall: 0.5048 - val_loss: 0.3068 - val_recall: 0.5083\n",
      "Epoch 155/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3093 - recall: 0.5061 - val_loss: 0.3064 - val_recall: 0.5635\n",
      "Epoch 156/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3080 - recall: 0.5097 - val_loss: 0.3142 - val_recall: 0.6133\n",
      "Epoch 157/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3068 - recall: 0.5230 - val_loss: 0.2999 - val_recall: 0.5691\n",
      "Epoch 158/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3073 - recall: 0.5230 - val_loss: 0.3134 - val_recall: 0.5912\n",
      "Epoch 159/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3089 - recall: 0.5073 - val_loss: 0.3065 - val_recall: 0.5138\n",
      "Epoch 160/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3066 - recall: 0.5067 - val_loss: 0.3120 - val_recall: 0.5470\n",
      "Epoch 161/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3071 - recall: 0.5121 - val_loss: 0.3058 - val_recall: 0.5193\n",
      "Epoch 162/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3069 - recall: 0.5127 - val_loss: 0.3032 - val_recall: 0.5801\n",
      "Epoch 163/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3054 - recall: 0.5194 - val_loss: 0.3060 - val_recall: 0.6133\n",
      "Epoch 164/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3064 - recall: 0.5200 - val_loss: 0.3024 - val_recall: 0.5691\n",
      "Epoch 165/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3056 - recall: 0.5188 - val_loss: 0.3083 - val_recall: 0.6133\n",
      "Epoch 166/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3060 - recall: 0.5188 - val_loss: 0.3082 - val_recall: 0.5083\n",
      "Epoch 167/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3049 - recall: 0.5206 - val_loss: 0.3118 - val_recall: 0.4641\n",
      "Epoch 168/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3058 - recall: 0.5133 - val_loss: 0.3093 - val_recall: 0.6133\n",
      "Epoch 169/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3049 - recall: 0.5200 - val_loss: 0.3136 - val_recall: 0.6022\n",
      "Epoch 170/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3066 - recall: 0.5079 - val_loss: 0.3077 - val_recall: 0.5193\n",
      "Epoch 171/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3065 - recall: 0.5200 - val_loss: 0.3040 - val_recall: 0.5746\n",
      "Epoch 172/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3048 - recall: 0.5206 - val_loss: 0.3075 - val_recall: 0.5580\n",
      "Epoch 173/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3050 - recall: 0.5266 - val_loss: 0.3080 - val_recall: 0.5304\n",
      "Epoch 174/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3046 - recall: 0.5133 - val_loss: 0.3066 - val_recall: 0.5967\n",
      "Epoch 175/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3056 - recall: 0.5224 - val_loss: 0.3006 - val_recall: 0.5746\n",
      "Epoch 176/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3050 - recall: 0.5163 - val_loss: 0.3046 - val_recall: 0.5801\n",
      "Epoch 177/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3046 - recall: 0.5206 - val_loss: 0.3013 - val_recall: 0.5470\n",
      "Epoch 178/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3062 - recall: 0.5115 - val_loss: 0.3103 - val_recall: 0.6077\n",
      "Epoch 179/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3039 - recall: 0.5212 - val_loss: 0.3114 - val_recall: 0.5028\n",
      "Epoch 180/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3106 - recall: 0.5151 - val_loss: 0.3055 - val_recall: 0.5635\n",
      "Epoch 181/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3036 - recall: 0.5182 - val_loss: 0.3018 - val_recall: 0.5249\n",
      "Epoch 182/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3047 - recall: 0.5169 - val_loss: 0.3049 - val_recall: 0.5470\n",
      "Epoch 183/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3038 - recall: 0.5212 - val_loss: 0.3030 - val_recall: 0.5801\n",
      "Epoch 184/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3035 - recall: 0.5218 - val_loss: 0.3165 - val_recall: 0.5967\n",
      "Epoch 185/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3030 - recall: 0.5248 - val_loss: 0.3184 - val_recall: 0.6354\n",
      "Epoch 186/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3051 - recall: 0.5248 - val_loss: 0.3072 - val_recall: 0.5746\n",
      "Epoch 187/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3019 - recall: 0.5224 - val_loss: 0.3130 - val_recall: 0.5359\n",
      "Epoch 188/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3036 - recall: 0.5224 - val_loss: 0.3043 - val_recall: 0.6077\n",
      "Epoch 189/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3030 - recall: 0.5151 - val_loss: 0.3020 - val_recall: 0.5801\n",
      "Epoch 190/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3018 - recall: 0.5297 - val_loss: 0.3030 - val_recall: 0.5580\n",
      "Epoch 191/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3045 - recall: 0.5151 - val_loss: 0.3117 - val_recall: 0.5801\n",
      "Epoch 192/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3034 - recall: 0.5200 - val_loss: 0.3157 - val_recall: 0.5028\n",
      "Epoch 193/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3030 - recall: 0.5315 - val_loss: 0.3159 - val_recall: 0.5193\n",
      "Epoch 194/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3021 - recall: 0.5206 - val_loss: 0.3089 - val_recall: 0.5083\n",
      "Epoch 195/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3040 - recall: 0.5218 - val_loss: 0.3087 - val_recall: 0.5414\n",
      "Epoch 196/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3030 - recall: 0.5188 - val_loss: 0.3095 - val_recall: 0.5470\n",
      "Epoch 197/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3043 - recall: 0.5212 - val_loss: 0.3070 - val_recall: 0.6243\n",
      "Epoch 198/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3030 - recall: 0.5206 - val_loss: 0.3086 - val_recall: 0.5359\n",
      "Epoch 199/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3022 - recall: 0.5242 - val_loss: 0.3137 - val_recall: 0.6133\n",
      "Epoch 200/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3019 - recall: 0.5248 - val_loss: 0.3091 - val_recall: 0.5746\n",
      "Epoch 201/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3019 - recall: 0.5260 - val_loss: 0.3121 - val_recall: 0.5580\n",
      "Epoch 202/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3013 - recall: 0.5297 - val_loss: 0.3060 - val_recall: 0.5414\n",
      "Epoch 203/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3009 - recall: 0.5333 - val_loss: 0.3082 - val_recall: 0.5083\n",
      "Epoch 204/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3019 - recall: 0.5169 - val_loss: 0.3094 - val_recall: 0.5470\n",
      "Epoch 205/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3023 - recall: 0.5321 - val_loss: 0.3025 - val_recall: 0.5525\n",
      "Epoch 206/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3003 - recall: 0.5333 - val_loss: 0.3174 - val_recall: 0.6133\n",
      "Epoch 207/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3019 - recall: 0.5182 - val_loss: 0.3061 - val_recall: 0.6077\n",
      "Epoch 208/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3015 - recall: 0.5309 - val_loss: 0.3122 - val_recall: 0.5967\n",
      "Epoch 209/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3005 - recall: 0.5236 - val_loss: 0.3046 - val_recall: 0.5635\n",
      "Epoch 210/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3018 - recall: 0.5278 - val_loss: 0.3263 - val_recall: 0.6022\n",
      "Epoch 211/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3003 - recall: 0.5236 - val_loss: 0.3084 - val_recall: 0.6188\n",
      "Epoch 212/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3002 - recall: 0.5339 - val_loss: 0.3123 - val_recall: 0.5028\n",
      "Epoch 213/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3010 - recall: 0.5327 - val_loss: 0.3071 - val_recall: 0.6133\n",
      "Epoch 214/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3008 - recall: 0.5351 - val_loss: 0.3070 - val_recall: 0.6188\n",
      "Epoch 215/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2989 - recall: 0.5285 - val_loss: 0.3234 - val_recall: 0.5691\n",
      "Epoch 216/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3005 - recall: 0.5303 - val_loss: 0.3120 - val_recall: 0.5856\n",
      "Epoch 217/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3002 - recall: 0.5339 - val_loss: 0.3047 - val_recall: 0.5470\n",
      "Epoch 218/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3006 - recall: 0.5327 - val_loss: 0.3099 - val_recall: 0.5249\n",
      "Epoch 219/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2995 - recall: 0.5212 - val_loss: 0.3075 - val_recall: 0.5470\n",
      "Epoch 220/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2993 - recall: 0.5333 - val_loss: 0.3063 - val_recall: 0.5746\n",
      "Epoch 221/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2984 - recall: 0.5297 - val_loss: 0.3121 - val_recall: 0.5635\n",
      "Epoch 222/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2989 - recall: 0.5266 - val_loss: 0.3220 - val_recall: 0.5856\n",
      "Epoch 223/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2995 - recall: 0.5327 - val_loss: 0.3116 - val_recall: 0.5912\n",
      "Epoch 224/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2999 - recall: 0.5297 - val_loss: 0.3175 - val_recall: 0.5083\n",
      "Epoch 225/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2990 - recall: 0.5381 - val_loss: 0.3084 - val_recall: 0.5359\n",
      "Epoch 226/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2985 - recall: 0.5351 - val_loss: 0.3046 - val_recall: 0.5746\n",
      "Epoch 227/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2997 - recall: 0.5333 - val_loss: 0.3057 - val_recall: 0.5801\n",
      "Epoch 228/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2987 - recall: 0.5333 - val_loss: 0.3148 - val_recall: 0.5691\n",
      "Epoch 229/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2983 - recall: 0.5266 - val_loss: 0.3074 - val_recall: 0.6022\n",
      "Epoch 230/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2982 - recall: 0.5327 - val_loss: 0.3100 - val_recall: 0.5746\n",
      "Epoch 231/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3004 - recall: 0.5430 - val_loss: 0.3060 - val_recall: 0.5801\n",
      "Epoch 232/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2992 - recall: 0.5321 - val_loss: 0.3125 - val_recall: 0.5138\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2985 - recall: 0.5430 - val_loss: 0.3090 - val_recall: 0.5967\n",
      "Epoch 234/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2986 - recall: 0.5424 - val_loss: 0.3107 - val_recall: 0.5801\n",
      "Epoch 235/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2987 - recall: 0.5339 - val_loss: 0.3046 - val_recall: 0.6188\n",
      "Epoch 236/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2971 - recall: 0.5357 - val_loss: 0.3123 - val_recall: 0.5912\n",
      "Epoch 237/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2967 - recall: 0.5351 - val_loss: 0.3114 - val_recall: 0.5028\n",
      "Epoch 238/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2970 - recall: 0.5333 - val_loss: 0.3201 - val_recall: 0.5138\n",
      "Epoch 239/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2966 - recall: 0.5303 - val_loss: 0.3173 - val_recall: 0.4972\n",
      "Epoch 240/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2984 - recall: 0.5406 - val_loss: 0.3127 - val_recall: 0.5912\n",
      "Epoch 241/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2973 - recall: 0.5369 - val_loss: 0.3099 - val_recall: 0.5912\n",
      "Epoch 242/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2978 - recall: 0.5327 - val_loss: 0.3107 - val_recall: 0.5746\n",
      "Epoch 243/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2956 - recall: 0.5484 - val_loss: 0.3128 - val_recall: 0.4917\n",
      "Epoch 244/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2975 - recall: 0.5369 - val_loss: 0.3063 - val_recall: 0.5525\n",
      "Epoch 245/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2964 - recall: 0.5327 - val_loss: 0.3046 - val_recall: 0.5635\n",
      "Epoch 246/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2962 - recall: 0.5363 - val_loss: 0.3078 - val_recall: 0.5635\n",
      "Epoch 247/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2961 - recall: 0.5406 - val_loss: 0.3110 - val_recall: 0.5635\n",
      "Epoch 248/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2966 - recall: 0.5430 - val_loss: 0.3095 - val_recall: 0.5967\n",
      "Epoch 249/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2956 - recall: 0.5369 - val_loss: 0.3142 - val_recall: 0.5414\n",
      "Epoch 250/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2954 - recall: 0.5381 - val_loss: 0.3137 - val_recall: 0.4972\n",
      "Epoch 251/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2955 - recall: 0.5291 - val_loss: 0.3081 - val_recall: 0.5746\n",
      "Epoch 252/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2944 - recall: 0.5424 - val_loss: 0.3253 - val_recall: 0.4751\n",
      "Epoch 253/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2963 - recall: 0.5375 - val_loss: 0.3111 - val_recall: 0.4696\n",
      "Epoch 254/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2947 - recall: 0.5387 - val_loss: 0.3140 - val_recall: 0.4917\n",
      "Epoch 255/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2953 - recall: 0.5303 - val_loss: 0.3169 - val_recall: 0.5414\n",
      "Epoch 256/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2962 - recall: 0.5454 - val_loss: 0.3238 - val_recall: 0.5580\n",
      "Epoch 257/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2935 - recall: 0.5472 - val_loss: 0.3121 - val_recall: 0.5083\n",
      "Epoch 258/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2957 - recall: 0.5381 - val_loss: 0.3195 - val_recall: 0.4972\n",
      "Epoch 259/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2952 - recall: 0.5406 - val_loss: 0.3102 - val_recall: 0.5691\n",
      "Epoch 260/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2939 - recall: 0.5400 - val_loss: 0.3078 - val_recall: 0.5470\n",
      "Epoch 261/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2949 - recall: 0.5285 - val_loss: 0.3182 - val_recall: 0.6298\n",
      "Epoch 262/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2961 - recall: 0.5454 - val_loss: 0.3283 - val_recall: 0.4917\n",
      "Epoch 263/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2937 - recall: 0.5357 - val_loss: 0.3220 - val_recall: 0.5028\n",
      "Epoch 264/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2947 - recall: 0.5363 - val_loss: 0.3205 - val_recall: 0.5691\n",
      "Epoch 265/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2950 - recall: 0.5393 - val_loss: 0.3171 - val_recall: 0.5249\n",
      "Epoch 266/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2918 - recall: 0.5533 - val_loss: 0.3134 - val_recall: 0.5193\n",
      "Epoch 267/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2937 - recall: 0.5387 - val_loss: 0.3222 - val_recall: 0.6022\n",
      "Epoch 268/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2951 - recall: 0.5369 - val_loss: 0.3152 - val_recall: 0.5414\n",
      "Epoch 269/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2933 - recall: 0.5369 - val_loss: 0.3149 - val_recall: 0.5746\n",
      "Epoch 270/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2940 - recall: 0.5496 - val_loss: 0.3258 - val_recall: 0.5525\n",
      "Epoch 271/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2927 - recall: 0.5472 - val_loss: 0.3224 - val_recall: 0.5525\n",
      "Epoch 272/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2943 - recall: 0.5454 - val_loss: 0.3082 - val_recall: 0.5193\n",
      "Epoch 273/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2929 - recall: 0.5418 - val_loss: 0.3123 - val_recall: 0.5580\n",
      "Epoch 274/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2917 - recall: 0.5436 - val_loss: 0.3210 - val_recall: 0.6133\n",
      "Epoch 275/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2931 - recall: 0.5369 - val_loss: 0.3184 - val_recall: 0.5414\n",
      "Epoch 276/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2948 - recall: 0.5466 - val_loss: 0.3187 - val_recall: 0.5359\n",
      "Epoch 277/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2925 - recall: 0.5466 - val_loss: 0.3244 - val_recall: 0.5414\n",
      "Epoch 278/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2927 - recall: 0.5333 - val_loss: 0.3264 - val_recall: 0.6022\n",
      "Epoch 279/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2910 - recall: 0.5369 - val_loss: 0.3196 - val_recall: 0.6022\n",
      "Epoch 280/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2920 - recall: 0.5448 - val_loss: 0.3179 - val_recall: 0.5249\n",
      "Epoch 281/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2912 - recall: 0.5472 - val_loss: 0.3146 - val_recall: 0.5359\n",
      "Epoch 282/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2911 - recall: 0.5400 - val_loss: 0.3218 - val_recall: 0.5580\n",
      "Epoch 283/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2919 - recall: 0.5454 - val_loss: 0.3141 - val_recall: 0.5359\n",
      "Epoch 284/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2910 - recall: 0.5521 - val_loss: 0.3159 - val_recall: 0.5359\n",
      "Epoch 285/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2920 - recall: 0.5321 - val_loss: 0.3185 - val_recall: 0.5304\n",
      "Epoch 286/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2911 - recall: 0.5484 - val_loss: 0.3224 - val_recall: 0.5470\n",
      "Epoch 287/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2919 - recall: 0.5393 - val_loss: 0.3229 - val_recall: 0.5249\n",
      "Epoch 288/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2918 - recall: 0.5430 - val_loss: 0.3208 - val_recall: 0.5635\n",
      "Epoch 289/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2900 - recall: 0.5478 - val_loss: 0.3266 - val_recall: 0.4807\n",
      "Epoch 290/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2924 - recall: 0.5472 - val_loss: 0.3189 - val_recall: 0.5083\n",
      "Epoch 291/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2904 - recall: 0.5533 - val_loss: 0.3257 - val_recall: 0.5138\n",
      "Epoch 292/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2912 - recall: 0.5418 - val_loss: 0.3215 - val_recall: 0.5028\n",
      "Epoch 293/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2914 - recall: 0.5418 - val_loss: 0.3183 - val_recall: 0.5249\n",
      "Epoch 294/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2884 - recall: 0.5466 - val_loss: 0.3194 - val_recall: 0.5746\n",
      "Epoch 295/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2892 - recall: 0.5424 - val_loss: 0.3264 - val_recall: 0.5359\n",
      "Epoch 296/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2903 - recall: 0.5478 - val_loss: 0.3179 - val_recall: 0.5746\n",
      "Epoch 297/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2881 - recall: 0.5527 - val_loss: 0.3337 - val_recall: 0.6022\n",
      "Epoch 298/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2907 - recall: 0.5527 - val_loss: 0.3143 - val_recall: 0.5470\n",
      "Epoch 299/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2894 - recall: 0.5460 - val_loss: 0.3249 - val_recall: 0.5580\n",
      "Epoch 300/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2909 - recall: 0.5539 - val_loss: 0.3225 - val_recall: 0.5083\n",
      "Epoch 301/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2874 - recall: 0.5533 - val_loss: 0.3219 - val_recall: 0.5635\n",
      "Epoch 302/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2874 - recall: 0.5490 - val_loss: 0.3300 - val_recall: 0.5414\n",
      "Epoch 303/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2887 - recall: 0.5478 - val_loss: 0.3289 - val_recall: 0.5138\n",
      "Epoch 304/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2891 - recall: 0.5490 - val_loss: 0.3225 - val_recall: 0.5801\n",
      "Epoch 305/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2904 - recall: 0.5484 - val_loss: 0.3287 - val_recall: 0.5470\n",
      "Epoch 306/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2893 - recall: 0.5539 - val_loss: 0.3205 - val_recall: 0.5856\n",
      "Epoch 307/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2891 - recall: 0.5557 - val_loss: 0.3229 - val_recall: 0.5414\n",
      "Epoch 308/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2882 - recall: 0.5527 - val_loss: 0.3332 - val_recall: 0.4365\n",
      "Epoch 309/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2894 - recall: 0.5563 - val_loss: 0.3274 - val_recall: 0.4972\n",
      "Epoch 310/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2885 - recall: 0.5448 - val_loss: 0.3214 - val_recall: 0.5580\n",
      "Epoch 311/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2881 - recall: 0.5508 - val_loss: 0.3216 - val_recall: 0.5249\n",
      "Epoch 312/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2881 - recall: 0.5466 - val_loss: 0.3245 - val_recall: 0.5414\n",
      "Epoch 313/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2871 - recall: 0.5484 - val_loss: 0.3251 - val_recall: 0.5635\n",
      "Epoch 314/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2880 - recall: 0.5490 - val_loss: 0.3326 - val_recall: 0.4972\n",
      "Epoch 315/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2870 - recall: 0.5551 - val_loss: 0.3339 - val_recall: 0.5414\n",
      "Epoch 316/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2871 - recall: 0.5466 - val_loss: 0.3222 - val_recall: 0.5525\n",
      "Epoch 317/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2861 - recall: 0.5539 - val_loss: 0.3238 - val_recall: 0.5912\n",
      "Epoch 318/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2880 - recall: 0.5496 - val_loss: 0.3225 - val_recall: 0.5801\n",
      "Epoch 319/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2880 - recall: 0.5490 - val_loss: 0.3341 - val_recall: 0.5359\n",
      "Epoch 320/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2871 - recall: 0.5654 - val_loss: 0.3260 - val_recall: 0.5856\n",
      "Epoch 321/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2867 - recall: 0.5545 - val_loss: 0.3329 - val_recall: 0.5967\n",
      "Epoch 322/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2868 - recall: 0.5581 - val_loss: 0.3242 - val_recall: 0.5635\n",
      "Epoch 323/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2856 - recall: 0.5412 - val_loss: 0.3420 - val_recall: 0.6022\n",
      "Epoch 324/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2868 - recall: 0.5472 - val_loss: 0.3270 - val_recall: 0.5912\n",
      "Epoch 325/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2887 - recall: 0.5436 - val_loss: 0.3330 - val_recall: 0.5470\n",
      "Epoch 326/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2871 - recall: 0.5521 - val_loss: 0.3318 - val_recall: 0.5912\n",
      "Epoch 327/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2859 - recall: 0.5484 - val_loss: 0.3390 - val_recall: 0.5470\n",
      "Epoch 328/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2867 - recall: 0.5557 - val_loss: 0.3246 - val_recall: 0.5801\n",
      "Epoch 329/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2866 - recall: 0.5581 - val_loss: 0.3252 - val_recall: 0.5912\n",
      "Epoch 330/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2857 - recall: 0.5563 - val_loss: 0.3223 - val_recall: 0.5470\n",
      "Epoch 331/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2863 - recall: 0.5533 - val_loss: 0.3248 - val_recall: 0.5691\n",
      "Epoch 332/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2846 - recall: 0.5648 - val_loss: 0.3347 - val_recall: 0.5525\n",
      "Epoch 333/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2851 - recall: 0.5502 - val_loss: 0.3242 - val_recall: 0.5193\n",
      "Epoch 334/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2864 - recall: 0.5587 - val_loss: 0.3317 - val_recall: 0.5746\n",
      "Epoch 335/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2862 - recall: 0.5502 - val_loss: 0.3345 - val_recall: 0.5691\n",
      "Epoch 336/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2853 - recall: 0.5478 - val_loss: 0.3364 - val_recall: 0.5691\n",
      "Epoch 337/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2838 - recall: 0.5623 - val_loss: 0.3374 - val_recall: 0.5470\n",
      "Epoch 338/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2839 - recall: 0.5484 - val_loss: 0.3406 - val_recall: 0.4751\n",
      "Epoch 339/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2850 - recall: 0.5490 - val_loss: 0.3358 - val_recall: 0.5912\n",
      "Epoch 340/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2830 - recall: 0.5605 - val_loss: 0.3309 - val_recall: 0.5525\n",
      "Epoch 341/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2844 - recall: 0.5581 - val_loss: 0.3330 - val_recall: 0.4972\n",
      "Epoch 342/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2836 - recall: 0.5527 - val_loss: 0.3337 - val_recall: 0.6022\n",
      "Epoch 343/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2834 - recall: 0.5521 - val_loss: 0.3322 - val_recall: 0.5856\n",
      "Epoch 344/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2832 - recall: 0.5533 - val_loss: 0.3337 - val_recall: 0.5470\n",
      "Epoch 345/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2847 - recall: 0.5563 - val_loss: 0.3413 - val_recall: 0.5249\n",
      "Epoch 346/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2840 - recall: 0.5630 - val_loss: 0.3250 - val_recall: 0.5635\n",
      "Epoch 347/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2847 - recall: 0.5557 - val_loss: 0.3471 - val_recall: 0.6243\n",
      "Epoch 348/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2841 - recall: 0.5593 - val_loss: 0.3404 - val_recall: 0.5359\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2846 - recall: 0.5630 - val_loss: 0.3327 - val_recall: 0.5083\n",
      "Epoch 350/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2810 - recall: 0.5587 - val_loss: 0.3379 - val_recall: 0.5028\n",
      "Epoch 351/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2828 - recall: 0.5605 - val_loss: 0.3257 - val_recall: 0.5635\n",
      "Epoch 352/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2815 - recall: 0.5557 - val_loss: 0.3288 - val_recall: 0.5193\n",
      "Epoch 353/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2819 - recall: 0.5551 - val_loss: 0.3431 - val_recall: 0.5470\n",
      "Epoch 354/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2814 - recall: 0.5508 - val_loss: 0.3294 - val_recall: 0.6077\n",
      "Epoch 355/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2853 - recall: 0.5672 - val_loss: 0.3321 - val_recall: 0.5580\n",
      "Epoch 356/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2806 - recall: 0.5611 - val_loss: 0.3328 - val_recall: 0.5249\n",
      "Epoch 357/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2829 - recall: 0.5593 - val_loss: 0.3373 - val_recall: 0.4972\n",
      "Epoch 358/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2810 - recall: 0.5587 - val_loss: 0.3350 - val_recall: 0.5525\n",
      "Epoch 359/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2819 - recall: 0.5708 - val_loss: 0.3324 - val_recall: 0.5138\n",
      "Epoch 360/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2832 - recall: 0.5539 - val_loss: 0.3393 - val_recall: 0.5470\n",
      "Epoch 361/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2807 - recall: 0.5684 - val_loss: 0.3372 - val_recall: 0.5028\n",
      "Epoch 362/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2809 - recall: 0.5630 - val_loss: 0.3292 - val_recall: 0.5912\n",
      "Epoch 363/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2805 - recall: 0.5630 - val_loss: 0.3358 - val_recall: 0.5138\n",
      "Epoch 364/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2830 - recall: 0.5575 - val_loss: 0.3413 - val_recall: 0.5967\n",
      "Epoch 365/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2792 - recall: 0.5630 - val_loss: 0.3330 - val_recall: 0.5083\n",
      "Epoch 366/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2815 - recall: 0.5545 - val_loss: 0.3350 - val_recall: 0.5083\n",
      "Epoch 367/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2823 - recall: 0.5581 - val_loss: 0.3517 - val_recall: 0.5193\n",
      "Epoch 368/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2814 - recall: 0.5545 - val_loss: 0.3354 - val_recall: 0.5691\n",
      "Epoch 369/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2826 - recall: 0.5611 - val_loss: 0.3468 - val_recall: 0.4751\n",
      "Epoch 370/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2819 - recall: 0.5642 - val_loss: 0.3324 - val_recall: 0.4917\n",
      "Epoch 371/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2803 - recall: 0.5539 - val_loss: 0.3423 - val_recall: 0.5304\n",
      "Epoch 372/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2787 - recall: 0.5684 - val_loss: 0.3309 - val_recall: 0.5912\n",
      "Epoch 373/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2803 - recall: 0.5587 - val_loss: 0.3474 - val_recall: 0.5691\n",
      "Epoch 374/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2818 - recall: 0.5678 - val_loss: 0.3438 - val_recall: 0.5525\n",
      "Epoch 375/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2798 - recall: 0.5642 - val_loss: 0.3512 - val_recall: 0.5801\n",
      "Epoch 376/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2831 - recall: 0.5551 - val_loss: 0.3423 - val_recall: 0.5138\n",
      "Epoch 377/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2802 - recall: 0.5623 - val_loss: 0.3411 - val_recall: 0.5801\n",
      "Epoch 378/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2796 - recall: 0.5617 - val_loss: 0.3474 - val_recall: 0.4972\n",
      "Epoch 379/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2791 - recall: 0.5654 - val_loss: 0.3445 - val_recall: 0.5138\n",
      "Epoch 380/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2772 - recall: 0.5678 - val_loss: 0.3385 - val_recall: 0.5138\n",
      "Epoch 381/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2803 - recall: 0.5587 - val_loss: 0.3457 - val_recall: 0.5470\n",
      "Epoch 382/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2783 - recall: 0.5684 - val_loss: 0.3431 - val_recall: 0.6022\n",
      "Epoch 383/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2810 - recall: 0.5696 - val_loss: 0.3460 - val_recall: 0.4751\n",
      "Epoch 384/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2778 - recall: 0.5630 - val_loss: 0.3443 - val_recall: 0.5193\n",
      "Epoch 385/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2780 - recall: 0.5605 - val_loss: 0.3343 - val_recall: 0.5635\n",
      "Epoch 386/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2807 - recall: 0.5605 - val_loss: 0.3559 - val_recall: 0.5193\n",
      "Epoch 387/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2801 - recall: 0.5575 - val_loss: 0.3467 - val_recall: 0.4917\n",
      "Epoch 388/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2794 - recall: 0.5636 - val_loss: 0.3376 - val_recall: 0.4751\n",
      "Epoch 389/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2783 - recall: 0.5642 - val_loss: 0.3513 - val_recall: 0.5138\n",
      "Epoch 390/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2774 - recall: 0.5763 - val_loss: 0.3357 - val_recall: 0.5083\n",
      "Epoch 391/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2784 - recall: 0.5599 - val_loss: 0.3484 - val_recall: 0.5691\n",
      "Epoch 392/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2800 - recall: 0.5690 - val_loss: 0.3513 - val_recall: 0.5580\n",
      "Epoch 393/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2782 - recall: 0.5745 - val_loss: 0.3410 - val_recall: 0.4862\n",
      "Epoch 394/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2775 - recall: 0.5708 - val_loss: 0.3453 - val_recall: 0.5028\n",
      "Epoch 395/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2786 - recall: 0.5575 - val_loss: 0.3550 - val_recall: 0.4586\n",
      "Epoch 396/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2782 - recall: 0.5648 - val_loss: 0.3481 - val_recall: 0.5912\n",
      "Epoch 397/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2781 - recall: 0.5702 - val_loss: 0.3476 - val_recall: 0.4696\n",
      "Epoch 398/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2792 - recall: 0.5648 - val_loss: 0.3442 - val_recall: 0.4751\n",
      "Epoch 399/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2781 - recall: 0.5611 - val_loss: 0.3536 - val_recall: 0.5138\n",
      "Epoch 400/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2784 - recall: 0.5708 - val_loss: 0.3343 - val_recall: 0.5635\n",
      "Epoch 401/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2784 - recall: 0.5660 - val_loss: 0.3560 - val_recall: 0.5138\n",
      "Epoch 402/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2785 - recall: 0.5714 - val_loss: 0.3574 - val_recall: 0.5304\n",
      "Epoch 403/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2794 - recall: 0.5732 - val_loss: 0.3434 - val_recall: 0.5635\n",
      "Epoch 404/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2749 - recall: 0.5763 - val_loss: 0.3539 - val_recall: 0.5249\n",
      "Epoch 405/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2765 - recall: 0.5732 - val_loss: 0.3425 - val_recall: 0.5691\n",
      "Epoch 406/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2786 - recall: 0.5672 - val_loss: 0.3622 - val_recall: 0.5580\n",
      "Epoch 407/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2776 - recall: 0.5708 - val_loss: 0.3506 - val_recall: 0.5635\n",
      "Epoch 408/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2782 - recall: 0.5617 - val_loss: 0.3696 - val_recall: 0.4033\n",
      "Epoch 409/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2778 - recall: 0.5666 - val_loss: 0.3557 - val_recall: 0.4972\n",
      "Epoch 410/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2761 - recall: 0.5654 - val_loss: 0.3468 - val_recall: 0.5691\n",
      "Epoch 411/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2801 - recall: 0.5678 - val_loss: 0.3453 - val_recall: 0.4972\n",
      "Epoch 412/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2776 - recall: 0.5672 - val_loss: 0.3408 - val_recall: 0.5249\n",
      "Epoch 413/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2758 - recall: 0.5714 - val_loss: 0.3377 - val_recall: 0.5746\n",
      "Epoch 414/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2752 - recall: 0.5690 - val_loss: 0.3513 - val_recall: 0.5249\n",
      "Epoch 415/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2757 - recall: 0.5696 - val_loss: 0.3484 - val_recall: 0.5304\n",
      "Epoch 416/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2768 - recall: 0.5745 - val_loss: 0.3454 - val_recall: 0.5580\n",
      "Epoch 417/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2759 - recall: 0.5678 - val_loss: 0.3432 - val_recall: 0.5635\n",
      "Epoch 418/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2759 - recall: 0.5708 - val_loss: 0.3492 - val_recall: 0.5635\n",
      "Epoch 419/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2777 - recall: 0.5714 - val_loss: 0.3473 - val_recall: 0.4807\n",
      "Epoch 420/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2736 - recall: 0.5787 - val_loss: 0.3539 - val_recall: 0.5359\n",
      "Epoch 421/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2766 - recall: 0.5726 - val_loss: 0.3552 - val_recall: 0.5691\n",
      "Epoch 422/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2777 - recall: 0.5720 - val_loss: 0.3559 - val_recall: 0.4696\n",
      "Epoch 423/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2749 - recall: 0.5648 - val_loss: 0.3536 - val_recall: 0.5525\n",
      "Epoch 424/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2743 - recall: 0.5775 - val_loss: 0.3624 - val_recall: 0.5967\n",
      "Epoch 425/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2761 - recall: 0.5769 - val_loss: 0.3501 - val_recall: 0.4972\n",
      "Epoch 426/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2755 - recall: 0.5696 - val_loss: 0.3496 - val_recall: 0.4862\n",
      "Epoch 427/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2742 - recall: 0.5738 - val_loss: 0.3474 - val_recall: 0.5083\n",
      "Epoch 428/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2745 - recall: 0.5726 - val_loss: 0.3549 - val_recall: 0.5580\n",
      "Epoch 429/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2753 - recall: 0.5775 - val_loss: 0.3514 - val_recall: 0.5801\n",
      "Epoch 430/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2775 - recall: 0.5817 - val_loss: 0.3503 - val_recall: 0.4696\n",
      "Epoch 431/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2773 - recall: 0.5684 - val_loss: 0.3565 - val_recall: 0.5414\n",
      "Epoch 432/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2726 - recall: 0.5787 - val_loss: 0.3550 - val_recall: 0.5856\n",
      "Epoch 433/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2744 - recall: 0.5648 - val_loss: 0.3528 - val_recall: 0.5028\n",
      "Epoch 434/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2741 - recall: 0.5720 - val_loss: 0.3536 - val_recall: 0.5138\n",
      "Epoch 435/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2754 - recall: 0.5678 - val_loss: 0.3625 - val_recall: 0.5525\n",
      "Epoch 436/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2749 - recall: 0.5793 - val_loss: 0.3744 - val_recall: 0.4420\n",
      "Epoch 437/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2733 - recall: 0.5793 - val_loss: 0.3621 - val_recall: 0.5249\n",
      "Epoch 438/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2752 - recall: 0.5738 - val_loss: 0.3601 - val_recall: 0.4586\n",
      "Epoch 439/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2751 - recall: 0.5696 - val_loss: 0.3517 - val_recall: 0.5746\n",
      "Epoch 440/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2770 - recall: 0.5684 - val_loss: 0.3556 - val_recall: 0.5193\n",
      "Epoch 441/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2721 - recall: 0.5726 - val_loss: 0.3683 - val_recall: 0.5193\n",
      "Epoch 442/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2734 - recall: 0.5708 - val_loss: 0.3606 - val_recall: 0.4641\n",
      "Epoch 443/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2712 - recall: 0.5745 - val_loss: 0.3586 - val_recall: 0.5414\n",
      "Epoch 444/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2732 - recall: 0.5738 - val_loss: 0.3544 - val_recall: 0.5470\n",
      "Epoch 445/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2717 - recall: 0.5781 - val_loss: 0.3567 - val_recall: 0.5028\n",
      "Epoch 446/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2731 - recall: 0.5775 - val_loss: 0.3657 - val_recall: 0.5304\n",
      "Epoch 447/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2740 - recall: 0.5678 - val_loss: 0.3582 - val_recall: 0.5525\n",
      "Epoch 448/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2712 - recall: 0.5811 - val_loss: 0.3602 - val_recall: 0.5414\n",
      "Epoch 449/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2716 - recall: 0.5745 - val_loss: 0.3700 - val_recall: 0.4972\n",
      "Epoch 450/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2722 - recall: 0.5781 - val_loss: 0.3561 - val_recall: 0.5801\n",
      "Epoch 451/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2707 - recall: 0.5775 - val_loss: 0.3671 - val_recall: 0.6133\n",
      "Epoch 452/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2737 - recall: 0.5799 - val_loss: 0.3606 - val_recall: 0.5193\n",
      "Epoch 453/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2733 - recall: 0.5690 - val_loss: 0.3622 - val_recall: 0.5249\n",
      "Epoch 454/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2709 - recall: 0.5805 - val_loss: 0.3584 - val_recall: 0.5525\n",
      "Epoch 455/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2739 - recall: 0.5708 - val_loss: 0.3777 - val_recall: 0.6188\n",
      "Epoch 456/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2717 - recall: 0.5878 - val_loss: 0.3524 - val_recall: 0.5525\n",
      "Epoch 457/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2732 - recall: 0.5702 - val_loss: 0.3714 - val_recall: 0.4807\n",
      "Epoch 458/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2711 - recall: 0.5799 - val_loss: 0.3695 - val_recall: 0.5746\n",
      "Epoch 459/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2735 - recall: 0.5720 - val_loss: 0.3718 - val_recall: 0.5912\n",
      "Epoch 460/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2695 - recall: 0.5793 - val_loss: 0.3611 - val_recall: 0.6077\n",
      "Epoch 461/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2730 - recall: 0.5793 - val_loss: 0.3620 - val_recall: 0.5580\n",
      "Epoch 462/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2743 - recall: 0.5823 - val_loss: 0.3620 - val_recall: 0.4696\n",
      "Epoch 463/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2702 - recall: 0.5775 - val_loss: 0.3651 - val_recall: 0.5691\n",
      "Epoch 464/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2707 - recall: 0.5793 - val_loss: 0.3831 - val_recall: 0.5691\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2718 - recall: 0.5732 - val_loss: 0.3688 - val_recall: 0.5138\n",
      "Epoch 466/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2688 - recall: 0.5811 - val_loss: 0.3663 - val_recall: 0.4807\n",
      "Epoch 467/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2726 - recall: 0.5720 - val_loss: 0.3678 - val_recall: 0.4917\n",
      "Epoch 468/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2708 - recall: 0.5769 - val_loss: 0.3729 - val_recall: 0.5691\n",
      "Epoch 469/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2699 - recall: 0.5854 - val_loss: 0.3698 - val_recall: 0.5028\n",
      "Epoch 470/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2688 - recall: 0.5769 - val_loss: 0.3678 - val_recall: 0.4972\n",
      "Epoch 471/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2707 - recall: 0.5860 - val_loss: 0.3628 - val_recall: 0.5028\n",
      "Epoch 472/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2701 - recall: 0.5829 - val_loss: 0.3599 - val_recall: 0.5193\n",
      "Epoch 473/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2697 - recall: 0.5872 - val_loss: 0.3704 - val_recall: 0.5580\n",
      "Epoch 474/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2690 - recall: 0.5914 - val_loss: 0.3630 - val_recall: 0.5746\n",
      "Epoch 475/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2685 - recall: 0.5884 - val_loss: 0.3618 - val_recall: 0.5414\n",
      "Epoch 476/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2703 - recall: 0.5829 - val_loss: 0.3762 - val_recall: 0.4641\n",
      "Epoch 477/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2691 - recall: 0.5854 - val_loss: 0.3626 - val_recall: 0.5028\n",
      "Epoch 478/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2691 - recall: 0.5793 - val_loss: 0.3605 - val_recall: 0.5304\n",
      "Epoch 479/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2695 - recall: 0.5914 - val_loss: 0.3553 - val_recall: 0.5580\n",
      "Epoch 480/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2677 - recall: 0.5847 - val_loss: 0.3828 - val_recall: 0.6077\n",
      "Epoch 481/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2682 - recall: 0.5817 - val_loss: 0.3639 - val_recall: 0.5028\n",
      "Epoch 482/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2682 - recall: 0.5829 - val_loss: 0.3750 - val_recall: 0.4972\n",
      "Epoch 483/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2687 - recall: 0.5829 - val_loss: 0.3627 - val_recall: 0.5028\n",
      "Epoch 484/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2705 - recall: 0.5908 - val_loss: 0.3640 - val_recall: 0.5193\n",
      "Epoch 485/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2679 - recall: 0.5914 - val_loss: 0.3668 - val_recall: 0.5359\n",
      "Epoch 486/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2658 - recall: 0.5950 - val_loss: 0.3618 - val_recall: 0.5746\n",
      "Epoch 487/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2707 - recall: 0.5829 - val_loss: 0.3676 - val_recall: 0.5359\n",
      "Epoch 488/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2701 - recall: 0.5896 - val_loss: 0.3749 - val_recall: 0.5912\n",
      "Epoch 489/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2698 - recall: 0.5872 - val_loss: 0.3655 - val_recall: 0.5801\n",
      "Epoch 490/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2672 - recall: 0.5841 - val_loss: 0.3689 - val_recall: 0.4586\n",
      "Epoch 491/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2667 - recall: 0.5890 - val_loss: 0.3714 - val_recall: 0.5028\n",
      "Epoch 492/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2667 - recall: 0.5890 - val_loss: 0.3747 - val_recall: 0.5304\n",
      "Epoch 493/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2657 - recall: 0.5956 - val_loss: 0.3741 - val_recall: 0.5249\n",
      "Epoch 494/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2657 - recall: 0.5841 - val_loss: 0.3927 - val_recall: 0.5801\n",
      "Epoch 495/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2673 - recall: 0.5872 - val_loss: 0.3746 - val_recall: 0.5746\n",
      "Epoch 496/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2685 - recall: 0.5920 - val_loss: 0.3678 - val_recall: 0.5525\n",
      "Epoch 497/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2700 - recall: 0.5787 - val_loss: 0.3741 - val_recall: 0.5138\n",
      "Epoch 498/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2659 - recall: 0.5878 - val_loss: 0.3720 - val_recall: 0.4972\n",
      "Epoch 499/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.2669 - recall: 0.5847 - val_loss: 0.3704 - val_recall: 0.5525\n",
      "Epoch 500/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.2683 - recall: 0.5854 - val_loss: 0.3832 - val_recall: 0.4475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1638a406850>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, epochs = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 36)                432       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 18)                666       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 9)                 171       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,279\n",
      "Trainable params: 1,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.498   0.013     0.450       0.000\n",
       "1 0.456   0.074     0.417       0.171\n",
       "2 0.427   0.179     0.385       0.326\n",
       "3 0.401   0.286     0.349       0.398\n",
       "4 0.382   0.355     0.330       0.442"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "[[760  36]\n",
      " [127  77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       796\n",
      "           1       0.68      0.38      0.49       204\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.77      0.67      0.69      1000\n",
      "weighted avg       0.82      0.84      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (Receiver Operating Curve) and AUC (Area Under Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "y_pred_proba = model.predict(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.plot(recalls, precisions, label='ANN')\n",
    "plt.xlabel('recalls')\n",
    "plt.ylabel('precisions')\n",
    "plt.title('Precisions_Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6422480824744734"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with class_weigth\n",
    "\n",
    "Investigate how the \"class_weight\" hyper-parameter is used in a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.001)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6278777731268314, 1: 2.454991816693944}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights=class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "class_weights={0:class_weights[0], 1:class_weights[1]}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.6451 - recall: 0.6241 - val_loss: 0.6146 - val_recall: 0.7790\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5970 - recall: 0.6985 - val_loss: 0.5211 - val_recall: 0.7017\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5677 - recall: 0.6992 - val_loss: 0.5693 - val_recall: 0.8177\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5430 - recall: 0.7264 - val_loss: 0.5245 - val_recall: 0.8177\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5239 - recall: 0.7312 - val_loss: 0.4552 - val_recall: 0.7956\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5054 - recall: 0.7379 - val_loss: 0.5590 - val_recall: 0.8619\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4976 - recall: 0.7524 - val_loss: 0.4706 - val_recall: 0.8398\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4910 - recall: 0.7518 - val_loss: 0.4955 - val_recall: 0.8619\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4882 - recall: 0.7548 - val_loss: 0.4503 - val_recall: 0.8232\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4869 - recall: 0.7548 - val_loss: 0.5224 - val_recall: 0.8729\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4830 - recall: 0.7573 - val_loss: 0.4104 - val_recall: 0.7790\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4770 - recall: 0.7615 - val_loss: 0.5488 - val_recall: 0.8785\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4797 - recall: 0.7712 - val_loss: 0.3963 - val_recall: 0.7845\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4784 - recall: 0.7615 - val_loss: 0.4545 - val_recall: 0.8398\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4756 - recall: 0.7530 - val_loss: 0.4341 - val_recall: 0.8177\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4742 - recall: 0.7663 - val_loss: 0.4086 - val_recall: 0.7845\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4719 - recall: 0.7591 - val_loss: 0.4816 - val_recall: 0.8453\n",
      "Epoch 18/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4707 - recall: 0.7766 - val_loss: 0.4263 - val_recall: 0.8232\n",
      "Epoch 19/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4705 - recall: 0.7597 - val_loss: 0.5061 - val_recall: 0.8674\n",
      "Epoch 20/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4691 - recall: 0.7585 - val_loss: 0.4353 - val_recall: 0.8232\n",
      "Epoch 21/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4673 - recall: 0.7676 - val_loss: 0.4485 - val_recall: 0.8453\n",
      "Epoch 22/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4660 - recall: 0.7633 - val_loss: 0.5503 - val_recall: 0.8785\n",
      "Epoch 23/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4678 - recall: 0.7760 - val_loss: 0.4209 - val_recall: 0.8066\n",
      "Epoch 24/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4661 - recall: 0.7706 - val_loss: 0.3952 - val_recall: 0.7348\n",
      "Epoch 25/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4632 - recall: 0.7518 - val_loss: 0.4369 - val_recall: 0.8287\n",
      "Epoch 26/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4635 - recall: 0.7657 - val_loss: 0.4105 - val_recall: 0.7790\n",
      "Epoch 27/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4613 - recall: 0.7663 - val_loss: 0.4639 - val_recall: 0.8398\n",
      "Epoch 28/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4581 - recall: 0.7730 - val_loss: 0.4647 - val_recall: 0.8398\n",
      "Epoch 29/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4585 - recall: 0.7736 - val_loss: 0.4388 - val_recall: 0.8122\n",
      "Epoch 30/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4576 - recall: 0.7772 - val_loss: 0.4581 - val_recall: 0.8122\n",
      "Epoch 31/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4596 - recall: 0.7688 - val_loss: 0.4111 - val_recall: 0.8066\n",
      "Epoch 32/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4555 - recall: 0.7615 - val_loss: 0.4671 - val_recall: 0.8398\n",
      "Epoch 33/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4555 - recall: 0.7754 - val_loss: 0.4331 - val_recall: 0.8122\n",
      "Epoch 34/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4544 - recall: 0.7688 - val_loss: 0.4395 - val_recall: 0.8177\n",
      "Epoch 35/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4559 - recall: 0.7754 - val_loss: 0.3735 - val_recall: 0.7514\n",
      "Epoch 36/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4528 - recall: 0.7676 - val_loss: 0.3839 - val_recall: 0.7680\n",
      "Epoch 37/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4534 - recall: 0.7663 - val_loss: 0.4329 - val_recall: 0.8011\n",
      "Epoch 38/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4511 - recall: 0.7760 - val_loss: 0.4293 - val_recall: 0.8343\n",
      "Epoch 39/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4554 - recall: 0.7785 - val_loss: 0.4505 - val_recall: 0.8232\n",
      "Epoch 40/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4490 - recall: 0.7736 - val_loss: 0.4160 - val_recall: 0.7901\n",
      "Epoch 41/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4511 - recall: 0.7706 - val_loss: 0.4553 - val_recall: 0.8287\n",
      "Epoch 42/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4482 - recall: 0.7772 - val_loss: 0.5035 - val_recall: 0.8564\n",
      "Epoch 43/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4487 - recall: 0.7851 - val_loss: 0.4110 - val_recall: 0.7901\n",
      "Epoch 44/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4479 - recall: 0.7754 - val_loss: 0.4422 - val_recall: 0.8177\n",
      "Epoch 45/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4451 - recall: 0.7797 - val_loss: 0.4297 - val_recall: 0.7956\n",
      "Epoch 46/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4449 - recall: 0.7803 - val_loss: 0.4106 - val_recall: 0.8122\n",
      "Epoch 47/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4426 - recall: 0.7797 - val_loss: 0.4797 - val_recall: 0.8343\n",
      "Epoch 48/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4462 - recall: 0.7748 - val_loss: 0.4571 - val_recall: 0.8453\n",
      "Epoch 49/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4426 - recall: 0.7772 - val_loss: 0.4677 - val_recall: 0.8177\n",
      "Epoch 50/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4438 - recall: 0.7730 - val_loss: 0.4659 - val_recall: 0.8287\n",
      "Epoch 51/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4411 - recall: 0.7778 - val_loss: 0.4329 - val_recall: 0.8177\n",
      "Epoch 52/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4413 - recall: 0.7754 - val_loss: 0.4350 - val_recall: 0.8011\n",
      "Epoch 53/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4395 - recall: 0.7900 - val_loss: 0.3988 - val_recall: 0.7514\n",
      "Epoch 54/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4404 - recall: 0.7809 - val_loss: 0.4030 - val_recall: 0.7680\n",
      "Epoch 55/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4380 - recall: 0.7797 - val_loss: 0.4147 - val_recall: 0.7845\n",
      "Epoch 56/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4373 - recall: 0.7778 - val_loss: 0.4156 - val_recall: 0.7956\n",
      "Epoch 57/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4396 - recall: 0.7766 - val_loss: 0.4932 - val_recall: 0.8453\n",
      "Epoch 58/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4388 - recall: 0.7851 - val_loss: 0.3788 - val_recall: 0.7680\n",
      "Epoch 59/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4375 - recall: 0.7845 - val_loss: 0.3763 - val_recall: 0.7348\n",
      "Epoch 60/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4359 - recall: 0.7851 - val_loss: 0.4146 - val_recall: 0.8122\n",
      "Epoch 61/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4351 - recall: 0.7857 - val_loss: 0.4887 - val_recall: 0.8564\n",
      "Epoch 62/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4354 - recall: 0.7875 - val_loss: 0.4175 - val_recall: 0.8066\n",
      "Epoch 63/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4343 - recall: 0.7809 - val_loss: 0.4508 - val_recall: 0.8232\n",
      "Epoch 64/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4335 - recall: 0.7815 - val_loss: 0.3989 - val_recall: 0.7790\n",
      "Epoch 65/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4318 - recall: 0.7833 - val_loss: 0.4224 - val_recall: 0.7845\n",
      "Epoch 66/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4321 - recall: 0.7778 - val_loss: 0.5283 - val_recall: 0.8729\n",
      "Epoch 67/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4356 - recall: 0.7785 - val_loss: 0.3753 - val_recall: 0.7569\n",
      "Epoch 68/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4298 - recall: 0.7887 - val_loss: 0.4494 - val_recall: 0.8232\n",
      "Epoch 69/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4302 - recall: 0.7851 - val_loss: 0.4247 - val_recall: 0.8066\n",
      "Epoch 70/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4302 - recall: 0.7851 - val_loss: 0.3547 - val_recall: 0.7182\n",
      "Epoch 71/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.4300 - recall: 0.7881 - val_loss: 0.3535 - val_recall: 0.7182\n",
      "Epoch 72/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4282 - recall: 0.7839 - val_loss: 0.4265 - val_recall: 0.8232\n",
      "Epoch 73/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4272 - recall: 0.7839 - val_loss: 0.4341 - val_recall: 0.8177\n",
      "Epoch 74/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4288 - recall: 0.7863 - val_loss: 0.3824 - val_recall: 0.7514\n",
      "Epoch 75/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4258 - recall: 0.7875 - val_loss: 0.4509 - val_recall: 0.8066\n",
      "Epoch 76/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4256 - recall: 0.7827 - val_loss: 0.4233 - val_recall: 0.8177\n",
      "Epoch 77/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4239 - recall: 0.7924 - val_loss: 0.4163 - val_recall: 0.7845\n",
      "Epoch 78/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4249 - recall: 0.7893 - val_loss: 0.4247 - val_recall: 0.7735\n",
      "Epoch 79/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4250 - recall: 0.7912 - val_loss: 0.4207 - val_recall: 0.7845\n",
      "Epoch 80/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4244 - recall: 0.7912 - val_loss: 0.4473 - val_recall: 0.8122\n",
      "Epoch 81/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4225 - recall: 0.7960 - val_loss: 0.4651 - val_recall: 0.8508\n",
      "Epoch 82/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4236 - recall: 0.7863 - val_loss: 0.4360 - val_recall: 0.8066\n",
      "Epoch 83/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4214 - recall: 0.7996 - val_loss: 0.3956 - val_recall: 0.7569\n",
      "Epoch 84/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4212 - recall: 0.7966 - val_loss: 0.3957 - val_recall: 0.7735\n",
      "Epoch 85/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4211 - recall: 0.7881 - val_loss: 0.3563 - val_recall: 0.7072\n",
      "Epoch 86/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4225 - recall: 0.7845 - val_loss: 0.4482 - val_recall: 0.8232\n",
      "Epoch 87/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4209 - recall: 0.7972 - val_loss: 0.4229 - val_recall: 0.7956\n",
      "Epoch 88/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4216 - recall: 0.7912 - val_loss: 0.4486 - val_recall: 0.8177\n",
      "Epoch 89/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4192 - recall: 0.7918 - val_loss: 0.4370 - val_recall: 0.8011\n",
      "Epoch 90/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4193 - recall: 0.7887 - val_loss: 0.4297 - val_recall: 0.8122\n",
      "Epoch 91/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4177 - recall: 0.7906 - val_loss: 0.3939 - val_recall: 0.7514\n",
      "Epoch 92/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4187 - recall: 0.7954 - val_loss: 0.4117 - val_recall: 0.7956\n",
      "Epoch 93/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4164 - recall: 0.7924 - val_loss: 0.4053 - val_recall: 0.8066\n",
      "Epoch 94/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4183 - recall: 0.7906 - val_loss: 0.4487 - val_recall: 0.8177\n",
      "Epoch 95/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4173 - recall: 0.7954 - val_loss: 0.5063 - val_recall: 0.8619\n",
      "Epoch 96/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4160 - recall: 0.7960 - val_loss: 0.3951 - val_recall: 0.7735\n",
      "Epoch 97/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4148 - recall: 0.7881 - val_loss: 0.4504 - val_recall: 0.8122\n",
      "Epoch 98/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4169 - recall: 0.7942 - val_loss: 0.5393 - val_recall: 0.8729\n",
      "Epoch 99/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4130 - recall: 0.7984 - val_loss: 0.4662 - val_recall: 0.8343\n",
      "Epoch 100/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4149 - recall: 0.8008 - val_loss: 0.4160 - val_recall: 0.7514\n",
      "Epoch 101/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4123 - recall: 0.7912 - val_loss: 0.4314 - val_recall: 0.8011\n",
      "Epoch 102/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4115 - recall: 0.8008 - val_loss: 0.4076 - val_recall: 0.7845\n",
      "Epoch 103/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4110 - recall: 0.7972 - val_loss: 0.4858 - val_recall: 0.8508\n",
      "Epoch 104/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4109 - recall: 0.8075 - val_loss: 0.4083 - val_recall: 0.7790\n",
      "Epoch 105/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4103 - recall: 0.7924 - val_loss: 0.4417 - val_recall: 0.7956\n",
      "Epoch 106/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4129 - recall: 0.7930 - val_loss: 0.4545 - val_recall: 0.7956\n",
      "Epoch 107/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4118 - recall: 0.7863 - val_loss: 0.5572 - val_recall: 0.8950\n",
      "Epoch 108/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4123 - recall: 0.8015 - val_loss: 0.4244 - val_recall: 0.7624\n",
      "Epoch 109/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4118 - recall: 0.7912 - val_loss: 0.3925 - val_recall: 0.7790\n",
      "Epoch 110/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.8063 - val_loss: 0.4468 - val_recall: 0.8177\n",
      "Epoch 111/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4073 - recall: 0.8075 - val_loss: 0.3819 - val_recall: 0.7403\n",
      "Epoch 112/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4083 - recall: 0.7978 - val_loss: 0.4300 - val_recall: 0.7790\n",
      "Epoch 113/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.7984 - val_loss: 0.4776 - val_recall: 0.8287\n",
      "Epoch 114/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4058 - recall: 0.8069 - val_loss: 0.4812 - val_recall: 0.8232\n",
      "Epoch 115/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4061 - recall: 0.7936 - val_loss: 0.3828 - val_recall: 0.7403\n",
      "Epoch 116/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4062 - recall: 0.7942 - val_loss: 0.4031 - val_recall: 0.7624\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4074 - recall: 0.8002 - val_loss: 0.4701 - val_recall: 0.8287\n",
      "Epoch 118/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4049 - recall: 0.7984 - val_loss: 0.3597 - val_recall: 0.7403\n",
      "Epoch 119/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4085 - recall: 0.7996 - val_loss: 0.4105 - val_recall: 0.7514\n",
      "Epoch 120/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4026 - recall: 0.8045 - val_loss: 0.5839 - val_recall: 0.8895\n",
      "Epoch 121/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.8021 - val_loss: 0.4488 - val_recall: 0.7956\n",
      "Epoch 122/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4056 - recall: 0.8021 - val_loss: 0.4128 - val_recall: 0.7901\n",
      "Epoch 123/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4039 - recall: 0.8111 - val_loss: 0.4211 - val_recall: 0.7956\n",
      "Epoch 124/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4020 - recall: 0.8027 - val_loss: 0.4167 - val_recall: 0.7624\n",
      "Epoch 125/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4017 - recall: 0.8057 - val_loss: 0.4937 - val_recall: 0.8508\n",
      "Epoch 126/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4003 - recall: 0.8069 - val_loss: 0.4624 - val_recall: 0.8011\n",
      "Epoch 127/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4022 - recall: 0.8081 - val_loss: 0.4044 - val_recall: 0.7348\n",
      "Epoch 128/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4021 - recall: 0.8075 - val_loss: 0.4158 - val_recall: 0.7956\n",
      "Epoch 129/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4053 - recall: 0.8063 - val_loss: 0.3939 - val_recall: 0.7569\n",
      "Epoch 130/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4011 - recall: 0.7960 - val_loss: 0.4561 - val_recall: 0.8232\n",
      "Epoch 131/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4034 - recall: 0.8057 - val_loss: 0.4485 - val_recall: 0.8177\n",
      "Epoch 132/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3976 - recall: 0.8081 - val_loss: 0.4221 - val_recall: 0.7514\n",
      "Epoch 133/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3993 - recall: 0.8117 - val_loss: 0.3885 - val_recall: 0.7182\n",
      "Epoch 134/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4016 - recall: 0.8069 - val_loss: 0.4183 - val_recall: 0.7790\n",
      "Epoch 135/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4000 - recall: 0.7990 - val_loss: 0.4378 - val_recall: 0.8122\n",
      "Epoch 136/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3990 - recall: 0.8069 - val_loss: 0.4922 - val_recall: 0.8619\n",
      "Epoch 137/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3974 - recall: 0.8123 - val_loss: 0.4579 - val_recall: 0.8177\n",
      "Epoch 138/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3985 - recall: 0.8045 - val_loss: 0.4424 - val_recall: 0.7901\n",
      "Epoch 139/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3987 - recall: 0.8069 - val_loss: 0.4527 - val_recall: 0.8011\n",
      "Epoch 140/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3961 - recall: 0.8057 - val_loss: 0.4452 - val_recall: 0.8177\n",
      "Epoch 141/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3955 - recall: 0.8123 - val_loss: 0.4021 - val_recall: 0.7569\n",
      "Epoch 142/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3949 - recall: 0.8027 - val_loss: 0.5173 - val_recall: 0.8343\n",
      "Epoch 143/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3961 - recall: 0.8196 - val_loss: 0.4147 - val_recall: 0.7680\n",
      "Epoch 144/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3963 - recall: 0.8142 - val_loss: 0.4154 - val_recall: 0.7459\n",
      "Epoch 145/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3968 - recall: 0.8021 - val_loss: 0.4198 - val_recall: 0.7680\n",
      "Epoch 146/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3944 - recall: 0.8105 - val_loss: 0.4801 - val_recall: 0.8343\n",
      "Epoch 147/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3942 - recall: 0.8063 - val_loss: 0.4358 - val_recall: 0.7956\n",
      "Epoch 148/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3930 - recall: 0.8142 - val_loss: 0.4381 - val_recall: 0.7790\n",
      "Epoch 149/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3938 - recall: 0.8081 - val_loss: 0.4449 - val_recall: 0.7680\n",
      "Epoch 150/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3912 - recall: 0.8166 - val_loss: 0.4015 - val_recall: 0.7293\n",
      "Epoch 151/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3933 - recall: 0.8075 - val_loss: 0.4254 - val_recall: 0.7790\n",
      "Epoch 152/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3952 - recall: 0.8160 - val_loss: 0.3874 - val_recall: 0.7514\n",
      "Epoch 153/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3943 - recall: 0.8075 - val_loss: 0.4300 - val_recall: 0.7735\n",
      "Epoch 154/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3932 - recall: 0.8166 - val_loss: 0.3622 - val_recall: 0.7072\n",
      "Epoch 155/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3955 - recall: 0.8002 - val_loss: 0.4282 - val_recall: 0.7735\n",
      "Epoch 156/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3929 - recall: 0.8148 - val_loss: 0.5061 - val_recall: 0.8343\n",
      "Epoch 157/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3934 - recall: 0.7996 - val_loss: 0.4414 - val_recall: 0.7956\n",
      "Epoch 158/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8142 - val_loss: 0.4880 - val_recall: 0.8066\n",
      "Epoch 159/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8220 - val_loss: 0.3745 - val_recall: 0.7182\n",
      "Epoch 160/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3887 - recall: 0.8178 - val_loss: 0.4407 - val_recall: 0.8122\n",
      "Epoch 161/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3915 - recall: 0.8123 - val_loss: 0.4078 - val_recall: 0.7514\n",
      "Epoch 162/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3919 - recall: 0.8069 - val_loss: 0.4284 - val_recall: 0.7901\n",
      "Epoch 163/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3875 - recall: 0.8148 - val_loss: 0.4490 - val_recall: 0.8122\n",
      "Epoch 164/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3901 - recall: 0.8117 - val_loss: 0.4406 - val_recall: 0.8066\n",
      "Epoch 165/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3869 - recall: 0.8202 - val_loss: 0.4151 - val_recall: 0.7845\n",
      "Epoch 166/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3899 - recall: 0.8051 - val_loss: 0.4344 - val_recall: 0.7845\n",
      "Epoch 167/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3892 - recall: 0.8148 - val_loss: 0.4151 - val_recall: 0.7182\n",
      "Epoch 168/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3887 - recall: 0.8166 - val_loss: 0.4938 - val_recall: 0.8398\n",
      "Epoch 169/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8196 - val_loss: 0.4328 - val_recall: 0.7845\n",
      "Epoch 170/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3894 - recall: 0.8202 - val_loss: 0.3822 - val_recall: 0.7238\n",
      "Epoch 171/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3880 - recall: 0.8142 - val_loss: 0.4751 - val_recall: 0.8122\n",
      "Epoch 172/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3867 - recall: 0.8136 - val_loss: 0.4135 - val_recall: 0.7624\n",
      "Epoch 173/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3883 - recall: 0.8184 - val_loss: 0.3799 - val_recall: 0.7238\n",
      "Epoch 174/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3875 - recall: 0.8232 - val_loss: 0.4546 - val_recall: 0.8122\n",
      "Epoch 175/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8111 - val_loss: 0.4486 - val_recall: 0.7845\n",
      "Epoch 176/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3852 - recall: 0.8142 - val_loss: 0.4563 - val_recall: 0.8177\n",
      "Epoch 177/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3912 - recall: 0.8136 - val_loss: 0.4059 - val_recall: 0.7735\n",
      "Epoch 178/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3890 - recall: 0.8142 - val_loss: 0.4564 - val_recall: 0.8066\n",
      "Epoch 179/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3867 - recall: 0.8184 - val_loss: 0.4392 - val_recall: 0.7790\n",
      "Epoch 180/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8148 - val_loss: 0.4409 - val_recall: 0.7790\n",
      "Epoch 181/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3853 - recall: 0.8238 - val_loss: 0.4032 - val_recall: 0.7238\n",
      "Epoch 182/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3848 - recall: 0.8238 - val_loss: 0.4816 - val_recall: 0.8232\n",
      "Epoch 183/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3864 - recall: 0.8154 - val_loss: 0.3993 - val_recall: 0.7569\n",
      "Epoch 184/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3847 - recall: 0.8166 - val_loss: 0.4941 - val_recall: 0.8066\n",
      "Epoch 185/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3870 - recall: 0.8051 - val_loss: 0.4669 - val_recall: 0.8122\n",
      "Epoch 186/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3850 - recall: 0.8305 - val_loss: 0.4492 - val_recall: 0.7901\n",
      "Epoch 187/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8208 - val_loss: 0.3987 - val_recall: 0.7459\n",
      "Epoch 188/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8123 - val_loss: 0.4489 - val_recall: 0.8122\n",
      "Epoch 189/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3833 - recall: 0.8202 - val_loss: 0.4239 - val_recall: 0.7845\n",
      "Epoch 190/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3846 - recall: 0.8154 - val_loss: 0.4258 - val_recall: 0.7459\n",
      "Epoch 191/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3864 - recall: 0.8172 - val_loss: 0.4822 - val_recall: 0.8011\n",
      "Epoch 192/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3853 - recall: 0.8196 - val_loss: 0.4035 - val_recall: 0.7293\n",
      "Epoch 193/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8287 - val_loss: 0.4502 - val_recall: 0.7680\n",
      "Epoch 194/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3852 - recall: 0.8196 - val_loss: 0.3740 - val_recall: 0.7127\n",
      "Epoch 195/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3846 - recall: 0.8208 - val_loss: 0.4331 - val_recall: 0.7790\n",
      "Epoch 196/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8196 - val_loss: 0.4995 - val_recall: 0.8177\n",
      "Epoch 197/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3845 - recall: 0.8172 - val_loss: 0.4739 - val_recall: 0.8232\n",
      "Epoch 198/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8148 - val_loss: 0.4235 - val_recall: 0.7735\n",
      "Epoch 199/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3821 - recall: 0.8251 - val_loss: 0.4815 - val_recall: 0.8066\n",
      "Epoch 200/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3827 - recall: 0.8226 - val_loss: 0.5281 - val_recall: 0.8564\n",
      "Epoch 201/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3794 - recall: 0.8196 - val_loss: 0.4782 - val_recall: 0.8177\n",
      "Epoch 202/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3808 - recall: 0.8160 - val_loss: 0.4269 - val_recall: 0.7845\n",
      "Epoch 203/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3815 - recall: 0.8299 - val_loss: 0.4095 - val_recall: 0.7569\n",
      "Epoch 204/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3817 - recall: 0.8287 - val_loss: 0.4173 - val_recall: 0.7624\n",
      "Epoch 205/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3843 - recall: 0.8208 - val_loss: 0.3964 - val_recall: 0.7348\n",
      "Epoch 206/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3767 - recall: 0.8196 - val_loss: 0.4453 - val_recall: 0.7845\n",
      "Epoch 207/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3826 - recall: 0.8263 - val_loss: 0.4419 - val_recall: 0.7680\n",
      "Epoch 208/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3803 - recall: 0.8226 - val_loss: 0.5073 - val_recall: 0.8398\n",
      "Epoch 209/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8257 - val_loss: 0.4839 - val_recall: 0.8122\n",
      "Epoch 210/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8202 - val_loss: 0.5117 - val_recall: 0.8398\n",
      "Epoch 211/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3784 - recall: 0.8178 - val_loss: 0.4769 - val_recall: 0.8011\n",
      "Epoch 212/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3770 - recall: 0.8251 - val_loss: 0.4004 - val_recall: 0.7403\n",
      "Epoch 213/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8178 - val_loss: 0.4100 - val_recall: 0.7680\n",
      "Epoch 214/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3801 - recall: 0.8160 - val_loss: 0.5052 - val_recall: 0.8232\n",
      "Epoch 215/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3791 - recall: 0.8269 - val_loss: 0.5134 - val_recall: 0.8287\n",
      "Epoch 216/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8220 - val_loss: 0.4811 - val_recall: 0.7901\n",
      "Epoch 217/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8202 - val_loss: 0.4182 - val_recall: 0.7459\n",
      "Epoch 218/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3776 - recall: 0.8226 - val_loss: 0.4181 - val_recall: 0.7459\n",
      "Epoch 219/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3787 - recall: 0.8257 - val_loss: 0.3944 - val_recall: 0.7459\n",
      "Epoch 220/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3765 - recall: 0.8232 - val_loss: 0.4590 - val_recall: 0.7790\n",
      "Epoch 221/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3780 - recall: 0.8281 - val_loss: 0.4255 - val_recall: 0.7735\n",
      "Epoch 222/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3787 - recall: 0.8287 - val_loss: 0.4961 - val_recall: 0.8287\n",
      "Epoch 223/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3740 - recall: 0.8251 - val_loss: 0.4946 - val_recall: 0.8011\n",
      "Epoch 224/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3761 - recall: 0.8214 - val_loss: 0.4485 - val_recall: 0.7624\n",
      "Epoch 225/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3750 - recall: 0.8245 - val_loss: 0.4135 - val_recall: 0.7790\n",
      "Epoch 226/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3766 - recall: 0.8263 - val_loss: 0.4758 - val_recall: 0.7956\n",
      "Epoch 227/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3768 - recall: 0.8226 - val_loss: 0.4203 - val_recall: 0.7514\n",
      "Epoch 228/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3747 - recall: 0.8263 - val_loss: 0.4996 - val_recall: 0.8177\n",
      "Epoch 229/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3733 - recall: 0.8360 - val_loss: 0.4690 - val_recall: 0.7790\n",
      "Epoch 230/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3735 - recall: 0.8263 - val_loss: 0.4587 - val_recall: 0.7735\n",
      "Epoch 231/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3763 - recall: 0.8299 - val_loss: 0.4076 - val_recall: 0.7403\n",
      "Epoch 232/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3782 - recall: 0.8251 - val_loss: 0.4741 - val_recall: 0.8066\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3743 - recall: 0.8275 - val_loss: 0.4806 - val_recall: 0.7845\n",
      "Epoch 234/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3774 - recall: 0.8311 - val_loss: 0.4846 - val_recall: 0.8177\n",
      "Epoch 235/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3759 - recall: 0.8220 - val_loss: 0.4344 - val_recall: 0.8122\n",
      "Epoch 236/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3756 - recall: 0.8341 - val_loss: 0.4800 - val_recall: 0.7735\n",
      "Epoch 237/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8263 - val_loss: 0.4197 - val_recall: 0.7238\n",
      "Epoch 238/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3756 - recall: 0.8287 - val_loss: 0.4560 - val_recall: 0.7624\n",
      "Epoch 239/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3736 - recall: 0.8323 - val_loss: 0.4643 - val_recall: 0.7569\n",
      "Epoch 240/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3722 - recall: 0.8311 - val_loss: 0.5003 - val_recall: 0.8122\n",
      "Epoch 241/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3743 - recall: 0.8311 - val_loss: 0.4697 - val_recall: 0.7956\n",
      "Epoch 242/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3748 - recall: 0.8354 - val_loss: 0.4845 - val_recall: 0.7956\n",
      "Epoch 243/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3702 - recall: 0.8275 - val_loss: 0.4065 - val_recall: 0.7238\n",
      "Epoch 244/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3728 - recall: 0.8281 - val_loss: 0.4653 - val_recall: 0.8011\n",
      "Epoch 245/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3708 - recall: 0.8335 - val_loss: 0.4255 - val_recall: 0.7680\n",
      "Epoch 246/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3706 - recall: 0.8305 - val_loss: 0.4608 - val_recall: 0.7956\n",
      "Epoch 247/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3734 - recall: 0.8208 - val_loss: 0.4831 - val_recall: 0.8287\n",
      "Epoch 248/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3729 - recall: 0.8263 - val_loss: 0.4684 - val_recall: 0.7956\n",
      "Epoch 249/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3722 - recall: 0.8329 - val_loss: 0.4734 - val_recall: 0.7790\n",
      "Epoch 250/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3718 - recall: 0.8329 - val_loss: 0.4221 - val_recall: 0.7238\n",
      "Epoch 251/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3707 - recall: 0.8311 - val_loss: 0.4895 - val_recall: 0.7845\n",
      "Epoch 252/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8238 - val_loss: 0.3920 - val_recall: 0.7017\n",
      "Epoch 253/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8293 - val_loss: 0.4082 - val_recall: 0.7459\n",
      "Epoch 254/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3701 - recall: 0.8329 - val_loss: 0.3777 - val_recall: 0.6851\n",
      "Epoch 255/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3711 - recall: 0.8166 - val_loss: 0.4675 - val_recall: 0.7901\n",
      "Epoch 256/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3692 - recall: 0.8347 - val_loss: 0.4379 - val_recall: 0.7182\n",
      "Epoch 257/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3681 - recall: 0.8372 - val_loss: 0.3912 - val_recall: 0.6906\n",
      "Epoch 258/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8293 - val_loss: 0.4172 - val_recall: 0.7569\n",
      "Epoch 259/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8269 - val_loss: 0.4495 - val_recall: 0.7956\n",
      "Epoch 260/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3694 - recall: 0.8275 - val_loss: 0.4325 - val_recall: 0.7624\n",
      "Epoch 261/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8214 - val_loss: 0.4802 - val_recall: 0.7845\n",
      "Epoch 262/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3700 - recall: 0.8323 - val_loss: 0.4079 - val_recall: 0.6851\n",
      "Epoch 263/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3685 - recall: 0.8275 - val_loss: 0.4256 - val_recall: 0.7127\n",
      "Epoch 264/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3680 - recall: 0.8323 - val_loss: 0.5051 - val_recall: 0.8343\n",
      "Epoch 265/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3672 - recall: 0.8208 - val_loss: 0.4435 - val_recall: 0.7735\n",
      "Epoch 266/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3679 - recall: 0.8347 - val_loss: 0.4144 - val_recall: 0.6961\n",
      "Epoch 267/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3669 - recall: 0.8354 - val_loss: 0.5666 - val_recall: 0.8564\n",
      "Epoch 268/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3696 - recall: 0.8305 - val_loss: 0.4480 - val_recall: 0.7901\n",
      "Epoch 269/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3664 - recall: 0.8311 - val_loss: 0.4480 - val_recall: 0.7459\n",
      "Epoch 270/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3703 - recall: 0.8275 - val_loss: 0.4811 - val_recall: 0.7735\n",
      "Epoch 271/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3683 - recall: 0.8341 - val_loss: 0.4388 - val_recall: 0.7348\n",
      "Epoch 272/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3664 - recall: 0.8329 - val_loss: 0.4410 - val_recall: 0.7624\n",
      "Epoch 273/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3697 - recall: 0.8311 - val_loss: 0.4483 - val_recall: 0.7514\n",
      "Epoch 274/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3659 - recall: 0.8251 - val_loss: 0.5036 - val_recall: 0.8177\n",
      "Epoch 275/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3689 - recall: 0.8366 - val_loss: 0.4607 - val_recall: 0.7624\n",
      "Epoch 276/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3666 - recall: 0.8329 - val_loss: 0.4480 - val_recall: 0.7569\n",
      "Epoch 277/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3677 - recall: 0.8317 - val_loss: 0.4315 - val_recall: 0.7238\n",
      "Epoch 278/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3654 - recall: 0.8305 - val_loss: 0.5058 - val_recall: 0.8232\n",
      "Epoch 279/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3651 - recall: 0.8245 - val_loss: 0.4823 - val_recall: 0.8066\n",
      "Epoch 280/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3625 - recall: 0.8366 - val_loss: 0.4307 - val_recall: 0.7127\n",
      "Epoch 281/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3639 - recall: 0.8347 - val_loss: 0.4530 - val_recall: 0.7735\n",
      "Epoch 282/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3656 - recall: 0.8360 - val_loss: 0.4697 - val_recall: 0.7845\n",
      "Epoch 283/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3635 - recall: 0.8317 - val_loss: 0.4606 - val_recall: 0.7680\n",
      "Epoch 284/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3630 - recall: 0.8329 - val_loss: 0.4516 - val_recall: 0.7624\n",
      "Epoch 285/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3640 - recall: 0.8378 - val_loss: 0.4417 - val_recall: 0.7514\n",
      "Epoch 286/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3669 - recall: 0.8354 - val_loss: 0.4473 - val_recall: 0.7459\n",
      "Epoch 287/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3626 - recall: 0.8354 - val_loss: 0.4038 - val_recall: 0.7348\n",
      "Epoch 288/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3647 - recall: 0.8323 - val_loss: 0.5241 - val_recall: 0.8232\n",
      "Epoch 289/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3640 - recall: 0.8378 - val_loss: 0.3761 - val_recall: 0.6575\n",
      "Epoch 290/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3641 - recall: 0.8287 - val_loss: 0.4345 - val_recall: 0.7514\n",
      "Epoch 291/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3627 - recall: 0.8366 - val_loss: 0.3896 - val_recall: 0.7072\n",
      "Epoch 292/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3645 - recall: 0.8311 - val_loss: 0.3980 - val_recall: 0.7182\n",
      "Epoch 293/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3624 - recall: 0.8305 - val_loss: 0.4426 - val_recall: 0.7624\n",
      "Epoch 294/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3604 - recall: 0.8311 - val_loss: 0.5059 - val_recall: 0.8177\n",
      "Epoch 295/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3615 - recall: 0.8414 - val_loss: 0.4209 - val_recall: 0.7403\n",
      "Epoch 296/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3629 - recall: 0.8317 - val_loss: 0.5109 - val_recall: 0.7956\n",
      "Epoch 297/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3615 - recall: 0.8372 - val_loss: 0.5534 - val_recall: 0.8619\n",
      "Epoch 298/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3608 - recall: 0.8360 - val_loss: 0.4712 - val_recall: 0.7735\n",
      "Epoch 299/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3626 - recall: 0.8335 - val_loss: 0.4168 - val_recall: 0.7072\n",
      "Epoch 300/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3613 - recall: 0.8390 - val_loss: 0.3799 - val_recall: 0.7072\n",
      "Epoch 301/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3623 - recall: 0.8347 - val_loss: 0.4722 - val_recall: 0.7735\n",
      "Epoch 302/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3613 - recall: 0.8366 - val_loss: 0.4320 - val_recall: 0.7072\n",
      "Epoch 303/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3607 - recall: 0.8366 - val_loss: 0.4153 - val_recall: 0.7293\n",
      "Epoch 304/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3607 - recall: 0.8232 - val_loss: 0.4794 - val_recall: 0.8232\n",
      "Epoch 305/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3653 - recall: 0.8317 - val_loss: 0.5224 - val_recall: 0.8066\n",
      "Epoch 306/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3631 - recall: 0.8378 - val_loss: 0.4381 - val_recall: 0.7459\n",
      "Epoch 307/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3597 - recall: 0.8372 - val_loss: 0.4099 - val_recall: 0.7348\n",
      "Epoch 308/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3608 - recall: 0.8341 - val_loss: 0.3870 - val_recall: 0.7182\n",
      "Epoch 309/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3593 - recall: 0.8420 - val_loss: 0.3960 - val_recall: 0.6796\n",
      "Epoch 310/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3617 - recall: 0.8341 - val_loss: 0.4805 - val_recall: 0.7901\n",
      "Epoch 311/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3600 - recall: 0.8384 - val_loss: 0.4238 - val_recall: 0.7017\n",
      "Epoch 312/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3597 - recall: 0.8420 - val_loss: 0.4404 - val_recall: 0.7680\n",
      "Epoch 313/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3609 - recall: 0.8305 - val_loss: 0.4348 - val_recall: 0.7403\n",
      "Epoch 314/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3594 - recall: 0.8341 - val_loss: 0.4418 - val_recall: 0.7901\n",
      "Epoch 315/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3563 - recall: 0.8450 - val_loss: 0.4678 - val_recall: 0.7680\n",
      "Epoch 316/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3588 - recall: 0.8450 - val_loss: 0.4337 - val_recall: 0.7459\n",
      "Epoch 317/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3575 - recall: 0.8426 - val_loss: 0.4756 - val_recall: 0.7956\n",
      "Epoch 318/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3590 - recall: 0.8432 - val_loss: 0.4625 - val_recall: 0.8011\n",
      "Epoch 319/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3596 - recall: 0.8396 - val_loss: 0.4747 - val_recall: 0.7790\n",
      "Epoch 320/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3629 - recall: 0.8323 - val_loss: 0.4817 - val_recall: 0.8011\n",
      "Epoch 321/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3591 - recall: 0.8287 - val_loss: 0.5038 - val_recall: 0.8122\n",
      "Epoch 322/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3588 - recall: 0.8420 - val_loss: 0.4583 - val_recall: 0.7624\n",
      "Epoch 323/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8523 - val_loss: 0.4809 - val_recall: 0.7735\n",
      "Epoch 324/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3546 - recall: 0.8432 - val_loss: 0.4653 - val_recall: 0.7403\n",
      "Epoch 325/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3611 - recall: 0.8372 - val_loss: 0.5168 - val_recall: 0.8232\n",
      "Epoch 326/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3578 - recall: 0.8384 - val_loss: 0.5689 - val_recall: 0.8508\n",
      "Epoch 327/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3592 - recall: 0.8511 - val_loss: 0.4709 - val_recall: 0.7790\n",
      "Epoch 328/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3561 - recall: 0.8354 - val_loss: 0.5145 - val_recall: 0.8122\n",
      "Epoch 329/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3559 - recall: 0.8335 - val_loss: 0.5106 - val_recall: 0.8177\n",
      "Epoch 330/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3567 - recall: 0.8414 - val_loss: 0.4274 - val_recall: 0.7403\n",
      "Epoch 331/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8360 - val_loss: 0.4660 - val_recall: 0.8122\n",
      "Epoch 332/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3571 - recall: 0.8517 - val_loss: 0.4561 - val_recall: 0.7680\n",
      "Epoch 333/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8408 - val_loss: 0.4264 - val_recall: 0.7569\n",
      "Epoch 334/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3583 - recall: 0.8305 - val_loss: 0.4690 - val_recall: 0.7569\n",
      "Epoch 335/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3555 - recall: 0.8426 - val_loss: 0.4981 - val_recall: 0.8011\n",
      "Epoch 336/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3532 - recall: 0.8378 - val_loss: 0.5185 - val_recall: 0.8122\n",
      "Epoch 337/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3574 - recall: 0.8481 - val_loss: 0.4215 - val_recall: 0.6961\n",
      "Epoch 338/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3580 - recall: 0.8378 - val_loss: 0.4301 - val_recall: 0.7403\n",
      "Epoch 339/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3570 - recall: 0.8462 - val_loss: 0.4921 - val_recall: 0.7845\n",
      "Epoch 340/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3524 - recall: 0.8420 - val_loss: 0.4425 - val_recall: 0.7735\n",
      "Epoch 341/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8396 - val_loss: 0.4576 - val_recall: 0.7569\n",
      "Epoch 342/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3534 - recall: 0.8438 - val_loss: 0.5160 - val_recall: 0.8011\n",
      "Epoch 343/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3544 - recall: 0.8481 - val_loss: 0.4563 - val_recall: 0.7569\n",
      "Epoch 344/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3524 - recall: 0.8378 - val_loss: 0.4878 - val_recall: 0.7956\n",
      "Epoch 345/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3540 - recall: 0.8426 - val_loss: 0.4583 - val_recall: 0.7569\n",
      "Epoch 346/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3553 - recall: 0.8481 - val_loss: 0.4938 - val_recall: 0.7901\n",
      "Epoch 347/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8390 - val_loss: 0.5845 - val_recall: 0.8398\n",
      "Epoch 348/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3548 - recall: 0.8426 - val_loss: 0.5014 - val_recall: 0.7514\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3546 - recall: 0.8456 - val_loss: 0.4245 - val_recall: 0.7790\n",
      "Epoch 350/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3523 - recall: 0.8469 - val_loss: 0.4259 - val_recall: 0.6851\n",
      "Epoch 351/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3522 - recall: 0.8456 - val_loss: 0.4605 - val_recall: 0.7680\n",
      "Epoch 352/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3530 - recall: 0.8450 - val_loss: 0.4584 - val_recall: 0.7790\n",
      "Epoch 353/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3519 - recall: 0.8444 - val_loss: 0.4792 - val_recall: 0.7459\n",
      "Epoch 354/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3532 - recall: 0.8384 - val_loss: 0.4842 - val_recall: 0.7956\n",
      "Epoch 355/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3572 - recall: 0.8456 - val_loss: 0.4502 - val_recall: 0.7459\n",
      "Epoch 356/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3515 - recall: 0.8444 - val_loss: 0.4163 - val_recall: 0.7017\n",
      "Epoch 357/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3518 - recall: 0.8444 - val_loss: 0.4181 - val_recall: 0.7348\n",
      "Epoch 358/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3526 - recall: 0.8378 - val_loss: 0.5125 - val_recall: 0.8343\n",
      "Epoch 359/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3516 - recall: 0.8432 - val_loss: 0.5161 - val_recall: 0.8066\n",
      "Epoch 360/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8366 - val_loss: 0.5019 - val_recall: 0.7901\n",
      "Epoch 361/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3506 - recall: 0.8475 - val_loss: 0.4202 - val_recall: 0.7238\n",
      "Epoch 362/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3514 - recall: 0.8366 - val_loss: 0.4834 - val_recall: 0.7845\n",
      "Epoch 363/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3492 - recall: 0.8390 - val_loss: 0.5194 - val_recall: 0.7901\n",
      "Epoch 364/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3522 - recall: 0.8481 - val_loss: 0.5087 - val_recall: 0.8287\n",
      "Epoch 365/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3458 - recall: 0.8541 - val_loss: 0.4306 - val_recall: 0.7514\n",
      "Epoch 366/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3495 - recall: 0.8487 - val_loss: 0.4552 - val_recall: 0.7238\n",
      "Epoch 367/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3528 - recall: 0.8420 - val_loss: 0.4432 - val_recall: 0.7182\n",
      "Epoch 368/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3507 - recall: 0.8450 - val_loss: 0.5006 - val_recall: 0.7901\n",
      "Epoch 369/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3536 - recall: 0.8535 - val_loss: 0.4490 - val_recall: 0.7182\n",
      "Epoch 370/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3537 - recall: 0.8420 - val_loss: 0.3985 - val_recall: 0.6685\n",
      "Epoch 371/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3512 - recall: 0.8396 - val_loss: 0.5008 - val_recall: 0.7735\n",
      "Epoch 372/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3515 - recall: 0.8432 - val_loss: 0.5630 - val_recall: 0.8398\n",
      "Epoch 373/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3473 - recall: 0.8432 - val_loss: 0.5213 - val_recall: 0.7901\n",
      "Epoch 374/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3465 - recall: 0.8481 - val_loss: 0.5047 - val_recall: 0.7956\n",
      "Epoch 375/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3495 - recall: 0.8493 - val_loss: 0.4560 - val_recall: 0.7348\n",
      "Epoch 376/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3494 - recall: 0.8469 - val_loss: 0.4925 - val_recall: 0.7569\n",
      "Epoch 377/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3476 - recall: 0.8469 - val_loss: 0.5474 - val_recall: 0.8343\n",
      "Epoch 378/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3471 - recall: 0.8529 - val_loss: 0.4235 - val_recall: 0.6961\n",
      "Epoch 379/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3466 - recall: 0.8517 - val_loss: 0.4560 - val_recall: 0.7624\n",
      "Epoch 380/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8511 - val_loss: 0.4175 - val_recall: 0.6906\n",
      "Epoch 381/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3496 - recall: 0.8462 - val_loss: 0.4598 - val_recall: 0.7624\n",
      "Epoch 382/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3455 - recall: 0.8511 - val_loss: 0.4978 - val_recall: 0.7735\n",
      "Epoch 383/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3477 - recall: 0.8469 - val_loss: 0.4550 - val_recall: 0.7514\n",
      "Epoch 384/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3488 - recall: 0.8481 - val_loss: 0.4592 - val_recall: 0.7514\n",
      "Epoch 385/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3447 - recall: 0.8499 - val_loss: 0.4770 - val_recall: 0.7624\n",
      "Epoch 386/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8475 - val_loss: 0.4935 - val_recall: 0.7680\n",
      "Epoch 387/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3475 - recall: 0.8547 - val_loss: 0.4641 - val_recall: 0.7238\n",
      "Epoch 388/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3444 - recall: 0.8559 - val_loss: 0.4371 - val_recall: 0.7238\n",
      "Epoch 389/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3442 - recall: 0.8511 - val_loss: 0.5066 - val_recall: 0.7845\n",
      "Epoch 390/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8559 - val_loss: 0.4197 - val_recall: 0.7459\n",
      "Epoch 391/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3500 - recall: 0.8438 - val_loss: 0.4777 - val_recall: 0.7680\n",
      "Epoch 392/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3485 - recall: 0.8426 - val_loss: 0.5093 - val_recall: 0.7680\n",
      "Epoch 393/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3468 - recall: 0.8529 - val_loss: 0.4389 - val_recall: 0.7348\n",
      "Epoch 394/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8535 - val_loss: 0.4440 - val_recall: 0.7514\n",
      "Epoch 395/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3445 - recall: 0.8487 - val_loss: 0.4395 - val_recall: 0.7293\n",
      "Epoch 396/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3498 - recall: 0.8481 - val_loss: 0.4636 - val_recall: 0.7569\n",
      "Epoch 397/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3413 - recall: 0.8547 - val_loss: 0.4366 - val_recall: 0.7182\n",
      "Epoch 398/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3461 - recall: 0.8499 - val_loss: 0.4472 - val_recall: 0.7569\n",
      "Epoch 399/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3461 - recall: 0.8438 - val_loss: 0.5078 - val_recall: 0.8066\n",
      "Epoch 400/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8481 - val_loss: 0.4949 - val_recall: 0.7845\n",
      "Epoch 401/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3430 - recall: 0.8523 - val_loss: 0.4853 - val_recall: 0.7624\n",
      "Epoch 402/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3451 - recall: 0.8547 - val_loss: 0.4987 - val_recall: 0.7403\n",
      "Epoch 403/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8505 - val_loss: 0.5185 - val_recall: 0.8011\n",
      "Epoch 404/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3425 - recall: 0.8487 - val_loss: 0.4468 - val_recall: 0.7072\n",
      "Epoch 405/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3429 - recall: 0.8541 - val_loss: 0.5348 - val_recall: 0.8287\n",
      "Epoch 406/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3457 - recall: 0.8475 - val_loss: 0.5403 - val_recall: 0.7735\n",
      "Epoch 407/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3418 - recall: 0.8505 - val_loss: 0.4938 - val_recall: 0.7735\n",
      "Epoch 408/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3418 - recall: 0.8529 - val_loss: 0.4063 - val_recall: 0.6133\n",
      "Epoch 409/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3438 - recall: 0.8571 - val_loss: 0.4366 - val_recall: 0.7293\n",
      "Epoch 410/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3412 - recall: 0.8529 - val_loss: 0.4766 - val_recall: 0.7238\n",
      "Epoch 411/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3464 - recall: 0.8481 - val_loss: 0.4400 - val_recall: 0.7403\n",
      "Epoch 412/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3450 - recall: 0.8481 - val_loss: 0.4929 - val_recall: 0.7845\n",
      "Epoch 413/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3411 - recall: 0.8608 - val_loss: 0.4562 - val_recall: 0.7845\n",
      "Epoch 414/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3443 - recall: 0.8523 - val_loss: 0.4869 - val_recall: 0.7680\n",
      "Epoch 415/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3423 - recall: 0.8596 - val_loss: 0.4287 - val_recall: 0.7182\n",
      "Epoch 416/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3412 - recall: 0.8559 - val_loss: 0.4675 - val_recall: 0.7459\n",
      "Epoch 417/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3420 - recall: 0.8529 - val_loss: 0.4658 - val_recall: 0.7845\n",
      "Epoch 418/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3437 - recall: 0.8529 - val_loss: 0.5793 - val_recall: 0.8066\n",
      "Epoch 419/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3432 - recall: 0.8517 - val_loss: 0.4299 - val_recall: 0.7127\n",
      "Epoch 420/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3381 - recall: 0.8487 - val_loss: 0.4984 - val_recall: 0.7901\n",
      "Epoch 421/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3413 - recall: 0.8577 - val_loss: 0.4985 - val_recall: 0.7956\n",
      "Epoch 422/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3426 - recall: 0.8475 - val_loss: 0.4163 - val_recall: 0.7072\n",
      "Epoch 423/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3421 - recall: 0.8517 - val_loss: 0.5062 - val_recall: 0.7680\n",
      "Epoch 424/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8529 - val_loss: 0.5780 - val_recall: 0.8287\n",
      "Epoch 425/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3414 - recall: 0.8590 - val_loss: 0.5330 - val_recall: 0.7680\n",
      "Epoch 426/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3435 - recall: 0.8571 - val_loss: 0.4286 - val_recall: 0.7017\n",
      "Epoch 427/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3416 - recall: 0.8517 - val_loss: 0.4277 - val_recall: 0.6906\n",
      "Epoch 428/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3428 - recall: 0.8559 - val_loss: 0.4635 - val_recall: 0.7624\n",
      "Epoch 429/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3406 - recall: 0.8535 - val_loss: 0.5291 - val_recall: 0.8011\n",
      "Epoch 430/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3445 - recall: 0.8571 - val_loss: 0.4261 - val_recall: 0.7348\n",
      "Epoch 431/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3406 - recall: 0.8450 - val_loss: 0.4449 - val_recall: 0.7348\n",
      "Epoch 432/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3392 - recall: 0.8668 - val_loss: 0.5493 - val_recall: 0.7680\n",
      "Epoch 433/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3385 - recall: 0.8511 - val_loss: 0.4338 - val_recall: 0.6961\n",
      "Epoch 434/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3395 - recall: 0.8571 - val_loss: 0.4276 - val_recall: 0.7238\n",
      "Epoch 435/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3411 - recall: 0.8584 - val_loss: 0.5272 - val_recall: 0.7845\n",
      "Epoch 436/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3392 - recall: 0.8541 - val_loss: 0.4096 - val_recall: 0.6796\n",
      "Epoch 437/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3399 - recall: 0.8565 - val_loss: 0.4809 - val_recall: 0.7569\n",
      "Epoch 438/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3405 - recall: 0.8529 - val_loss: 0.4201 - val_recall: 0.6851\n",
      "Epoch 439/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3408 - recall: 0.8559 - val_loss: 0.4715 - val_recall: 0.7680\n",
      "Epoch 440/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8584 - val_loss: 0.4535 - val_recall: 0.7348\n",
      "Epoch 441/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3375 - recall: 0.8450 - val_loss: 0.4936 - val_recall: 0.7459\n",
      "Epoch 442/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3386 - recall: 0.8584 - val_loss: 0.4777 - val_recall: 0.7624\n",
      "Epoch 443/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3375 - recall: 0.8571 - val_loss: 0.4934 - val_recall: 0.7238\n",
      "Epoch 444/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3374 - recall: 0.8541 - val_loss: 0.5112 - val_recall: 0.7845\n",
      "Epoch 445/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3371 - recall: 0.8584 - val_loss: 0.4273 - val_recall: 0.7127\n",
      "Epoch 446/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3397 - recall: 0.8553 - val_loss: 0.4779 - val_recall: 0.7569\n",
      "Epoch 447/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3373 - recall: 0.8565 - val_loss: 0.4946 - val_recall: 0.7735\n",
      "Epoch 448/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3370 - recall: 0.8596 - val_loss: 0.4667 - val_recall: 0.7293\n",
      "Epoch 449/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3371 - recall: 0.8614 - val_loss: 0.5257 - val_recall: 0.7845\n",
      "Epoch 450/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3368 - recall: 0.8565 - val_loss: 0.5075 - val_recall: 0.7901\n",
      "Epoch 451/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8529 - val_loss: 0.5900 - val_recall: 0.8232\n",
      "Epoch 452/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8614 - val_loss: 0.4746 - val_recall: 0.7293\n",
      "Epoch 453/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3386 - recall: 0.8541 - val_loss: 0.5034 - val_recall: 0.7569\n",
      "Epoch 454/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3365 - recall: 0.8602 - val_loss: 0.4760 - val_recall: 0.7624\n",
      "Epoch 455/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3364 - recall: 0.8608 - val_loss: 0.5737 - val_recall: 0.8398\n",
      "Epoch 456/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8565 - val_loss: 0.4841 - val_recall: 0.7680\n",
      "Epoch 457/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3397 - recall: 0.8529 - val_loss: 0.4756 - val_recall: 0.7403\n",
      "Epoch 458/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8571 - val_loss: 0.5612 - val_recall: 0.8177\n",
      "Epoch 459/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3374 - recall: 0.8596 - val_loss: 0.5484 - val_recall: 0.8177\n",
      "Epoch 460/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3328 - recall: 0.8577 - val_loss: 0.5978 - val_recall: 0.8674\n",
      "Epoch 461/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3384 - recall: 0.8493 - val_loss: 0.5133 - val_recall: 0.7845\n",
      "Epoch 462/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3370 - recall: 0.8614 - val_loss: 0.4746 - val_recall: 0.7514\n",
      "Epoch 463/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3363 - recall: 0.8535 - val_loss: 0.4742 - val_recall: 0.7403\n",
      "Epoch 464/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3349 - recall: 0.8602 - val_loss: 0.5636 - val_recall: 0.8066\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3357 - recall: 0.8626 - val_loss: 0.4827 - val_recall: 0.7514\n",
      "Epoch 466/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8656 - val_loss: 0.4843 - val_recall: 0.7348\n",
      "Epoch 467/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3390 - recall: 0.8608 - val_loss: 0.4798 - val_recall: 0.7514\n",
      "Epoch 468/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3376 - recall: 0.8620 - val_loss: 0.4975 - val_recall: 0.7514\n",
      "Epoch 469/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3323 - recall: 0.8553 - val_loss: 0.4571 - val_recall: 0.7072\n",
      "Epoch 470/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8674 - val_loss: 0.4560 - val_recall: 0.7293\n",
      "Epoch 471/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3350 - recall: 0.8553 - val_loss: 0.4457 - val_recall: 0.6961\n",
      "Epoch 472/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8571 - val_loss: 0.4755 - val_recall: 0.7735\n",
      "Epoch 473/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3324 - recall: 0.8656 - val_loss: 0.5092 - val_recall: 0.7735\n",
      "Epoch 474/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3366 - recall: 0.8650 - val_loss: 0.5127 - val_recall: 0.7735\n",
      "Epoch 475/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3328 - recall: 0.8644 - val_loss: 0.4716 - val_recall: 0.7293\n",
      "Epoch 476/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8608 - val_loss: 0.4565 - val_recall: 0.7127\n",
      "Epoch 477/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3346 - recall: 0.8535 - val_loss: 0.4808 - val_recall: 0.7459\n",
      "Epoch 478/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3368 - recall: 0.8644 - val_loss: 0.5784 - val_recall: 0.8177\n",
      "Epoch 479/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8596 - val_loss: 0.4721 - val_recall: 0.7293\n",
      "Epoch 480/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3312 - recall: 0.8535 - val_loss: 0.5333 - val_recall: 0.7735\n",
      "Epoch 481/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8590 - val_loss: 0.4882 - val_recall: 0.7569\n",
      "Epoch 482/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3333 - recall: 0.8602 - val_loss: 0.5060 - val_recall: 0.7624\n",
      "Epoch 483/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3294 - recall: 0.8723 - val_loss: 0.4718 - val_recall: 0.7403\n",
      "Epoch 484/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3344 - recall: 0.8596 - val_loss: 0.6180 - val_recall: 0.8453\n",
      "Epoch 485/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8686 - val_loss: 0.4875 - val_recall: 0.7624\n",
      "Epoch 486/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3292 - recall: 0.8553 - val_loss: 0.5581 - val_recall: 0.7790\n",
      "Epoch 487/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3324 - recall: 0.8650 - val_loss: 0.4428 - val_recall: 0.7293\n",
      "Epoch 488/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3331 - recall: 0.8590 - val_loss: 0.5353 - val_recall: 0.7790\n",
      "Epoch 489/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8602 - val_loss: 0.5328 - val_recall: 0.7956\n",
      "Epoch 490/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8608 - val_loss: 0.4449 - val_recall: 0.6961\n",
      "Epoch 491/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3317 - recall: 0.8614 - val_loss: 0.4794 - val_recall: 0.7403\n",
      "Epoch 492/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3311 - recall: 0.8711 - val_loss: 0.4874 - val_recall: 0.7514\n",
      "Epoch 493/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3341 - recall: 0.8620 - val_loss: 0.4718 - val_recall: 0.7293\n",
      "Epoch 494/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8547 - val_loss: 0.5174 - val_recall: 0.7845\n",
      "Epoch 495/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3314 - recall: 0.8692 - val_loss: 0.5197 - val_recall: 0.8066\n",
      "Epoch 496/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8590 - val_loss: 0.5003 - val_recall: 0.7790\n",
      "Epoch 497/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3305 - recall: 0.8596 - val_loss: 0.4832 - val_recall: 0.7182\n",
      "Epoch 498/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3304 - recall: 0.8596 - val_loss: 0.4285 - val_recall: 0.6630\n",
      "Epoch 499/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3308 - recall: 0.8529 - val_loss: 0.5126 - val_recall: 0.7680\n",
      "Epoch 500/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3318 - recall: 0.8674 - val_loss: 0.4129 - val_recall: 0.6354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1639f5c59d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, epochs = 500, verbose = 1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.645   0.624     0.615       0.779\n",
       "1 0.597   0.699     0.521       0.702\n",
       "2 0.568   0.699     0.569       0.818\n",
       "3 0.543   0.726     0.525       0.818\n",
       "4 0.524   0.731     0.455       0.796"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "[[676 120]\n",
      " [ 81 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       796\n",
      "           1       0.51      0.60      0.55       204\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.70      0.73      0.71      1000\n",
      "weighted avg       0.81      0.80      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (Receiver Operating Curve) and AUC (Area Under Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.plot(recalls, precisions, label='ANN')\n",
    "plt.xlabel('recalls')\n",
    "plt.ylabel('precisions')\n",
    "plt.title('Precisions_Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5931374980663807"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Different Methods to Develop The Model\n",
    "\n",
    "- Implement the following methods on model creating with \"class_weight\" parameter\n",
    "- Create and evaluate model for each method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase The Learning Rate and Observe The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.005)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.6451 - recall: 0.6241 - val_loss: 0.6146 - val_recall: 0.7790\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5970 - recall: 0.6985 - val_loss: 0.5211 - val_recall: 0.7017\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5677 - recall: 0.6992 - val_loss: 0.5693 - val_recall: 0.8177\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5430 - recall: 0.7264 - val_loss: 0.5245 - val_recall: 0.8177\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5239 - recall: 0.7312 - val_loss: 0.4552 - val_recall: 0.7956\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5054 - recall: 0.7379 - val_loss: 0.5590 - val_recall: 0.8619\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4976 - recall: 0.7524 - val_loss: 0.4706 - val_recall: 0.8398\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4910 - recall: 0.7518 - val_loss: 0.4955 - val_recall: 0.8619\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4882 - recall: 0.7548 - val_loss: 0.4503 - val_recall: 0.8232\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4869 - recall: 0.7548 - val_loss: 0.5224 - val_recall: 0.8729\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4830 - recall: 0.7573 - val_loss: 0.4104 - val_recall: 0.7790\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4770 - recall: 0.7615 - val_loss: 0.5488 - val_recall: 0.8785\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4797 - recall: 0.7712 - val_loss: 0.3963 - val_recall: 0.7845\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4784 - recall: 0.7615 - val_loss: 0.4545 - val_recall: 0.8398\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4756 - recall: 0.7530 - val_loss: 0.4341 - val_recall: 0.8177\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4742 - recall: 0.7663 - val_loss: 0.4086 - val_recall: 0.7845\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4719 - recall: 0.7591 - val_loss: 0.4816 - val_recall: 0.8453\n",
      "Epoch 18/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4707 - recall: 0.7766 - val_loss: 0.4263 - val_recall: 0.8232\n",
      "Epoch 19/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4705 - recall: 0.7597 - val_loss: 0.5061 - val_recall: 0.8674\n",
      "Epoch 20/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4691 - recall: 0.7585 - val_loss: 0.4353 - val_recall: 0.8232\n",
      "Epoch 21/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4673 - recall: 0.7676 - val_loss: 0.4485 - val_recall: 0.8453\n",
      "Epoch 22/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4660 - recall: 0.7633 - val_loss: 0.5503 - val_recall: 0.8785\n",
      "Epoch 23/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4678 - recall: 0.7760 - val_loss: 0.4209 - val_recall: 0.8066\n",
      "Epoch 24/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4661 - recall: 0.7706 - val_loss: 0.3952 - val_recall: 0.7348\n",
      "Epoch 25/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4632 - recall: 0.7518 - val_loss: 0.4369 - val_recall: 0.8287\n",
      "Epoch 26/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4635 - recall: 0.7657 - val_loss: 0.4105 - val_recall: 0.7790\n",
      "Epoch 27/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4613 - recall: 0.7663 - val_loss: 0.4639 - val_recall: 0.8398\n",
      "Epoch 28/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4581 - recall: 0.7730 - val_loss: 0.4647 - val_recall: 0.8398\n",
      "Epoch 29/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4585 - recall: 0.7736 - val_loss: 0.4388 - val_recall: 0.8122\n",
      "Epoch 30/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4576 - recall: 0.7772 - val_loss: 0.4581 - val_recall: 0.8122\n",
      "Epoch 31/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.4596 - recall: 0.7688 - val_loss: 0.4111 - val_recall: 0.8066\n",
      "Epoch 32/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4555 - recall: 0.7615 - val_loss: 0.4671 - val_recall: 0.8398\n",
      "Epoch 33/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4555 - recall: 0.7754 - val_loss: 0.4331 - val_recall: 0.8122\n",
      "Epoch 34/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4544 - recall: 0.7688 - val_loss: 0.4395 - val_recall: 0.8177\n",
      "Epoch 35/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4559 - recall: 0.7754 - val_loss: 0.3735 - val_recall: 0.7514\n",
      "Epoch 36/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4528 - recall: 0.7676 - val_loss: 0.3839 - val_recall: 0.7680\n",
      "Epoch 37/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4534 - recall: 0.7663 - val_loss: 0.4329 - val_recall: 0.8011\n",
      "Epoch 38/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4511 - recall: 0.7760 - val_loss: 0.4293 - val_recall: 0.8343\n",
      "Epoch 39/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4554 - recall: 0.7785 - val_loss: 0.4505 - val_recall: 0.8232\n",
      "Epoch 40/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4490 - recall: 0.7736 - val_loss: 0.4160 - val_recall: 0.7901\n",
      "Epoch 41/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4511 - recall: 0.7706 - val_loss: 0.4553 - val_recall: 0.8287\n",
      "Epoch 42/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4482 - recall: 0.7772 - val_loss: 0.5035 - val_recall: 0.8564\n",
      "Epoch 43/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4487 - recall: 0.7851 - val_loss: 0.4110 - val_recall: 0.7901\n",
      "Epoch 44/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4479 - recall: 0.7754 - val_loss: 0.4422 - val_recall: 0.8177\n",
      "Epoch 45/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4451 - recall: 0.7797 - val_loss: 0.4297 - val_recall: 0.7956\n",
      "Epoch 46/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4449 - recall: 0.7803 - val_loss: 0.4106 - val_recall: 0.8122\n",
      "Epoch 47/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4426 - recall: 0.7797 - val_loss: 0.4797 - val_recall: 0.8343\n",
      "Epoch 48/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4462 - recall: 0.7748 - val_loss: 0.4571 - val_recall: 0.8453\n",
      "Epoch 49/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4426 - recall: 0.7772 - val_loss: 0.4677 - val_recall: 0.8177\n",
      "Epoch 50/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4438 - recall: 0.7730 - val_loss: 0.4659 - val_recall: 0.8287\n",
      "Epoch 51/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4411 - recall: 0.7778 - val_loss: 0.4329 - val_recall: 0.8177\n",
      "Epoch 52/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4413 - recall: 0.7754 - val_loss: 0.4350 - val_recall: 0.8011\n",
      "Epoch 53/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4395 - recall: 0.7900 - val_loss: 0.3988 - val_recall: 0.7514\n",
      "Epoch 54/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4404 - recall: 0.7809 - val_loss: 0.4030 - val_recall: 0.7680\n",
      "Epoch 55/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4380 - recall: 0.7797 - val_loss: 0.4147 - val_recall: 0.7845\n",
      "Epoch 56/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4373 - recall: 0.7778 - val_loss: 0.4156 - val_recall: 0.7956\n",
      "Epoch 57/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4396 - recall: 0.7766 - val_loss: 0.4932 - val_recall: 0.8453\n",
      "Epoch 58/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4388 - recall: 0.7851 - val_loss: 0.3788 - val_recall: 0.7680\n",
      "Epoch 59/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4375 - recall: 0.7845 - val_loss: 0.3763 - val_recall: 0.7348\n",
      "Epoch 60/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4359 - recall: 0.7851 - val_loss: 0.4146 - val_recall: 0.8122\n",
      "Epoch 61/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4351 - recall: 0.7857 - val_loss: 0.4887 - val_recall: 0.8564\n",
      "Epoch 62/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4354 - recall: 0.7875 - val_loss: 0.4175 - val_recall: 0.8066\n",
      "Epoch 63/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4343 - recall: 0.7809 - val_loss: 0.4508 - val_recall: 0.8232\n",
      "Epoch 64/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4335 - recall: 0.7815 - val_loss: 0.3989 - val_recall: 0.7790\n",
      "Epoch 65/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4318 - recall: 0.7833 - val_loss: 0.4224 - val_recall: 0.7845\n",
      "Epoch 66/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4321 - recall: 0.7778 - val_loss: 0.5283 - val_recall: 0.8729\n",
      "Epoch 67/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4356 - recall: 0.7785 - val_loss: 0.3753 - val_recall: 0.7569\n",
      "Epoch 68/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4298 - recall: 0.7887 - val_loss: 0.4494 - val_recall: 0.8232\n",
      "Epoch 69/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4302 - recall: 0.7851 - val_loss: 0.4247 - val_recall: 0.8066\n",
      "Epoch 70/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4302 - recall: 0.7851 - val_loss: 0.3547 - val_recall: 0.7182\n",
      "Epoch 71/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4300 - recall: 0.7881 - val_loss: 0.3535 - val_recall: 0.7182\n",
      "Epoch 72/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4282 - recall: 0.7839 - val_loss: 0.4265 - val_recall: 0.8232\n",
      "Epoch 73/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4272 - recall: 0.7839 - val_loss: 0.4341 - val_recall: 0.8177\n",
      "Epoch 74/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4288 - recall: 0.7863 - val_loss: 0.3824 - val_recall: 0.7514\n",
      "Epoch 75/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4258 - recall: 0.7875 - val_loss: 0.4509 - val_recall: 0.8066\n",
      "Epoch 76/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4256 - recall: 0.7827 - val_loss: 0.4233 - val_recall: 0.8177\n",
      "Epoch 77/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4239 - recall: 0.7924 - val_loss: 0.4163 - val_recall: 0.7845\n",
      "Epoch 78/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4249 - recall: 0.7893 - val_loss: 0.4247 - val_recall: 0.7735\n",
      "Epoch 79/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4250 - recall: 0.7912 - val_loss: 0.4207 - val_recall: 0.7845\n",
      "Epoch 80/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4244 - recall: 0.7912 - val_loss: 0.4473 - val_recall: 0.8122\n",
      "Epoch 81/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4225 - recall: 0.7960 - val_loss: 0.4651 - val_recall: 0.8508\n",
      "Epoch 82/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4236 - recall: 0.7863 - val_loss: 0.4360 - val_recall: 0.8066\n",
      "Epoch 83/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4214 - recall: 0.7996 - val_loss: 0.3956 - val_recall: 0.7569\n",
      "Epoch 84/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4212 - recall: 0.7966 - val_loss: 0.3957 - val_recall: 0.7735\n",
      "Epoch 85/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4211 - recall: 0.7881 - val_loss: 0.3563 - val_recall: 0.7072\n",
      "Epoch 86/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4225 - recall: 0.7845 - val_loss: 0.4482 - val_recall: 0.8232\n",
      "Epoch 87/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4209 - recall: 0.7972 - val_loss: 0.4229 - val_recall: 0.7956\n",
      "Epoch 88/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4216 - recall: 0.7912 - val_loss: 0.4486 - val_recall: 0.8177\n",
      "Epoch 89/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4192 - recall: 0.7918 - val_loss: 0.4370 - val_recall: 0.8011\n",
      "Epoch 90/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4193 - recall: 0.7887 - val_loss: 0.4297 - val_recall: 0.8122\n",
      "Epoch 91/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4177 - recall: 0.7906 - val_loss: 0.3939 - val_recall: 0.7514\n",
      "Epoch 92/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4187 - recall: 0.7954 - val_loss: 0.4117 - val_recall: 0.7956\n",
      "Epoch 93/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4164 - recall: 0.7924 - val_loss: 0.4053 - val_recall: 0.8066\n",
      "Epoch 94/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4183 - recall: 0.7906 - val_loss: 0.4487 - val_recall: 0.8177\n",
      "Epoch 95/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4173 - recall: 0.7954 - val_loss: 0.5063 - val_recall: 0.8619\n",
      "Epoch 96/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4160 - recall: 0.7960 - val_loss: 0.3951 - val_recall: 0.7735\n",
      "Epoch 97/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4148 - recall: 0.7881 - val_loss: 0.4504 - val_recall: 0.8122\n",
      "Epoch 98/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4169 - recall: 0.7942 - val_loss: 0.5393 - val_recall: 0.8729\n",
      "Epoch 99/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4130 - recall: 0.7984 - val_loss: 0.4662 - val_recall: 0.8343\n",
      "Epoch 100/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4149 - recall: 0.8008 - val_loss: 0.4160 - val_recall: 0.7514\n",
      "Epoch 101/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4123 - recall: 0.7912 - val_loss: 0.4314 - val_recall: 0.8011\n",
      "Epoch 102/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4115 - recall: 0.8008 - val_loss: 0.4076 - val_recall: 0.7845\n",
      "Epoch 103/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4110 - recall: 0.7972 - val_loss: 0.4858 - val_recall: 0.8508\n",
      "Epoch 104/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4109 - recall: 0.8075 - val_loss: 0.4083 - val_recall: 0.7790\n",
      "Epoch 105/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4103 - recall: 0.7924 - val_loss: 0.4417 - val_recall: 0.7956\n",
      "Epoch 106/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4129 - recall: 0.7930 - val_loss: 0.4545 - val_recall: 0.7956\n",
      "Epoch 107/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4118 - recall: 0.7863 - val_loss: 0.5572 - val_recall: 0.8950\n",
      "Epoch 108/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4123 - recall: 0.8015 - val_loss: 0.4244 - val_recall: 0.7624\n",
      "Epoch 109/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4118 - recall: 0.7912 - val_loss: 0.3925 - val_recall: 0.7790\n",
      "Epoch 110/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.8063 - val_loss: 0.4468 - val_recall: 0.8177\n",
      "Epoch 111/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4073 - recall: 0.8075 - val_loss: 0.3819 - val_recall: 0.7403\n",
      "Epoch 112/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4083 - recall: 0.7978 - val_loss: 0.4300 - val_recall: 0.7790\n",
      "Epoch 113/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.7984 - val_loss: 0.4776 - val_recall: 0.8287\n",
      "Epoch 114/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4058 - recall: 0.8069 - val_loss: 0.4812 - val_recall: 0.8232\n",
      "Epoch 115/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4061 - recall: 0.7936 - val_loss: 0.3828 - val_recall: 0.7403\n",
      "Epoch 116/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4062 - recall: 0.7942 - val_loss: 0.4031 - val_recall: 0.7624\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4074 - recall: 0.8002 - val_loss: 0.4701 - val_recall: 0.8287\n",
      "Epoch 118/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4049 - recall: 0.7984 - val_loss: 0.3597 - val_recall: 0.7403\n",
      "Epoch 119/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4085 - recall: 0.7996 - val_loss: 0.4105 - val_recall: 0.7514\n",
      "Epoch 120/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4026 - recall: 0.8045 - val_loss: 0.5839 - val_recall: 0.8895\n",
      "Epoch 121/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4082 - recall: 0.8021 - val_loss: 0.4488 - val_recall: 0.7956\n",
      "Epoch 122/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4056 - recall: 0.8021 - val_loss: 0.4128 - val_recall: 0.7901\n",
      "Epoch 123/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4039 - recall: 0.8111 - val_loss: 0.4211 - val_recall: 0.7956\n",
      "Epoch 124/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4020 - recall: 0.8027 - val_loss: 0.4167 - val_recall: 0.7624\n",
      "Epoch 125/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4017 - recall: 0.8057 - val_loss: 0.4937 - val_recall: 0.8508\n",
      "Epoch 126/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4003 - recall: 0.8069 - val_loss: 0.4624 - val_recall: 0.8011\n",
      "Epoch 127/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4022 - recall: 0.8081 - val_loss: 0.4044 - val_recall: 0.7348\n",
      "Epoch 128/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4021 - recall: 0.8075 - val_loss: 0.4158 - val_recall: 0.7956\n",
      "Epoch 129/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4053 - recall: 0.8063 - val_loss: 0.3939 - val_recall: 0.7569\n",
      "Epoch 130/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4011 - recall: 0.7960 - val_loss: 0.4561 - val_recall: 0.8232\n",
      "Epoch 131/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4034 - recall: 0.8057 - val_loss: 0.4485 - val_recall: 0.8177\n",
      "Epoch 132/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3976 - recall: 0.8081 - val_loss: 0.4221 - val_recall: 0.7514\n",
      "Epoch 133/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3993 - recall: 0.8117 - val_loss: 0.3885 - val_recall: 0.7182\n",
      "Epoch 134/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4016 - recall: 0.8069 - val_loss: 0.4183 - val_recall: 0.7790\n",
      "Epoch 135/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.4000 - recall: 0.7990 - val_loss: 0.4378 - val_recall: 0.8122\n",
      "Epoch 136/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3990 - recall: 0.8069 - val_loss: 0.4922 - val_recall: 0.8619\n",
      "Epoch 137/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3974 - recall: 0.8123 - val_loss: 0.4579 - val_recall: 0.8177\n",
      "Epoch 138/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3985 - recall: 0.8045 - val_loss: 0.4424 - val_recall: 0.7901\n",
      "Epoch 139/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3987 - recall: 0.8069 - val_loss: 0.4527 - val_recall: 0.8011\n",
      "Epoch 140/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3961 - recall: 0.8057 - val_loss: 0.4452 - val_recall: 0.8177\n",
      "Epoch 141/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3955 - recall: 0.8123 - val_loss: 0.4021 - val_recall: 0.7569\n",
      "Epoch 142/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3949 - recall: 0.8027 - val_loss: 0.5173 - val_recall: 0.8343\n",
      "Epoch 143/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3961 - recall: 0.8196 - val_loss: 0.4147 - val_recall: 0.7680\n",
      "Epoch 144/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3963 - recall: 0.8142 - val_loss: 0.4154 - val_recall: 0.7459\n",
      "Epoch 145/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3968 - recall: 0.8021 - val_loss: 0.4198 - val_recall: 0.7680\n",
      "Epoch 146/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3944 - recall: 0.8105 - val_loss: 0.4801 - val_recall: 0.8343\n",
      "Epoch 147/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3942 - recall: 0.8063 - val_loss: 0.4358 - val_recall: 0.7956\n",
      "Epoch 148/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3930 - recall: 0.8142 - val_loss: 0.4381 - val_recall: 0.7790\n",
      "Epoch 149/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3938 - recall: 0.8081 - val_loss: 0.4449 - val_recall: 0.7680\n",
      "Epoch 150/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3912 - recall: 0.8166 - val_loss: 0.4015 - val_recall: 0.7293\n",
      "Epoch 151/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3933 - recall: 0.8075 - val_loss: 0.4254 - val_recall: 0.7790\n",
      "Epoch 152/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3952 - recall: 0.8160 - val_loss: 0.3874 - val_recall: 0.7514\n",
      "Epoch 153/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3943 - recall: 0.8075 - val_loss: 0.4300 - val_recall: 0.7735\n",
      "Epoch 154/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3932 - recall: 0.8166 - val_loss: 0.3622 - val_recall: 0.7072\n",
      "Epoch 155/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3955 - recall: 0.8002 - val_loss: 0.4282 - val_recall: 0.7735\n",
      "Epoch 156/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3929 - recall: 0.8148 - val_loss: 0.5061 - val_recall: 0.8343\n",
      "Epoch 157/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3934 - recall: 0.7996 - val_loss: 0.4414 - val_recall: 0.7956\n",
      "Epoch 158/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8142 - val_loss: 0.4880 - val_recall: 0.8066\n",
      "Epoch 159/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8220 - val_loss: 0.3745 - val_recall: 0.7182\n",
      "Epoch 160/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3887 - recall: 0.8178 - val_loss: 0.4407 - val_recall: 0.8122\n",
      "Epoch 161/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3915 - recall: 0.8123 - val_loss: 0.4078 - val_recall: 0.7514\n",
      "Epoch 162/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3919 - recall: 0.8069 - val_loss: 0.4284 - val_recall: 0.7901\n",
      "Epoch 163/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3875 - recall: 0.8148 - val_loss: 0.4490 - val_recall: 0.8122\n",
      "Epoch 164/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3901 - recall: 0.8117 - val_loss: 0.4406 - val_recall: 0.8066\n",
      "Epoch 165/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3869 - recall: 0.8202 - val_loss: 0.4151 - val_recall: 0.7845\n",
      "Epoch 166/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3899 - recall: 0.8051 - val_loss: 0.4344 - val_recall: 0.7845\n",
      "Epoch 167/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3892 - recall: 0.8148 - val_loss: 0.4151 - val_recall: 0.7182\n",
      "Epoch 168/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3887 - recall: 0.8166 - val_loss: 0.4938 - val_recall: 0.8398\n",
      "Epoch 169/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8196 - val_loss: 0.4328 - val_recall: 0.7845\n",
      "Epoch 170/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3894 - recall: 0.8202 - val_loss: 0.3822 - val_recall: 0.7238\n",
      "Epoch 171/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3880 - recall: 0.8142 - val_loss: 0.4751 - val_recall: 0.8122\n",
      "Epoch 172/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3867 - recall: 0.8136 - val_loss: 0.4135 - val_recall: 0.7624\n",
      "Epoch 173/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3883 - recall: 0.8184 - val_loss: 0.3799 - val_recall: 0.7238\n",
      "Epoch 174/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3875 - recall: 0.8232 - val_loss: 0.4546 - val_recall: 0.8122\n",
      "Epoch 175/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3914 - recall: 0.8111 - val_loss: 0.4486 - val_recall: 0.7845\n",
      "Epoch 176/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3852 - recall: 0.8142 - val_loss: 0.4563 - val_recall: 0.8177\n",
      "Epoch 177/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3912 - recall: 0.8136 - val_loss: 0.4059 - val_recall: 0.7735\n",
      "Epoch 178/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3890 - recall: 0.8142 - val_loss: 0.4564 - val_recall: 0.8066\n",
      "Epoch 179/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3867 - recall: 0.8184 - val_loss: 0.4392 - val_recall: 0.7790\n",
      "Epoch 180/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8148 - val_loss: 0.4409 - val_recall: 0.7790\n",
      "Epoch 181/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3853 - recall: 0.8238 - val_loss: 0.4032 - val_recall: 0.7238\n",
      "Epoch 182/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3848 - recall: 0.8238 - val_loss: 0.4816 - val_recall: 0.8232\n",
      "Epoch 183/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3864 - recall: 0.8154 - val_loss: 0.3993 - val_recall: 0.7569\n",
      "Epoch 184/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3847 - recall: 0.8166 - val_loss: 0.4941 - val_recall: 0.8066\n",
      "Epoch 185/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3870 - recall: 0.8051 - val_loss: 0.4669 - val_recall: 0.8122\n",
      "Epoch 186/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3850 - recall: 0.8305 - val_loss: 0.4492 - val_recall: 0.7901\n",
      "Epoch 187/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8208 - val_loss: 0.3987 - val_recall: 0.7459\n",
      "Epoch 188/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3900 - recall: 0.8123 - val_loss: 0.4489 - val_recall: 0.8122\n",
      "Epoch 189/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3833 - recall: 0.8202 - val_loss: 0.4239 - val_recall: 0.7845\n",
      "Epoch 190/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3846 - recall: 0.8154 - val_loss: 0.4258 - val_recall: 0.7459\n",
      "Epoch 191/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3864 - recall: 0.8172 - val_loss: 0.4822 - val_recall: 0.8011\n",
      "Epoch 192/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3853 - recall: 0.8196 - val_loss: 0.4035 - val_recall: 0.7293\n",
      "Epoch 193/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8287 - val_loss: 0.4502 - val_recall: 0.7680\n",
      "Epoch 194/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3852 - recall: 0.8196 - val_loss: 0.3740 - val_recall: 0.7127\n",
      "Epoch 195/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3846 - recall: 0.8208 - val_loss: 0.4331 - val_recall: 0.7790\n",
      "Epoch 196/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8196 - val_loss: 0.4995 - val_recall: 0.8177\n",
      "Epoch 197/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3845 - recall: 0.8172 - val_loss: 0.4739 - val_recall: 0.8232\n",
      "Epoch 198/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3819 - recall: 0.8148 - val_loss: 0.4235 - val_recall: 0.7735\n",
      "Epoch 199/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3821 - recall: 0.8251 - val_loss: 0.4815 - val_recall: 0.8066\n",
      "Epoch 200/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3827 - recall: 0.8226 - val_loss: 0.5281 - val_recall: 0.8564\n",
      "Epoch 201/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3794 - recall: 0.8196 - val_loss: 0.4782 - val_recall: 0.8177\n",
      "Epoch 202/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3808 - recall: 0.8160 - val_loss: 0.4269 - val_recall: 0.7845\n",
      "Epoch 203/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3815 - recall: 0.8299 - val_loss: 0.4095 - val_recall: 0.7569\n",
      "Epoch 204/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3817 - recall: 0.8287 - val_loss: 0.4173 - val_recall: 0.7624\n",
      "Epoch 205/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3843 - recall: 0.8208 - val_loss: 0.3964 - val_recall: 0.7348\n",
      "Epoch 206/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3767 - recall: 0.8196 - val_loss: 0.4453 - val_recall: 0.7845\n",
      "Epoch 207/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3826 - recall: 0.8263 - val_loss: 0.4419 - val_recall: 0.7680\n",
      "Epoch 208/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3803 - recall: 0.8226 - val_loss: 0.5073 - val_recall: 0.8398\n",
      "Epoch 209/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8257 - val_loss: 0.4839 - val_recall: 0.8122\n",
      "Epoch 210/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8202 - val_loss: 0.5117 - val_recall: 0.8398\n",
      "Epoch 211/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3784 - recall: 0.8178 - val_loss: 0.4769 - val_recall: 0.8011\n",
      "Epoch 212/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3770 - recall: 0.8251 - val_loss: 0.4004 - val_recall: 0.7403\n",
      "Epoch 213/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8178 - val_loss: 0.4100 - val_recall: 0.7680\n",
      "Epoch 214/500\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3801 - recall: 0.8160 - val_loss: 0.5052 - val_recall: 0.8232\n",
      "Epoch 215/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3791 - recall: 0.8269 - val_loss: 0.5134 - val_recall: 0.8287\n",
      "Epoch 216/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3802 - recall: 0.8220 - val_loss: 0.4811 - val_recall: 0.7901\n",
      "Epoch 217/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3793 - recall: 0.8202 - val_loss: 0.4182 - val_recall: 0.7459\n",
      "Epoch 218/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3776 - recall: 0.8226 - val_loss: 0.4181 - val_recall: 0.7459\n",
      "Epoch 219/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3787 - recall: 0.8257 - val_loss: 0.3944 - val_recall: 0.7459\n",
      "Epoch 220/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3765 - recall: 0.8232 - val_loss: 0.4590 - val_recall: 0.7790\n",
      "Epoch 221/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3780 - recall: 0.8281 - val_loss: 0.4255 - val_recall: 0.7735\n",
      "Epoch 222/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3787 - recall: 0.8287 - val_loss: 0.4961 - val_recall: 0.8287\n",
      "Epoch 223/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3740 - recall: 0.8251 - val_loss: 0.4946 - val_recall: 0.8011\n",
      "Epoch 224/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3761 - recall: 0.8214 - val_loss: 0.4485 - val_recall: 0.7624\n",
      "Epoch 225/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3750 - recall: 0.8245 - val_loss: 0.4135 - val_recall: 0.7790\n",
      "Epoch 226/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3766 - recall: 0.8263 - val_loss: 0.4758 - val_recall: 0.7956\n",
      "Epoch 227/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3768 - recall: 0.8226 - val_loss: 0.4203 - val_recall: 0.7514\n",
      "Epoch 228/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3747 - recall: 0.8263 - val_loss: 0.4996 - val_recall: 0.8177\n",
      "Epoch 229/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3733 - recall: 0.8360 - val_loss: 0.4690 - val_recall: 0.7790\n",
      "Epoch 230/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3735 - recall: 0.8263 - val_loss: 0.4587 - val_recall: 0.7735\n",
      "Epoch 231/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3763 - recall: 0.8299 - val_loss: 0.4076 - val_recall: 0.7403\n",
      "Epoch 232/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3782 - recall: 0.8251 - val_loss: 0.4741 - val_recall: 0.8066\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3743 - recall: 0.8275 - val_loss: 0.4806 - val_recall: 0.7845\n",
      "Epoch 234/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3774 - recall: 0.8311 - val_loss: 0.4846 - val_recall: 0.8177\n",
      "Epoch 235/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3759 - recall: 0.8220 - val_loss: 0.4344 - val_recall: 0.8122\n",
      "Epoch 236/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3756 - recall: 0.8341 - val_loss: 0.4800 - val_recall: 0.7735\n",
      "Epoch 237/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8263 - val_loss: 0.4197 - val_recall: 0.7238\n",
      "Epoch 238/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3756 - recall: 0.8287 - val_loss: 0.4560 - val_recall: 0.7624\n",
      "Epoch 239/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3736 - recall: 0.8323 - val_loss: 0.4643 - val_recall: 0.7569\n",
      "Epoch 240/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3722 - recall: 0.8311 - val_loss: 0.5003 - val_recall: 0.8122\n",
      "Epoch 241/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3743 - recall: 0.8311 - val_loss: 0.4697 - val_recall: 0.7956\n",
      "Epoch 242/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3748 - recall: 0.8354 - val_loss: 0.4845 - val_recall: 0.7956\n",
      "Epoch 243/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3702 - recall: 0.8275 - val_loss: 0.4065 - val_recall: 0.7238\n",
      "Epoch 244/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3728 - recall: 0.8281 - val_loss: 0.4653 - val_recall: 0.8011\n",
      "Epoch 245/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3708 - recall: 0.8335 - val_loss: 0.4255 - val_recall: 0.7680\n",
      "Epoch 246/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3706 - recall: 0.8305 - val_loss: 0.4608 - val_recall: 0.7956\n",
      "Epoch 247/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3734 - recall: 0.8208 - val_loss: 0.4831 - val_recall: 0.8287\n",
      "Epoch 248/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3729 - recall: 0.8263 - val_loss: 0.4684 - val_recall: 0.7956\n",
      "Epoch 249/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3722 - recall: 0.8329 - val_loss: 0.4734 - val_recall: 0.7790\n",
      "Epoch 250/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3718 - recall: 0.8329 - val_loss: 0.4221 - val_recall: 0.7238\n",
      "Epoch 251/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3707 - recall: 0.8311 - val_loss: 0.4895 - val_recall: 0.7845\n",
      "Epoch 252/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8238 - val_loss: 0.3920 - val_recall: 0.7017\n",
      "Epoch 253/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8293 - val_loss: 0.4082 - val_recall: 0.7459\n",
      "Epoch 254/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3701 - recall: 0.8329 - val_loss: 0.3777 - val_recall: 0.6851\n",
      "Epoch 255/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3711 - recall: 0.8166 - val_loss: 0.4675 - val_recall: 0.7901\n",
      "Epoch 256/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3692 - recall: 0.8347 - val_loss: 0.4379 - val_recall: 0.7182\n",
      "Epoch 257/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3681 - recall: 0.8372 - val_loss: 0.3912 - val_recall: 0.6906\n",
      "Epoch 258/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8293 - val_loss: 0.4172 - val_recall: 0.7569\n",
      "Epoch 259/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3705 - recall: 0.8269 - val_loss: 0.4495 - val_recall: 0.7956\n",
      "Epoch 260/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3694 - recall: 0.8275 - val_loss: 0.4325 - val_recall: 0.7624\n",
      "Epoch 261/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3714 - recall: 0.8214 - val_loss: 0.4802 - val_recall: 0.7845\n",
      "Epoch 262/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3700 - recall: 0.8323 - val_loss: 0.4079 - val_recall: 0.6851\n",
      "Epoch 263/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3685 - recall: 0.8275 - val_loss: 0.4256 - val_recall: 0.7127\n",
      "Epoch 264/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3680 - recall: 0.8323 - val_loss: 0.5051 - val_recall: 0.8343\n",
      "Epoch 265/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3672 - recall: 0.8208 - val_loss: 0.4435 - val_recall: 0.7735\n",
      "Epoch 266/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3679 - recall: 0.8347 - val_loss: 0.4144 - val_recall: 0.6961\n",
      "Epoch 267/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3669 - recall: 0.8354 - val_loss: 0.5666 - val_recall: 0.8564\n",
      "Epoch 268/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3696 - recall: 0.8305 - val_loss: 0.4480 - val_recall: 0.7901\n",
      "Epoch 269/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3664 - recall: 0.8311 - val_loss: 0.4480 - val_recall: 0.7459\n",
      "Epoch 270/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3703 - recall: 0.8275 - val_loss: 0.4811 - val_recall: 0.7735\n",
      "Epoch 271/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3683 - recall: 0.8341 - val_loss: 0.4388 - val_recall: 0.7348\n",
      "Epoch 272/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3664 - recall: 0.8329 - val_loss: 0.4410 - val_recall: 0.7624\n",
      "Epoch 273/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3697 - recall: 0.8311 - val_loss: 0.4483 - val_recall: 0.7514\n",
      "Epoch 274/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3659 - recall: 0.8251 - val_loss: 0.5036 - val_recall: 0.8177\n",
      "Epoch 275/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3689 - recall: 0.8366 - val_loss: 0.4607 - val_recall: 0.7624\n",
      "Epoch 276/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3666 - recall: 0.8329 - val_loss: 0.4480 - val_recall: 0.7569\n",
      "Epoch 277/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3677 - recall: 0.8317 - val_loss: 0.4315 - val_recall: 0.7238\n",
      "Epoch 278/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3654 - recall: 0.8305 - val_loss: 0.5058 - val_recall: 0.8232\n",
      "Epoch 279/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3651 - recall: 0.8245 - val_loss: 0.4823 - val_recall: 0.8066\n",
      "Epoch 280/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3625 - recall: 0.8366 - val_loss: 0.4307 - val_recall: 0.7127\n",
      "Epoch 281/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3639 - recall: 0.8347 - val_loss: 0.4530 - val_recall: 0.7735\n",
      "Epoch 282/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3656 - recall: 0.8360 - val_loss: 0.4697 - val_recall: 0.7845\n",
      "Epoch 283/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3635 - recall: 0.8317 - val_loss: 0.4606 - val_recall: 0.7680\n",
      "Epoch 284/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3630 - recall: 0.8329 - val_loss: 0.4516 - val_recall: 0.7624\n",
      "Epoch 285/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3640 - recall: 0.8378 - val_loss: 0.4417 - val_recall: 0.7514\n",
      "Epoch 286/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3669 - recall: 0.8354 - val_loss: 0.4473 - val_recall: 0.7459\n",
      "Epoch 287/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3626 - recall: 0.8354 - val_loss: 0.4038 - val_recall: 0.7348\n",
      "Epoch 288/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3647 - recall: 0.8323 - val_loss: 0.5241 - val_recall: 0.8232\n",
      "Epoch 289/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3640 - recall: 0.8378 - val_loss: 0.3761 - val_recall: 0.6575\n",
      "Epoch 290/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3641 - recall: 0.8287 - val_loss: 0.4345 - val_recall: 0.7514\n",
      "Epoch 291/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3627 - recall: 0.8366 - val_loss: 0.3896 - val_recall: 0.7072\n",
      "Epoch 292/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3645 - recall: 0.8311 - val_loss: 0.3980 - val_recall: 0.7182\n",
      "Epoch 293/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3624 - recall: 0.8305 - val_loss: 0.4426 - val_recall: 0.7624\n",
      "Epoch 294/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3604 - recall: 0.8311 - val_loss: 0.5059 - val_recall: 0.8177\n",
      "Epoch 295/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3615 - recall: 0.8414 - val_loss: 0.4209 - val_recall: 0.7403\n",
      "Epoch 296/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3629 - recall: 0.8317 - val_loss: 0.5109 - val_recall: 0.7956\n",
      "Epoch 297/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3615 - recall: 0.8372 - val_loss: 0.5534 - val_recall: 0.8619\n",
      "Epoch 298/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3608 - recall: 0.8360 - val_loss: 0.4712 - val_recall: 0.7735\n",
      "Epoch 299/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3626 - recall: 0.8335 - val_loss: 0.4168 - val_recall: 0.7072\n",
      "Epoch 300/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3613 - recall: 0.8390 - val_loss: 0.3799 - val_recall: 0.7072\n",
      "Epoch 301/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3623 - recall: 0.8347 - val_loss: 0.4722 - val_recall: 0.7735\n",
      "Epoch 302/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3613 - recall: 0.8366 - val_loss: 0.4320 - val_recall: 0.7072\n",
      "Epoch 303/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3607 - recall: 0.8366 - val_loss: 0.4153 - val_recall: 0.7293\n",
      "Epoch 304/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3607 - recall: 0.8232 - val_loss: 0.4794 - val_recall: 0.8232\n",
      "Epoch 305/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3653 - recall: 0.8317 - val_loss: 0.5224 - val_recall: 0.8066\n",
      "Epoch 306/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3631 - recall: 0.8378 - val_loss: 0.4381 - val_recall: 0.7459\n",
      "Epoch 307/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3597 - recall: 0.8372 - val_loss: 0.4099 - val_recall: 0.7348\n",
      "Epoch 308/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3608 - recall: 0.8341 - val_loss: 0.3870 - val_recall: 0.7182\n",
      "Epoch 309/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3593 - recall: 0.8420 - val_loss: 0.3960 - val_recall: 0.6796\n",
      "Epoch 310/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3617 - recall: 0.8341 - val_loss: 0.4805 - val_recall: 0.7901\n",
      "Epoch 311/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3600 - recall: 0.8384 - val_loss: 0.4238 - val_recall: 0.7017\n",
      "Epoch 312/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3597 - recall: 0.8420 - val_loss: 0.4404 - val_recall: 0.7680\n",
      "Epoch 313/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3609 - recall: 0.8305 - val_loss: 0.4348 - val_recall: 0.7403\n",
      "Epoch 314/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3594 - recall: 0.8341 - val_loss: 0.4418 - val_recall: 0.7901\n",
      "Epoch 315/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3563 - recall: 0.8450 - val_loss: 0.4678 - val_recall: 0.7680\n",
      "Epoch 316/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3588 - recall: 0.8450 - val_loss: 0.4337 - val_recall: 0.7459\n",
      "Epoch 317/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3575 - recall: 0.8426 - val_loss: 0.4756 - val_recall: 0.7956\n",
      "Epoch 318/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3590 - recall: 0.8432 - val_loss: 0.4625 - val_recall: 0.8011\n",
      "Epoch 319/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3596 - recall: 0.8396 - val_loss: 0.4747 - val_recall: 0.7790\n",
      "Epoch 320/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3629 - recall: 0.8323 - val_loss: 0.4817 - val_recall: 0.8011\n",
      "Epoch 321/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3591 - recall: 0.8287 - val_loss: 0.5038 - val_recall: 0.8122\n",
      "Epoch 322/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3588 - recall: 0.8420 - val_loss: 0.4583 - val_recall: 0.7624\n",
      "Epoch 323/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8523 - val_loss: 0.4809 - val_recall: 0.7735\n",
      "Epoch 324/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3546 - recall: 0.8432 - val_loss: 0.4653 - val_recall: 0.7403\n",
      "Epoch 325/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3611 - recall: 0.8372 - val_loss: 0.5168 - val_recall: 0.8232\n",
      "Epoch 326/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3578 - recall: 0.8384 - val_loss: 0.5689 - val_recall: 0.8508\n",
      "Epoch 327/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3592 - recall: 0.8511 - val_loss: 0.4709 - val_recall: 0.7790\n",
      "Epoch 328/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3561 - recall: 0.8354 - val_loss: 0.5145 - val_recall: 0.8122\n",
      "Epoch 329/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3559 - recall: 0.8335 - val_loss: 0.5106 - val_recall: 0.8177\n",
      "Epoch 330/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3567 - recall: 0.8414 - val_loss: 0.4274 - val_recall: 0.7403\n",
      "Epoch 331/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8360 - val_loss: 0.4660 - val_recall: 0.8122\n",
      "Epoch 332/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3571 - recall: 0.8517 - val_loss: 0.4561 - val_recall: 0.7680\n",
      "Epoch 333/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8408 - val_loss: 0.4264 - val_recall: 0.7569\n",
      "Epoch 334/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3583 - recall: 0.8305 - val_loss: 0.4690 - val_recall: 0.7569\n",
      "Epoch 335/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3555 - recall: 0.8426 - val_loss: 0.4981 - val_recall: 0.8011\n",
      "Epoch 336/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3532 - recall: 0.8378 - val_loss: 0.5185 - val_recall: 0.8122\n",
      "Epoch 337/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3574 - recall: 0.8481 - val_loss: 0.4215 - val_recall: 0.6961\n",
      "Epoch 338/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3580 - recall: 0.8378 - val_loss: 0.4301 - val_recall: 0.7403\n",
      "Epoch 339/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3570 - recall: 0.8462 - val_loss: 0.4921 - val_recall: 0.7845\n",
      "Epoch 340/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3524 - recall: 0.8420 - val_loss: 0.4425 - val_recall: 0.7735\n",
      "Epoch 341/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8396 - val_loss: 0.4576 - val_recall: 0.7569\n",
      "Epoch 342/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3534 - recall: 0.8438 - val_loss: 0.5160 - val_recall: 0.8011\n",
      "Epoch 343/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3544 - recall: 0.8481 - val_loss: 0.4563 - val_recall: 0.7569\n",
      "Epoch 344/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3524 - recall: 0.8378 - val_loss: 0.4878 - val_recall: 0.7956\n",
      "Epoch 345/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3540 - recall: 0.8426 - val_loss: 0.4583 - val_recall: 0.7569\n",
      "Epoch 346/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3553 - recall: 0.8481 - val_loss: 0.4938 - val_recall: 0.7901\n",
      "Epoch 347/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3562 - recall: 0.8390 - val_loss: 0.5845 - val_recall: 0.8398\n",
      "Epoch 348/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3548 - recall: 0.8426 - val_loss: 0.5014 - val_recall: 0.7514\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3546 - recall: 0.8456 - val_loss: 0.4245 - val_recall: 0.7790\n",
      "Epoch 350/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3523 - recall: 0.8469 - val_loss: 0.4259 - val_recall: 0.6851\n",
      "Epoch 351/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3522 - recall: 0.8456 - val_loss: 0.4605 - val_recall: 0.7680\n",
      "Epoch 352/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3530 - recall: 0.8450 - val_loss: 0.4584 - val_recall: 0.7790\n",
      "Epoch 353/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3519 - recall: 0.8444 - val_loss: 0.4792 - val_recall: 0.7459\n",
      "Epoch 354/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3532 - recall: 0.8384 - val_loss: 0.4842 - val_recall: 0.7956\n",
      "Epoch 355/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3572 - recall: 0.8456 - val_loss: 0.4502 - val_recall: 0.7459\n",
      "Epoch 356/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3515 - recall: 0.8444 - val_loss: 0.4163 - val_recall: 0.7017\n",
      "Epoch 357/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3518 - recall: 0.8444 - val_loss: 0.4181 - val_recall: 0.7348\n",
      "Epoch 358/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3526 - recall: 0.8378 - val_loss: 0.5125 - val_recall: 0.8343\n",
      "Epoch 359/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3516 - recall: 0.8432 - val_loss: 0.5161 - val_recall: 0.8066\n",
      "Epoch 360/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3541 - recall: 0.8366 - val_loss: 0.5019 - val_recall: 0.7901\n",
      "Epoch 361/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3506 - recall: 0.8475 - val_loss: 0.4202 - val_recall: 0.7238\n",
      "Epoch 362/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3514 - recall: 0.8366 - val_loss: 0.4834 - val_recall: 0.7845\n",
      "Epoch 363/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3492 - recall: 0.8390 - val_loss: 0.5194 - val_recall: 0.7901\n",
      "Epoch 364/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3522 - recall: 0.8481 - val_loss: 0.5087 - val_recall: 0.8287\n",
      "Epoch 365/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8541 - val_loss: 0.4306 - val_recall: 0.7514\n",
      "Epoch 366/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3495 - recall: 0.8487 - val_loss: 0.4552 - val_recall: 0.7238\n",
      "Epoch 367/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3528 - recall: 0.8420 - val_loss: 0.4432 - val_recall: 0.7182\n",
      "Epoch 368/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3507 - recall: 0.8450 - val_loss: 0.5006 - val_recall: 0.7901\n",
      "Epoch 369/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3536 - recall: 0.8535 - val_loss: 0.4490 - val_recall: 0.7182\n",
      "Epoch 370/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3537 - recall: 0.8420 - val_loss: 0.3985 - val_recall: 0.6685\n",
      "Epoch 371/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3512 - recall: 0.8396 - val_loss: 0.5008 - val_recall: 0.7735\n",
      "Epoch 372/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3515 - recall: 0.8432 - val_loss: 0.5630 - val_recall: 0.8398\n",
      "Epoch 373/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3473 - recall: 0.8432 - val_loss: 0.5213 - val_recall: 0.7901\n",
      "Epoch 374/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3465 - recall: 0.8481 - val_loss: 0.5047 - val_recall: 0.7956\n",
      "Epoch 375/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3495 - recall: 0.8493 - val_loss: 0.4560 - val_recall: 0.7348\n",
      "Epoch 376/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3494 - recall: 0.8469 - val_loss: 0.4925 - val_recall: 0.7569\n",
      "Epoch 377/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3476 - recall: 0.8469 - val_loss: 0.5474 - val_recall: 0.8343\n",
      "Epoch 378/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3471 - recall: 0.8529 - val_loss: 0.4235 - val_recall: 0.6961\n",
      "Epoch 379/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3466 - recall: 0.8517 - val_loss: 0.4560 - val_recall: 0.7624\n",
      "Epoch 380/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8511 - val_loss: 0.4175 - val_recall: 0.6906\n",
      "Epoch 381/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3496 - recall: 0.8462 - val_loss: 0.4598 - val_recall: 0.7624\n",
      "Epoch 382/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3455 - recall: 0.8511 - val_loss: 0.4978 - val_recall: 0.7735\n",
      "Epoch 383/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3477 - recall: 0.8469 - val_loss: 0.4550 - val_recall: 0.7514\n",
      "Epoch 384/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3488 - recall: 0.8481 - val_loss: 0.4592 - val_recall: 0.7514\n",
      "Epoch 385/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3447 - recall: 0.8499 - val_loss: 0.4770 - val_recall: 0.7624\n",
      "Epoch 386/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8475 - val_loss: 0.4935 - val_recall: 0.7680\n",
      "Epoch 387/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3475 - recall: 0.8547 - val_loss: 0.4641 - val_recall: 0.7238\n",
      "Epoch 388/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3444 - recall: 0.8559 - val_loss: 0.4371 - val_recall: 0.7238\n",
      "Epoch 389/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3442 - recall: 0.8511 - val_loss: 0.5066 - val_recall: 0.7845\n",
      "Epoch 390/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8559 - val_loss: 0.4197 - val_recall: 0.7459\n",
      "Epoch 391/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3500 - recall: 0.8438 - val_loss: 0.4777 - val_recall: 0.7680\n",
      "Epoch 392/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3485 - recall: 0.8426 - val_loss: 0.5093 - val_recall: 0.7680\n",
      "Epoch 393/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3468 - recall: 0.8529 - val_loss: 0.4389 - val_recall: 0.7348\n",
      "Epoch 394/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3440 - recall: 0.8535 - val_loss: 0.4440 - val_recall: 0.7514\n",
      "Epoch 395/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3445 - recall: 0.8487 - val_loss: 0.4395 - val_recall: 0.7293\n",
      "Epoch 396/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3498 - recall: 0.8481 - val_loss: 0.4636 - val_recall: 0.7569\n",
      "Epoch 397/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3413 - recall: 0.8547 - val_loss: 0.4366 - val_recall: 0.7182\n",
      "Epoch 398/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3461 - recall: 0.8499 - val_loss: 0.4472 - val_recall: 0.7569\n",
      "Epoch 399/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3461 - recall: 0.8438 - val_loss: 0.5078 - val_recall: 0.8066\n",
      "Epoch 400/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8481 - val_loss: 0.4949 - val_recall: 0.7845\n",
      "Epoch 401/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3430 - recall: 0.8523 - val_loss: 0.4853 - val_recall: 0.7624\n",
      "Epoch 402/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3451 - recall: 0.8547 - val_loss: 0.4987 - val_recall: 0.7403\n",
      "Epoch 403/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8505 - val_loss: 0.5185 - val_recall: 0.8011\n",
      "Epoch 404/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3425 - recall: 0.8487 - val_loss: 0.4468 - val_recall: 0.7072\n",
      "Epoch 405/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3429 - recall: 0.8541 - val_loss: 0.5348 - val_recall: 0.8287\n",
      "Epoch 406/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3457 - recall: 0.8475 - val_loss: 0.5403 - val_recall: 0.7735\n",
      "Epoch 407/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3418 - recall: 0.8505 - val_loss: 0.4938 - val_recall: 0.7735\n",
      "Epoch 408/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3418 - recall: 0.8529 - val_loss: 0.4063 - val_recall: 0.6133\n",
      "Epoch 409/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3438 - recall: 0.8571 - val_loss: 0.4366 - val_recall: 0.7293\n",
      "Epoch 410/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3412 - recall: 0.8529 - val_loss: 0.4766 - val_recall: 0.7238\n",
      "Epoch 411/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3464 - recall: 0.8481 - val_loss: 0.4400 - val_recall: 0.7403\n",
      "Epoch 412/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3450 - recall: 0.8481 - val_loss: 0.4929 - val_recall: 0.7845\n",
      "Epoch 413/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3411 - recall: 0.8608 - val_loss: 0.4562 - val_recall: 0.7845\n",
      "Epoch 414/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3443 - recall: 0.8523 - val_loss: 0.4869 - val_recall: 0.7680\n",
      "Epoch 415/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3423 - recall: 0.8596 - val_loss: 0.4287 - val_recall: 0.7182\n",
      "Epoch 416/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3412 - recall: 0.8559 - val_loss: 0.4675 - val_recall: 0.7459\n",
      "Epoch 417/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3420 - recall: 0.8529 - val_loss: 0.4658 - val_recall: 0.7845\n",
      "Epoch 418/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3437 - recall: 0.8529 - val_loss: 0.5793 - val_recall: 0.8066\n",
      "Epoch 419/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3432 - recall: 0.8517 - val_loss: 0.4299 - val_recall: 0.7127\n",
      "Epoch 420/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3381 - recall: 0.8487 - val_loss: 0.4984 - val_recall: 0.7901\n",
      "Epoch 421/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3413 - recall: 0.8577 - val_loss: 0.4985 - val_recall: 0.7956\n",
      "Epoch 422/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3426 - recall: 0.8475 - val_loss: 0.4163 - val_recall: 0.7072\n",
      "Epoch 423/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3421 - recall: 0.8517 - val_loss: 0.5062 - val_recall: 0.7680\n",
      "Epoch 424/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8529 - val_loss: 0.5780 - val_recall: 0.8287\n",
      "Epoch 425/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3414 - recall: 0.8590 - val_loss: 0.5330 - val_recall: 0.7680\n",
      "Epoch 426/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3435 - recall: 0.8571 - val_loss: 0.4286 - val_recall: 0.7017\n",
      "Epoch 427/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3416 - recall: 0.8517 - val_loss: 0.4277 - val_recall: 0.6906\n",
      "Epoch 428/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3428 - recall: 0.8559 - val_loss: 0.4635 - val_recall: 0.7624\n",
      "Epoch 429/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3406 - recall: 0.8535 - val_loss: 0.5291 - val_recall: 0.8011\n",
      "Epoch 430/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3445 - recall: 0.8571 - val_loss: 0.4261 - val_recall: 0.7348\n",
      "Epoch 431/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3406 - recall: 0.8450 - val_loss: 0.4449 - val_recall: 0.7348\n",
      "Epoch 432/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3392 - recall: 0.8668 - val_loss: 0.5493 - val_recall: 0.7680\n",
      "Epoch 433/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3385 - recall: 0.8511 - val_loss: 0.4338 - val_recall: 0.6961\n",
      "Epoch 434/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3395 - recall: 0.8571 - val_loss: 0.4276 - val_recall: 0.7238\n",
      "Epoch 435/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3411 - recall: 0.8584 - val_loss: 0.5272 - val_recall: 0.7845\n",
      "Epoch 436/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3392 - recall: 0.8541 - val_loss: 0.4096 - val_recall: 0.6796\n",
      "Epoch 437/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3399 - recall: 0.8565 - val_loss: 0.4809 - val_recall: 0.7569\n",
      "Epoch 438/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3405 - recall: 0.8529 - val_loss: 0.4201 - val_recall: 0.6851\n",
      "Epoch 439/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3408 - recall: 0.8559 - val_loss: 0.4715 - val_recall: 0.7680\n",
      "Epoch 440/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3458 - recall: 0.8584 - val_loss: 0.4535 - val_recall: 0.7348\n",
      "Epoch 441/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3375 - recall: 0.8450 - val_loss: 0.4936 - val_recall: 0.7459\n",
      "Epoch 442/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3386 - recall: 0.8584 - val_loss: 0.4777 - val_recall: 0.7624\n",
      "Epoch 443/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3375 - recall: 0.8571 - val_loss: 0.4934 - val_recall: 0.7238\n",
      "Epoch 444/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3374 - recall: 0.8541 - val_loss: 0.5112 - val_recall: 0.7845\n",
      "Epoch 445/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3371 - recall: 0.8584 - val_loss: 0.4273 - val_recall: 0.7127\n",
      "Epoch 446/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3397 - recall: 0.8553 - val_loss: 0.4779 - val_recall: 0.7569\n",
      "Epoch 447/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3373 - recall: 0.8565 - val_loss: 0.4946 - val_recall: 0.7735\n",
      "Epoch 448/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3370 - recall: 0.8596 - val_loss: 0.4667 - val_recall: 0.7293\n",
      "Epoch 449/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3371 - recall: 0.8614 - val_loss: 0.5257 - val_recall: 0.7845\n",
      "Epoch 450/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3368 - recall: 0.8565 - val_loss: 0.5075 - val_recall: 0.7901\n",
      "Epoch 451/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8529 - val_loss: 0.5900 - val_recall: 0.8232\n",
      "Epoch 452/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8614 - val_loss: 0.4746 - val_recall: 0.7293\n",
      "Epoch 453/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3386 - recall: 0.8541 - val_loss: 0.5034 - val_recall: 0.7569\n",
      "Epoch 454/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3365 - recall: 0.8602 - val_loss: 0.4760 - val_recall: 0.7624\n",
      "Epoch 455/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3364 - recall: 0.8608 - val_loss: 0.5737 - val_recall: 0.8398\n",
      "Epoch 456/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8565 - val_loss: 0.4841 - val_recall: 0.7680\n",
      "Epoch 457/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3397 - recall: 0.8529 - val_loss: 0.4756 - val_recall: 0.7403\n",
      "Epoch 458/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3377 - recall: 0.8571 - val_loss: 0.5612 - val_recall: 0.8177\n",
      "Epoch 459/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3374 - recall: 0.8596 - val_loss: 0.5484 - val_recall: 0.8177\n",
      "Epoch 460/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3328 - recall: 0.8577 - val_loss: 0.5978 - val_recall: 0.8674\n",
      "Epoch 461/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3384 - recall: 0.8493 - val_loss: 0.5133 - val_recall: 0.7845\n",
      "Epoch 462/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3370 - recall: 0.8614 - val_loss: 0.4746 - val_recall: 0.7514\n",
      "Epoch 463/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3363 - recall: 0.8535 - val_loss: 0.4742 - val_recall: 0.7403\n",
      "Epoch 464/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3349 - recall: 0.8602 - val_loss: 0.5636 - val_recall: 0.8066\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3357 - recall: 0.8626 - val_loss: 0.4827 - val_recall: 0.7514\n",
      "Epoch 466/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8656 - val_loss: 0.4843 - val_recall: 0.7348\n",
      "Epoch 467/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3390 - recall: 0.8608 - val_loss: 0.4798 - val_recall: 0.7514\n",
      "Epoch 468/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3376 - recall: 0.8620 - val_loss: 0.4975 - val_recall: 0.7514\n",
      "Epoch 469/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3323 - recall: 0.8553 - val_loss: 0.4571 - val_recall: 0.7072\n",
      "Epoch 470/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8674 - val_loss: 0.4560 - val_recall: 0.7293\n",
      "Epoch 471/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3350 - recall: 0.8553 - val_loss: 0.4457 - val_recall: 0.6961\n",
      "Epoch 472/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8571 - val_loss: 0.4755 - val_recall: 0.7735\n",
      "Epoch 473/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3324 - recall: 0.8656 - val_loss: 0.5092 - val_recall: 0.7735\n",
      "Epoch 474/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3366 - recall: 0.8650 - val_loss: 0.5127 - val_recall: 0.7735\n",
      "Epoch 475/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3328 - recall: 0.8644 - val_loss: 0.4716 - val_recall: 0.7293\n",
      "Epoch 476/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3352 - recall: 0.8608 - val_loss: 0.4565 - val_recall: 0.7127\n",
      "Epoch 477/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3346 - recall: 0.8535 - val_loss: 0.4808 - val_recall: 0.7459\n",
      "Epoch 478/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3368 - recall: 0.8644 - val_loss: 0.5784 - val_recall: 0.8177\n",
      "Epoch 479/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8596 - val_loss: 0.4721 - val_recall: 0.7293\n",
      "Epoch 480/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3312 - recall: 0.8535 - val_loss: 0.5333 - val_recall: 0.7735\n",
      "Epoch 481/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8590 - val_loss: 0.4882 - val_recall: 0.7569\n",
      "Epoch 482/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3333 - recall: 0.8602 - val_loss: 0.5060 - val_recall: 0.7624\n",
      "Epoch 483/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3294 - recall: 0.8723 - val_loss: 0.4718 - val_recall: 0.7403\n",
      "Epoch 484/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3344 - recall: 0.8596 - val_loss: 0.6180 - val_recall: 0.8453\n",
      "Epoch 485/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3358 - recall: 0.8686 - val_loss: 0.4875 - val_recall: 0.7624\n",
      "Epoch 486/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3292 - recall: 0.8553 - val_loss: 0.5581 - val_recall: 0.7790\n",
      "Epoch 487/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3324 - recall: 0.8650 - val_loss: 0.4428 - val_recall: 0.7293\n",
      "Epoch 488/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3331 - recall: 0.8590 - val_loss: 0.5353 - val_recall: 0.7790\n",
      "Epoch 489/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8602 - val_loss: 0.5328 - val_recall: 0.7956\n",
      "Epoch 490/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8608 - val_loss: 0.4449 - val_recall: 0.6961\n",
      "Epoch 491/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3317 - recall: 0.8614 - val_loss: 0.4794 - val_recall: 0.7403\n",
      "Epoch 492/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3311 - recall: 0.8711 - val_loss: 0.4874 - val_recall: 0.7514\n",
      "Epoch 493/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3341 - recall: 0.8620 - val_loss: 0.4718 - val_recall: 0.7293\n",
      "Epoch 494/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3335 - recall: 0.8547 - val_loss: 0.5174 - val_recall: 0.7845\n",
      "Epoch 495/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3314 - recall: 0.8692 - val_loss: 0.5197 - val_recall: 0.8066\n",
      "Epoch 496/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3338 - recall: 0.8590 - val_loss: 0.5003 - val_recall: 0.7790\n",
      "Epoch 497/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3305 - recall: 0.8596 - val_loss: 0.4832 - val_recall: 0.7182\n",
      "Epoch 498/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3304 - recall: 0.8596 - val_loss: 0.4285 - val_recall: 0.6630\n",
      "Epoch 499/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3308 - recall: 0.8529 - val_loss: 0.5126 - val_recall: 0.7680\n",
      "Epoch 500/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3318 - recall: 0.8674 - val_loss: 0.4129 - val_recall: 0.6354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16397e02bb0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, \n",
    "          epochs = 500, verbose = 1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.645   0.624     0.615       0.779\n",
       "1 0.597   0.699     0.521       0.702\n",
       "2 0.568   0.699     0.569       0.818\n",
       "3 0.543   0.726     0.525       0.818\n",
       "4 0.524   0.731     0.455       0.796"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "[[676 120]\n",
      " [ 81 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       796\n",
      "           1       0.51      0.60      0.55       204\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.70      0.73      0.71      1000\n",
      "weighted avg       0.81      0.80      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.005)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.6992 - recall: 0.5648 - val_loss: 0.6844 - val_recall: 0.6630\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6858 - recall: 0.6350 - val_loss: 0.6743 - val_recall: 0.7293\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6803 - recall: 0.5950 - val_loss: 0.6681 - val_recall: 0.7956\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6727 - recall: 0.6235 - val_loss: 0.6343 - val_recall: 0.7127\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6639 - recall: 0.6398 - val_loss: 0.6327 - val_recall: 0.7569\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6541 - recall: 0.6519 - val_loss: 0.6238 - val_recall: 0.7514\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6577 - recall: 0.6737 - val_loss: 0.6255 - val_recall: 0.7348\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6433 - recall: 0.7028 - val_loss: 0.5988 - val_recall: 0.7127\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6391 - recall: 0.6870 - val_loss: 0.5854 - val_recall: 0.6961\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6357 - recall: 0.6834 - val_loss: 0.5975 - val_recall: 0.7459\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6297 - recall: 0.6786 - val_loss: 0.5829 - val_recall: 0.7293\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6194 - recall: 0.6695 - val_loss: 0.5780 - val_recall: 0.7348\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6138 - recall: 0.6634 - val_loss: 0.5628 - val_recall: 0.7293\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6090 - recall: 0.6707 - val_loss: 0.5473 - val_recall: 0.7348\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6132 - recall: 0.6223 - val_loss: 0.5471 - val_recall: 0.7624\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6030 - recall: 0.6610 - val_loss: 0.5417 - val_recall: 0.7735\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5979 - recall: 0.6919 - val_loss: 0.5407 - val_recall: 0.7901\n",
      "Epoch 18/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5890 - recall: 0.6828 - val_loss: 0.5408 - val_recall: 0.7956\n",
      "Epoch 19/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5852 - recall: 0.6901 - val_loss: 0.5314 - val_recall: 0.7845\n",
      "Epoch 20/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5859 - recall: 0.6580 - val_loss: 0.5045 - val_recall: 0.7680\n",
      "Epoch 21/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5821 - recall: 0.6622 - val_loss: 0.5391 - val_recall: 0.8232\n",
      "Epoch 22/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5762 - recall: 0.6398 - val_loss: 0.5301 - val_recall: 0.8177\n",
      "Epoch 23/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5775 - recall: 0.6689 - val_loss: 0.5360 - val_recall: 0.8398\n",
      "Epoch 24/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5701 - recall: 0.6646 - val_loss: 0.5079 - val_recall: 0.8122\n",
      "Epoch 25/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5652 - recall: 0.6798 - val_loss: 0.4930 - val_recall: 0.8066\n",
      "Epoch 26/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5646 - recall: 0.6634 - val_loss: 0.5104 - val_recall: 0.8232\n",
      "Epoch 27/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5693 - recall: 0.6665 - val_loss: 0.4939 - val_recall: 0.8066\n",
      "Epoch 28/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5533 - recall: 0.6883 - val_loss: 0.4654 - val_recall: 0.7901\n",
      "Epoch 29/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5568 - recall: 0.7094 - val_loss: 0.4983 - val_recall: 0.8508\n",
      "Epoch 30/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5539 - recall: 0.7173 - val_loss: 0.4499 - val_recall: 0.7901\n",
      "Epoch 31/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5492 - recall: 0.7385 - val_loss: 0.4482 - val_recall: 0.8011\n",
      "Epoch 32/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5496 - recall: 0.7167 - val_loss: 0.4695 - val_recall: 0.8287\n",
      "Epoch 33/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5563 - recall: 0.7076 - val_loss: 0.4951 - val_recall: 0.8232\n",
      "Epoch 34/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5480 - recall: 0.7470 - val_loss: 0.4577 - val_recall: 0.8177\n",
      "Epoch 35/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5489 - recall: 0.7167 - val_loss: 0.4634 - val_recall: 0.8232\n",
      "Epoch 36/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5480 - recall: 0.7137 - val_loss: 0.4714 - val_recall: 0.8398\n",
      "Epoch 37/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5481 - recall: 0.7409 - val_loss: 0.5132 - val_recall: 0.8564\n",
      "Epoch 38/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5491 - recall: 0.7270 - val_loss: 0.4640 - val_recall: 0.8122\n",
      "Epoch 39/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5436 - recall: 0.7318 - val_loss: 0.4871 - val_recall: 0.8564\n",
      "Epoch 40/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5452 - recall: 0.7294 - val_loss: 0.4500 - val_recall: 0.8122\n",
      "Epoch 41/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5434 - recall: 0.7137 - val_loss: 0.4702 - val_recall: 0.8287\n",
      "Epoch 42/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5479 - recall: 0.7173 - val_loss: 0.4623 - val_recall: 0.8232\n",
      "Epoch 43/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5401 - recall: 0.7324 - val_loss: 0.4485 - val_recall: 0.8066\n",
      "Epoch 44/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5441 - recall: 0.7288 - val_loss: 0.4829 - val_recall: 0.8564\n",
      "Epoch 45/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5338 - recall: 0.7361 - val_loss: 0.4635 - val_recall: 0.8453\n",
      "Epoch 46/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5447 - recall: 0.7234 - val_loss: 0.4484 - val_recall: 0.8066\n",
      "Epoch 47/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5437 - recall: 0.7294 - val_loss: 0.4839 - val_recall: 0.8508\n",
      "Epoch 48/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5357 - recall: 0.7391 - val_loss: 0.4726 - val_recall: 0.8564\n",
      "Epoch 49/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5406 - recall: 0.7470 - val_loss: 0.4864 - val_recall: 0.8453\n",
      "Epoch 50/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5416 - recall: 0.7282 - val_loss: 0.4509 - val_recall: 0.8398\n",
      "Epoch 51/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5352 - recall: 0.7421 - val_loss: 0.4394 - val_recall: 0.7956\n",
      "Epoch 52/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5409 - recall: 0.7421 - val_loss: 0.4471 - val_recall: 0.7901\n",
      "Epoch 53/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5423 - recall: 0.7379 - val_loss: 0.4449 - val_recall: 0.8011\n",
      "Epoch 54/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5365 - recall: 0.7331 - val_loss: 0.4908 - val_recall: 0.8564\n",
      "Epoch 55/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5431 - recall: 0.7409 - val_loss: 0.4787 - val_recall: 0.8398\n",
      "Epoch 56/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5407 - recall: 0.7452 - val_loss: 0.5008 - val_recall: 0.8508\n",
      "Epoch 57/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5302 - recall: 0.7476 - val_loss: 0.4409 - val_recall: 0.8011\n",
      "Epoch 58/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5430 - recall: 0.7524 - val_loss: 0.4780 - val_recall: 0.8508\n",
      "Epoch 59/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5364 - recall: 0.7367 - val_loss: 0.4221 - val_recall: 0.8122\n",
      "Epoch 60/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5379 - recall: 0.7470 - val_loss: 0.4549 - val_recall: 0.8232\n",
      "Epoch 61/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5387 - recall: 0.7324 - val_loss: 0.4872 - val_recall: 0.8564\n",
      "Epoch 62/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5389 - recall: 0.7294 - val_loss: 0.4679 - val_recall: 0.8066\n",
      "Epoch 63/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5299 - recall: 0.7415 - val_loss: 0.4538 - val_recall: 0.8343\n",
      "Epoch 64/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5379 - recall: 0.7536 - val_loss: 0.4606 - val_recall: 0.8398\n",
      "Epoch 65/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5320 - recall: 0.7488 - val_loss: 0.4518 - val_recall: 0.8398\n",
      "Epoch 66/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5285 - recall: 0.7367 - val_loss: 0.4576 - val_recall: 0.8343\n",
      "Epoch 67/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5345 - recall: 0.7500 - val_loss: 0.4715 - val_recall: 0.8398\n",
      "Epoch 68/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5330 - recall: 0.7542 - val_loss: 0.4509 - val_recall: 0.8453\n",
      "Epoch 69/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5329 - recall: 0.7379 - val_loss: 0.4791 - val_recall: 0.8619\n",
      "Epoch 70/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5353 - recall: 0.7518 - val_loss: 0.4427 - val_recall: 0.8122\n",
      "Epoch 71/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5367 - recall: 0.7452 - val_loss: 0.4876 - val_recall: 0.8564\n",
      "Epoch 72/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5445 - recall: 0.7476 - val_loss: 0.4805 - val_recall: 0.8508\n",
      "Epoch 73/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5288 - recall: 0.7464 - val_loss: 0.4610 - val_recall: 0.8232\n",
      "Epoch 74/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5260 - recall: 0.7294 - val_loss: 0.4825 - val_recall: 0.8453\n",
      "Epoch 75/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5321 - recall: 0.7500 - val_loss: 0.4373 - val_recall: 0.8066\n",
      "Epoch 76/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5363 - recall: 0.7403 - val_loss: 0.4792 - val_recall: 0.8287\n",
      "Epoch 77/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5343 - recall: 0.7452 - val_loss: 0.4403 - val_recall: 0.8011\n",
      "Epoch 78/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5266 - recall: 0.7343 - val_loss: 0.4846 - val_recall: 0.8508\n",
      "Epoch 79/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5305 - recall: 0.7367 - val_loss: 0.4455 - val_recall: 0.8177\n",
      "Epoch 80/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5359 - recall: 0.7264 - val_loss: 0.4340 - val_recall: 0.8011\n",
      "Epoch 81/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5317 - recall: 0.7482 - val_loss: 0.4909 - val_recall: 0.8398\n",
      "Epoch 82/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5303 - recall: 0.7536 - val_loss: 0.4827 - val_recall: 0.8564\n",
      "Epoch 83/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5342 - recall: 0.7676 - val_loss: 0.4517 - val_recall: 0.8177\n",
      "Epoch 84/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5314 - recall: 0.7458 - val_loss: 0.4611 - val_recall: 0.8232\n",
      "Epoch 85/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5315 - recall: 0.7385 - val_loss: 0.4750 - val_recall: 0.8232\n",
      "Epoch 86/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5307 - recall: 0.7088 - val_loss: 0.4552 - val_recall: 0.8122\n",
      "Epoch 87/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5301 - recall: 0.7385 - val_loss: 0.4607 - val_recall: 0.8122\n",
      "Epoch 88/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5250 - recall: 0.7409 - val_loss: 0.4500 - val_recall: 0.8287\n",
      "Epoch 89/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5293 - recall: 0.7530 - val_loss: 0.4513 - val_recall: 0.8398\n",
      "Epoch 90/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5319 - recall: 0.7494 - val_loss: 0.4592 - val_recall: 0.8122\n",
      "Epoch 91/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5253 - recall: 0.7403 - val_loss: 0.4493 - val_recall: 0.8177\n",
      "Epoch 92/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5276 - recall: 0.7488 - val_loss: 0.4285 - val_recall: 0.8122\n",
      "Epoch 93/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5287 - recall: 0.7506 - val_loss: 0.4777 - val_recall: 0.8398\n",
      "Epoch 94/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5413 - recall: 0.7361 - val_loss: 0.4399 - val_recall: 0.8177\n",
      "Epoch 95/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5300 - recall: 0.7312 - val_loss: 0.4388 - val_recall: 0.8066\n",
      "Epoch 96/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5255 - recall: 0.7439 - val_loss: 0.4550 - val_recall: 0.8343\n",
      "Epoch 97/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5296 - recall: 0.7458 - val_loss: 0.4533 - val_recall: 0.8398\n",
      "Epoch 98/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5303 - recall: 0.7512 - val_loss: 0.4503 - val_recall: 0.8066\n",
      "Epoch 99/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5210 - recall: 0.7694 - val_loss: 0.4360 - val_recall: 0.8066\n",
      "Epoch 100/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5254 - recall: 0.7476 - val_loss: 0.4607 - val_recall: 0.8508\n",
      "Epoch 101/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5299 - recall: 0.7433 - val_loss: 0.4356 - val_recall: 0.8066\n",
      "Epoch 102/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5311 - recall: 0.7639 - val_loss: 0.4474 - val_recall: 0.8232\n",
      "Epoch 103/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5282 - recall: 0.7651 - val_loss: 0.4748 - val_recall: 0.8343\n",
      "Epoch 104/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5264 - recall: 0.7403 - val_loss: 0.4459 - val_recall: 0.8066\n",
      "Epoch 105/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5316 - recall: 0.7567 - val_loss: 0.4642 - val_recall: 0.8232\n",
      "Epoch 106/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5283 - recall: 0.7512 - val_loss: 0.4379 - val_recall: 0.8066\n",
      "Epoch 107/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5216 - recall: 0.7500 - val_loss: 0.4536 - val_recall: 0.8011\n",
      "Epoch 108/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5280 - recall: 0.7530 - val_loss: 0.4502 - val_recall: 0.8177\n",
      "Epoch 109/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5228 - recall: 0.7627 - val_loss: 0.4108 - val_recall: 0.7845\n",
      "Epoch 110/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5278 - recall: 0.7506 - val_loss: 0.4702 - val_recall: 0.8232\n",
      "Epoch 111/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5205 - recall: 0.7797 - val_loss: 0.4237 - val_recall: 0.7901\n",
      "Epoch 112/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5164 - recall: 0.7633 - val_loss: 0.4568 - val_recall: 0.8177\n",
      "Epoch 113/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5252 - recall: 0.7421 - val_loss: 0.4628 - val_recall: 0.8343\n",
      "Epoch 114/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5260 - recall: 0.7627 - val_loss: 0.4457 - val_recall: 0.8343\n",
      "Epoch 115/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5222 - recall: 0.7627 - val_loss: 0.4522 - val_recall: 0.8177\n",
      "Epoch 116/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5257 - recall: 0.7567 - val_loss: 0.4654 - val_recall: 0.8287\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5208 - recall: 0.7585 - val_loss: 0.4288 - val_recall: 0.8232\n",
      "Epoch 118/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5226 - recall: 0.7391 - val_loss: 0.4302 - val_recall: 0.7956\n",
      "Epoch 119/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5283 - recall: 0.7476 - val_loss: 0.4582 - val_recall: 0.8287\n",
      "Epoch 120/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5309 - recall: 0.7270 - val_loss: 0.4795 - val_recall: 0.8674\n",
      "Epoch 121/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5370 - recall: 0.7561 - val_loss: 0.4506 - val_recall: 0.8122\n",
      "Epoch 122/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5225 - recall: 0.7663 - val_loss: 0.4402 - val_recall: 0.8122\n",
      "Epoch 123/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5285 - recall: 0.7609 - val_loss: 0.4512 - val_recall: 0.8343\n",
      "Epoch 124/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5267 - recall: 0.7222 - val_loss: 0.4511 - val_recall: 0.8177\n",
      "Epoch 125/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5289 - recall: 0.7016 - val_loss: 0.4663 - val_recall: 0.8232\n",
      "Epoch 126/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5371 - recall: 0.7397 - val_loss: 0.4702 - val_recall: 0.8287\n",
      "Epoch 127/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5164 - recall: 0.7706 - val_loss: 0.4327 - val_recall: 0.8232\n",
      "Epoch 128/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5312 - recall: 0.7688 - val_loss: 0.4221 - val_recall: 0.8066\n",
      "Epoch 129/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5278 - recall: 0.7609 - val_loss: 0.4333 - val_recall: 0.8122\n",
      "Epoch 130/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5206 - recall: 0.7542 - val_loss: 0.4317 - val_recall: 0.8011\n",
      "Epoch 131/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5302 - recall: 0.7573 - val_loss: 0.4385 - val_recall: 0.8066\n",
      "Epoch 132/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5235 - recall: 0.7554 - val_loss: 0.4745 - val_recall: 0.8398\n",
      "Epoch 133/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5261 - recall: 0.7633 - val_loss: 0.4503 - val_recall: 0.8343\n",
      "Epoch 134/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7688 - val_loss: 0.4461 - val_recall: 0.8232\n",
      "Epoch 135/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5280 - recall: 0.7633 - val_loss: 0.4412 - val_recall: 0.8177\n",
      "Epoch 136/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5280 - recall: 0.7488 - val_loss: 0.4299 - val_recall: 0.7790\n",
      "Epoch 137/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5196 - recall: 0.7766 - val_loss: 0.4364 - val_recall: 0.8066\n",
      "Epoch 138/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5284 - recall: 0.7603 - val_loss: 0.4553 - val_recall: 0.8343\n",
      "Epoch 139/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5194 - recall: 0.7645 - val_loss: 0.4644 - val_recall: 0.8343\n",
      "Epoch 140/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5249 - recall: 0.7621 - val_loss: 0.4608 - val_recall: 0.8287\n",
      "Epoch 141/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5238 - recall: 0.7669 - val_loss: 0.4503 - val_recall: 0.8232\n",
      "Epoch 142/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5190 - recall: 0.7688 - val_loss: 0.4462 - val_recall: 0.8508\n",
      "Epoch 143/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5233 - recall: 0.7706 - val_loss: 0.4364 - val_recall: 0.8287\n",
      "Epoch 144/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.7585 - val_loss: 0.4557 - val_recall: 0.8343\n",
      "Epoch 145/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5263 - recall: 0.7627 - val_loss: 0.4448 - val_recall: 0.8232\n",
      "Epoch 146/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5235 - recall: 0.7700 - val_loss: 0.4664 - val_recall: 0.8453\n",
      "Epoch 147/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5294 - recall: 0.7639 - val_loss: 0.4431 - val_recall: 0.8122\n",
      "Epoch 148/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5228 - recall: 0.7736 - val_loss: 0.4630 - val_recall: 0.8398\n",
      "Epoch 149/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5272 - recall: 0.7676 - val_loss: 0.4622 - val_recall: 0.8177\n",
      "Epoch 150/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5196 - recall: 0.7760 - val_loss: 0.4477 - val_recall: 0.8177\n",
      "Epoch 151/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5200 - recall: 0.7778 - val_loss: 0.4549 - val_recall: 0.8343\n",
      "Epoch 152/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5241 - recall: 0.7627 - val_loss: 0.4368 - val_recall: 0.8232\n",
      "Epoch 153/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5250 - recall: 0.7645 - val_loss: 0.4507 - val_recall: 0.8508\n",
      "Epoch 154/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5228 - recall: 0.7791 - val_loss: 0.4542 - val_recall: 0.8177\n",
      "Epoch 155/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5243 - recall: 0.7748 - val_loss: 0.4600 - val_recall: 0.8398\n",
      "Epoch 156/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5170 - recall: 0.7706 - val_loss: 0.4406 - val_recall: 0.8232\n",
      "Epoch 157/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5149 - recall: 0.7797 - val_loss: 0.4269 - val_recall: 0.8177\n",
      "Epoch 158/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7791 - val_loss: 0.4509 - val_recall: 0.8232\n",
      "Epoch 159/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5175 - recall: 0.7754 - val_loss: 0.4235 - val_recall: 0.8122\n",
      "Epoch 160/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5205 - recall: 0.7730 - val_loss: 0.4566 - val_recall: 0.8453\n",
      "Epoch 161/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5194 - recall: 0.7597 - val_loss: 0.4422 - val_recall: 0.8177\n",
      "Epoch 162/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5314 - recall: 0.7536 - val_loss: 0.4386 - val_recall: 0.8177\n",
      "Epoch 163/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5207 - recall: 0.7730 - val_loss: 0.4528 - val_recall: 0.8232\n",
      "Epoch 164/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5134 - recall: 0.7918 - val_loss: 0.4147 - val_recall: 0.8066\n",
      "Epoch 165/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7694 - val_loss: 0.4273 - val_recall: 0.8011\n",
      "Epoch 166/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5246 - recall: 0.7591 - val_loss: 0.4738 - val_recall: 0.8398\n",
      "Epoch 167/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5243 - recall: 0.7633 - val_loss: 0.4636 - val_recall: 0.8564\n",
      "Epoch 168/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5205 - recall: 0.7839 - val_loss: 0.4841 - val_recall: 0.8729\n",
      "Epoch 169/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5299 - recall: 0.7797 - val_loss: 0.4770 - val_recall: 0.8564\n",
      "Epoch 170/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5211 - recall: 0.7760 - val_loss: 0.4316 - val_recall: 0.8232\n",
      "Epoch 171/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5198 - recall: 0.7718 - val_loss: 0.4653 - val_recall: 0.8508\n",
      "Epoch 172/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5158 - recall: 0.7742 - val_loss: 0.4528 - val_recall: 0.8564\n",
      "Epoch 173/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5186 - recall: 0.7900 - val_loss: 0.4420 - val_recall: 0.8398\n",
      "Epoch 174/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.7827 - val_loss: 0.4570 - val_recall: 0.8398\n",
      "Epoch 175/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5162 - recall: 0.7851 - val_loss: 0.4596 - val_recall: 0.8508\n",
      "Epoch 176/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5255 - recall: 0.7845 - val_loss: 0.4665 - val_recall: 0.8232\n",
      "Epoch 177/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5229 - recall: 0.7851 - val_loss: 0.4379 - val_recall: 0.8287\n",
      "Epoch 178/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5158 - recall: 0.7748 - val_loss: 0.4286 - val_recall: 0.8122\n",
      "Epoch 179/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5328 - recall: 0.7494 - val_loss: 0.4369 - val_recall: 0.8177\n",
      "Epoch 180/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5199 - recall: 0.7966 - val_loss: 0.4508 - val_recall: 0.8398\n",
      "Epoch 181/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.7785 - val_loss: 0.4273 - val_recall: 0.8122\n",
      "Epoch 182/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5289 - recall: 0.7785 - val_loss: 0.4435 - val_recall: 0.8343\n",
      "Epoch 183/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5159 - recall: 0.7791 - val_loss: 0.4381 - val_recall: 0.8177\n",
      "Epoch 184/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5130 - recall: 0.7706 - val_loss: 0.4712 - val_recall: 0.8674\n",
      "Epoch 185/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5166 - recall: 0.7839 - val_loss: 0.4803 - val_recall: 0.8674\n",
      "Epoch 186/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5210 - recall: 0.7936 - val_loss: 0.4675 - val_recall: 0.8343\n",
      "Epoch 187/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5196 - recall: 0.7948 - val_loss: 0.4611 - val_recall: 0.8232\n",
      "Epoch 188/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5277 - recall: 0.7766 - val_loss: 0.4378 - val_recall: 0.8011\n",
      "Epoch 189/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5170 - recall: 0.7403 - val_loss: 0.4205 - val_recall: 0.7569\n",
      "Epoch 190/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.6628 - val_loss: 0.4518 - val_recall: 0.7901\n",
      "Epoch 191/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5237 - recall: 0.6719 - val_loss: 0.4215 - val_recall: 0.7624\n",
      "Epoch 192/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.6622 - val_loss: 0.4451 - val_recall: 0.8011\n",
      "Epoch 193/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5143 - recall: 0.7669 - val_loss: 0.4422 - val_recall: 0.8177\n",
      "Epoch 194/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5276 - recall: 0.7694 - val_loss: 0.4293 - val_recall: 0.8066\n",
      "Epoch 195/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7748 - val_loss: 0.4540 - val_recall: 0.8287\n",
      "Epoch 196/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5282 - recall: 0.7875 - val_loss: 0.4436 - val_recall: 0.8177\n",
      "Epoch 197/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5221 - recall: 0.7730 - val_loss: 0.4522 - val_recall: 0.8177\n",
      "Epoch 198/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5181 - recall: 0.7881 - val_loss: 0.4589 - val_recall: 0.8343\n",
      "Epoch 199/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5191 - recall: 0.7766 - val_loss: 0.4389 - val_recall: 0.8066\n",
      "Epoch 200/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5189 - recall: 0.7839 - val_loss: 0.4341 - val_recall: 0.8066\n",
      "Epoch 201/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5234 - recall: 0.7827 - val_loss: 0.4508 - val_recall: 0.8177\n",
      "Epoch 202/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5207 - recall: 0.7676 - val_loss: 0.4537 - val_recall: 0.8177\n",
      "Epoch 203/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5264 - recall: 0.7863 - val_loss: 0.4625 - val_recall: 0.8343\n",
      "Epoch 204/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5154 - recall: 0.7742 - val_loss: 0.4490 - val_recall: 0.8177\n",
      "Epoch 205/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5234 - recall: 0.7676 - val_loss: 0.4430 - val_recall: 0.7790\n",
      "Epoch 206/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5124 - recall: 0.7833 - val_loss: 0.4671 - val_recall: 0.8287\n",
      "Epoch 207/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5110 - recall: 0.7797 - val_loss: 0.4393 - val_recall: 0.8453\n",
      "Epoch 208/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5211 - recall: 0.7791 - val_loss: 0.4428 - val_recall: 0.8122\n",
      "Epoch 209/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5169 - recall: 0.7984 - val_loss: 0.4284 - val_recall: 0.8011\n",
      "Epoch 210/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5172 - recall: 0.7797 - val_loss: 0.4588 - val_recall: 0.8564\n",
      "Epoch 211/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5231 - recall: 0.7718 - val_loss: 0.4555 - val_recall: 0.8343\n",
      "Epoch 212/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5133 - recall: 0.7978 - val_loss: 0.4344 - val_recall: 0.8122\n",
      "Epoch 213/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.7567 - val_loss: 0.4563 - val_recall: 0.8564\n",
      "Epoch 214/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5246 - recall: 0.7706 - val_loss: 0.4317 - val_recall: 0.8066\n",
      "Epoch 215/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7785 - val_loss: 0.4327 - val_recall: 0.8122\n",
      "Epoch 216/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.7597 - val_loss: 0.4593 - val_recall: 0.8398\n",
      "Epoch 217/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.7833 - val_loss: 0.4515 - val_recall: 0.8177\n",
      "Epoch 218/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5257 - recall: 0.7633 - val_loss: 0.4464 - val_recall: 0.8011\n",
      "Epoch 219/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5144 - recall: 0.7567 - val_loss: 0.4612 - val_recall: 0.8122\n",
      "Epoch 220/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5142 - recall: 0.7918 - val_loss: 0.4281 - val_recall: 0.8066\n",
      "Epoch 221/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7609 - val_loss: 0.4535 - val_recall: 0.8398\n",
      "Epoch 222/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5196 - recall: 0.7718 - val_loss: 0.4461 - val_recall: 0.8122\n",
      "Epoch 223/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5206 - recall: 0.7772 - val_loss: 0.4700 - val_recall: 0.8619\n",
      "Epoch 224/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5089 - recall: 0.7948 - val_loss: 0.4420 - val_recall: 0.8177\n",
      "Epoch 225/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5173 - recall: 0.7803 - val_loss: 0.4502 - val_recall: 0.8508\n",
      "Epoch 226/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5139 - recall: 0.7815 - val_loss: 0.4517 - val_recall: 0.8564\n",
      "Epoch 227/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5199 - recall: 0.7742 - val_loss: 0.4532 - val_recall: 0.8453\n",
      "Epoch 228/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5160 - recall: 0.7724 - val_loss: 0.4526 - val_recall: 0.8398\n",
      "Epoch 229/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5217 - recall: 0.7881 - val_loss: 0.4447 - val_recall: 0.8343\n",
      "Epoch 230/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5171 - recall: 0.7724 - val_loss: 0.4392 - val_recall: 0.8398\n",
      "Epoch 231/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5249 - recall: 0.7778 - val_loss: 0.4326 - val_recall: 0.8232\n",
      "Epoch 232/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.7651 - val_loss: 0.4732 - val_recall: 0.8674\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5131 - recall: 0.7942 - val_loss: 0.4274 - val_recall: 0.8177\n",
      "Epoch 234/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5211 - recall: 0.7627 - val_loss: 0.4345 - val_recall: 0.8343\n",
      "Epoch 235/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5265 - recall: 0.7657 - val_loss: 0.4557 - val_recall: 0.8398\n",
      "Epoch 236/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5247 - recall: 0.7821 - val_loss: 0.4694 - val_recall: 0.8508\n",
      "Epoch 237/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5162 - recall: 0.7815 - val_loss: 0.4485 - val_recall: 0.8453\n",
      "Epoch 238/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5190 - recall: 0.7803 - val_loss: 0.4544 - val_recall: 0.8564\n",
      "Epoch 239/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5174 - recall: 0.7845 - val_loss: 0.4395 - val_recall: 0.8343\n",
      "Epoch 240/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5216 - recall: 0.7797 - val_loss: 0.4382 - val_recall: 0.8232\n",
      "Epoch 241/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5237 - recall: 0.7912 - val_loss: 0.4876 - val_recall: 0.8619\n",
      "Epoch 242/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5134 - recall: 0.7912 - val_loss: 0.4399 - val_recall: 0.8232\n",
      "Epoch 243/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5212 - recall: 0.7742 - val_loss: 0.4536 - val_recall: 0.8453\n",
      "Epoch 244/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5242 - recall: 0.8057 - val_loss: 0.4339 - val_recall: 0.8177\n",
      "Epoch 245/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5172 - recall: 0.7669 - val_loss: 0.4387 - val_recall: 0.8122\n",
      "Epoch 246/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5243 - recall: 0.7821 - val_loss: 0.4522 - val_recall: 0.8453\n",
      "Epoch 247/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.7881 - val_loss: 0.4415 - val_recall: 0.8343\n",
      "Epoch 248/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5172 - recall: 0.7930 - val_loss: 0.4597 - val_recall: 0.8453\n",
      "Epoch 249/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5151 - recall: 0.7718 - val_loss: 0.4226 - val_recall: 0.8343\n",
      "Epoch 250/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5129 - recall: 0.7863 - val_loss: 0.4524 - val_recall: 0.8287\n",
      "Epoch 251/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5202 - recall: 0.7736 - val_loss: 0.4401 - val_recall: 0.8398\n",
      "Epoch 252/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.7766 - val_loss: 0.4354 - val_recall: 0.8287\n",
      "Epoch 253/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5145 - recall: 0.7736 - val_loss: 0.4476 - val_recall: 0.8398\n",
      "Epoch 254/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5174 - recall: 0.7942 - val_loss: 0.4570 - val_recall: 0.8232\n",
      "Epoch 255/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5171 - recall: 0.7766 - val_loss: 0.4322 - val_recall: 0.8398\n",
      "Epoch 256/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5241 - recall: 0.7536 - val_loss: 0.4780 - val_recall: 0.8508\n",
      "Epoch 257/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5184 - recall: 0.7942 - val_loss: 0.4412 - val_recall: 0.8508\n",
      "Epoch 258/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5157 - recall: 0.7857 - val_loss: 0.4426 - val_recall: 0.8398\n",
      "Epoch 259/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5208 - recall: 0.7688 - val_loss: 0.4729 - val_recall: 0.8508\n",
      "Epoch 260/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5234 - recall: 0.7524 - val_loss: 0.4568 - val_recall: 0.8453\n",
      "Epoch 261/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5163 - recall: 0.7542 - val_loss: 0.4500 - val_recall: 0.8398\n",
      "Epoch 262/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5206 - recall: 0.7918 - val_loss: 0.4405 - val_recall: 0.8398\n",
      "Epoch 263/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5186 - recall: 0.7815 - val_loss: 0.4355 - val_recall: 0.8453\n",
      "Epoch 264/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5151 - recall: 0.7778 - val_loss: 0.4488 - val_recall: 0.8564\n",
      "Epoch 265/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5192 - recall: 0.7821 - val_loss: 0.4466 - val_recall: 0.8453\n",
      "Epoch 266/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5176 - recall: 0.7936 - val_loss: 0.4354 - val_recall: 0.8177\n",
      "Epoch 267/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5086 - recall: 0.7361 - val_loss: 0.4506 - val_recall: 0.8508\n",
      "Epoch 268/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5166 - recall: 0.7821 - val_loss: 0.4540 - val_recall: 0.8287\n",
      "Epoch 269/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5158 - recall: 0.7657 - val_loss: 0.4464 - val_recall: 0.8398\n",
      "Epoch 270/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5117 - recall: 0.7791 - val_loss: 0.4258 - val_recall: 0.8398\n",
      "Epoch 271/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5229 - recall: 0.7924 - val_loss: 0.4457 - val_recall: 0.8343\n",
      "Epoch 272/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5155 - recall: 0.7966 - val_loss: 0.4508 - val_recall: 0.8398\n",
      "Epoch 273/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5161 - recall: 0.7869 - val_loss: 0.4329 - val_recall: 0.8066\n",
      "Epoch 274/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5297 - recall: 0.7712 - val_loss: 0.4810 - val_recall: 0.8674\n",
      "Epoch 275/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5146 - recall: 0.7772 - val_loss: 0.4357 - val_recall: 0.8343\n",
      "Epoch 276/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5174 - recall: 0.7615 - val_loss: 0.4410 - val_recall: 0.8508\n",
      "Epoch 277/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5061 - recall: 0.7906 - val_loss: 0.4522 - val_recall: 0.8564\n",
      "Epoch 278/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5142 - recall: 0.7736 - val_loss: 0.4426 - val_recall: 0.8508\n",
      "Epoch 279/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5174 - recall: 0.7815 - val_loss: 0.3996 - val_recall: 0.8287\n",
      "Epoch 280/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5151 - recall: 0.7561 - val_loss: 0.4361 - val_recall: 0.8619\n",
      "Epoch 281/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5203 - recall: 0.7803 - val_loss: 0.4551 - val_recall: 0.8619\n",
      "Epoch 282/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5139 - recall: 0.7845 - val_loss: 0.4273 - val_recall: 0.8508\n",
      "Epoch 283/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5087 - recall: 0.7645 - val_loss: 0.4814 - val_recall: 0.8729\n",
      "Epoch 284/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5156 - recall: 0.7930 - val_loss: 0.4482 - val_recall: 0.8619\n",
      "Epoch 285/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5110 - recall: 0.7797 - val_loss: 0.4382 - val_recall: 0.8508\n",
      "Epoch 286/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5210 - recall: 0.7906 - val_loss: 0.4653 - val_recall: 0.8674\n",
      "Epoch 287/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5102 - recall: 0.7797 - val_loss: 0.4352 - val_recall: 0.8287\n",
      "Epoch 288/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5123 - recall: 0.7791 - val_loss: 0.4531 - val_recall: 0.8508\n",
      "Epoch 289/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5183 - recall: 0.7881 - val_loss: 0.4355 - val_recall: 0.8453\n",
      "Epoch 290/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5198 - recall: 0.7851 - val_loss: 0.4140 - val_recall: 0.8011\n",
      "Epoch 291/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5143 - recall: 0.7900 - val_loss: 0.4435 - val_recall: 0.8398\n",
      "Epoch 292/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5161 - recall: 0.7996 - val_loss: 0.4378 - val_recall: 0.8177\n",
      "Epoch 293/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5135 - recall: 0.7712 - val_loss: 0.4499 - val_recall: 0.8232\n",
      "Epoch 294/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5141 - recall: 0.7845 - val_loss: 0.4425 - val_recall: 0.8343\n",
      "Epoch 295/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5060 - recall: 0.7954 - val_loss: 0.4555 - val_recall: 0.8619\n",
      "Epoch 296/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5132 - recall: 0.7669 - val_loss: 0.4406 - val_recall: 0.8287\n",
      "Epoch 297/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5190 - recall: 0.7028 - val_loss: 0.4465 - val_recall: 0.8343\n",
      "Epoch 298/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5107 - recall: 0.7754 - val_loss: 0.4366 - val_recall: 0.8564\n",
      "Epoch 299/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5104 - recall: 0.7343 - val_loss: 0.4341 - val_recall: 0.8343\n",
      "Epoch 300/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5178 - recall: 0.7857 - val_loss: 0.4252 - val_recall: 0.8177\n",
      "Epoch 301/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5163 - recall: 0.7948 - val_loss: 0.4616 - val_recall: 0.8674\n",
      "Epoch 302/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5210 - recall: 0.7839 - val_loss: 0.4317 - val_recall: 0.8508\n",
      "Epoch 303/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5236 - recall: 0.7833 - val_loss: 0.4494 - val_recall: 0.8674\n",
      "Epoch 304/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5232 - recall: 0.7766 - val_loss: 0.4344 - val_recall: 0.8453\n",
      "Epoch 305/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5098 - recall: 0.7851 - val_loss: 0.4353 - val_recall: 0.8398\n",
      "Epoch 306/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5159 - recall: 0.7930 - val_loss: 0.4240 - val_recall: 0.8287\n",
      "Epoch 307/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5155 - recall: 0.7778 - val_loss: 0.4399 - val_recall: 0.8508\n",
      "Epoch 308/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7857 - val_loss: 0.4446 - val_recall: 0.8398\n",
      "Epoch 309/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5253 - recall: 0.7706 - val_loss: 0.4508 - val_recall: 0.8343\n",
      "Epoch 310/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5145 - recall: 0.7815 - val_loss: 0.4696 - val_recall: 0.8674\n",
      "Epoch 311/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5178 - recall: 0.7857 - val_loss: 0.4530 - val_recall: 0.8508\n",
      "Epoch 312/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5094 - recall: 0.7851 - val_loss: 0.4561 - val_recall: 0.8453\n",
      "Epoch 313/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5115 - recall: 0.7833 - val_loss: 0.4482 - val_recall: 0.8343\n",
      "Epoch 314/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5246 - recall: 0.7863 - val_loss: 0.4650 - val_recall: 0.8398\n",
      "Epoch 315/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5150 - recall: 0.7760 - val_loss: 0.4624 - val_recall: 0.8619\n",
      "Epoch 316/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.7978 - val_loss: 0.4435 - val_recall: 0.8453\n",
      "Epoch 317/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5133 - recall: 0.7815 - val_loss: 0.4475 - val_recall: 0.8453\n",
      "Epoch 318/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5070 - recall: 0.8002 - val_loss: 0.4562 - val_recall: 0.8508\n",
      "Epoch 319/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5128 - recall: 0.7966 - val_loss: 0.4490 - val_recall: 0.8398\n",
      "Epoch 320/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5242 - recall: 0.7918 - val_loss: 0.4607 - val_recall: 0.8674\n",
      "Epoch 321/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7930 - val_loss: 0.4526 - val_recall: 0.8564\n",
      "Epoch 322/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5182 - recall: 0.7875 - val_loss: 0.4471 - val_recall: 0.8343\n",
      "Epoch 323/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7924 - val_loss: 0.4415 - val_recall: 0.8287\n",
      "Epoch 324/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5124 - recall: 0.7766 - val_loss: 0.4341 - val_recall: 0.8122\n",
      "Epoch 325/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5212 - recall: 0.7760 - val_loss: 0.4466 - val_recall: 0.8343\n",
      "Epoch 326/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5162 - recall: 0.7694 - val_loss: 0.4617 - val_recall: 0.8729\n",
      "Epoch 327/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5142 - recall: 0.7881 - val_loss: 0.4353 - val_recall: 0.8177\n",
      "Epoch 328/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.7785 - val_loss: 0.4374 - val_recall: 0.8398\n",
      "Epoch 329/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5225 - recall: 0.7827 - val_loss: 0.4185 - val_recall: 0.8287\n",
      "Epoch 330/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5154 - recall: 0.7839 - val_loss: 0.4310 - val_recall: 0.8232\n",
      "Epoch 331/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5175 - recall: 0.7645 - val_loss: 0.4659 - val_recall: 0.8619\n",
      "Epoch 332/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5157 - recall: 0.7663 - val_loss: 0.4700 - val_recall: 0.8619\n",
      "Epoch 333/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7869 - val_loss: 0.4376 - val_recall: 0.8232\n",
      "Epoch 334/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5202 - recall: 0.7954 - val_loss: 0.4669 - val_recall: 0.8674\n",
      "Epoch 335/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5142 - recall: 0.7809 - val_loss: 0.4574 - val_recall: 0.8508\n",
      "Epoch 336/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5105 - recall: 0.7893 - val_loss: 0.4577 - val_recall: 0.8398\n",
      "Epoch 337/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5164 - recall: 0.7791 - val_loss: 0.4612 - val_recall: 0.8508\n",
      "Epoch 338/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5098 - recall: 0.7906 - val_loss: 0.4681 - val_recall: 0.8564\n",
      "Epoch 339/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5114 - recall: 0.7730 - val_loss: 0.4433 - val_recall: 0.8508\n",
      "Epoch 340/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5051 - recall: 0.7833 - val_loss: 0.4577 - val_recall: 0.8619\n",
      "Epoch 341/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5188 - recall: 0.7863 - val_loss: 0.4805 - val_recall: 0.8674\n",
      "Epoch 342/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5136 - recall: 0.7942 - val_loss: 0.4369 - val_recall: 0.8564\n",
      "Epoch 343/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5144 - recall: 0.7918 - val_loss: 0.4385 - val_recall: 0.8564\n",
      "Epoch 344/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5233 - recall: 0.7700 - val_loss: 0.4347 - val_recall: 0.8564\n",
      "Epoch 345/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5095 - recall: 0.7760 - val_loss: 0.4487 - val_recall: 0.8619\n",
      "Epoch 346/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5169 - recall: 0.8087 - val_loss: 0.4222 - val_recall: 0.8177\n",
      "Epoch 347/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5228 - recall: 0.7906 - val_loss: 0.4592 - val_recall: 0.8453\n",
      "Epoch 348/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5134 - recall: 0.7893 - val_loss: 0.4416 - val_recall: 0.8453\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5183 - recall: 0.7912 - val_loss: 0.4476 - val_recall: 0.8564\n",
      "Epoch 350/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5182 - recall: 0.7718 - val_loss: 0.4568 - val_recall: 0.8398\n",
      "Epoch 351/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5059 - recall: 0.7815 - val_loss: 0.4624 - val_recall: 0.8619\n",
      "Epoch 352/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5181 - recall: 0.7924 - val_loss: 0.4309 - val_recall: 0.8287\n",
      "Epoch 353/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5189 - recall: 0.7821 - val_loss: 0.4605 - val_recall: 0.8564\n",
      "Epoch 354/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5080 - recall: 0.7748 - val_loss: 0.4379 - val_recall: 0.8343\n",
      "Epoch 355/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5074 - recall: 0.7766 - val_loss: 0.4356 - val_recall: 0.8453\n",
      "Epoch 356/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5219 - recall: 0.7869 - val_loss: 0.4519 - val_recall: 0.8453\n",
      "Epoch 357/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5107 - recall: 0.8069 - val_loss: 0.4147 - val_recall: 0.8177\n",
      "Epoch 358/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5114 - recall: 0.7875 - val_loss: 0.4571 - val_recall: 0.8674\n",
      "Epoch 359/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5162 - recall: 0.7930 - val_loss: 0.4504 - val_recall: 0.8564\n",
      "Epoch 360/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5156 - recall: 0.7827 - val_loss: 0.4369 - val_recall: 0.8232\n",
      "Epoch 361/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5136 - recall: 0.7772 - val_loss: 0.4385 - val_recall: 0.8398\n",
      "Epoch 362/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5131 - recall: 0.7942 - val_loss: 0.4328 - val_recall: 0.8508\n",
      "Epoch 363/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5184 - recall: 0.7863 - val_loss: 0.4656 - val_recall: 0.8508\n",
      "Epoch 364/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5170 - recall: 0.7869 - val_loss: 0.4259 - val_recall: 0.8398\n",
      "Epoch 365/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5193 - recall: 0.8039 - val_loss: 0.4320 - val_recall: 0.8232\n",
      "Epoch 366/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5197 - recall: 0.7627 - val_loss: 0.4539 - val_recall: 0.8508\n",
      "Epoch 367/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7990 - val_loss: 0.4361 - val_recall: 0.8232\n",
      "Epoch 368/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5160 - recall: 0.7712 - val_loss: 0.4360 - val_recall: 0.8232\n",
      "Epoch 369/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5248 - recall: 0.7724 - val_loss: 0.4389 - val_recall: 0.8343\n",
      "Epoch 370/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5209 - recall: 0.7984 - val_loss: 0.4724 - val_recall: 0.8674\n",
      "Epoch 371/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5128 - recall: 0.7791 - val_loss: 0.4497 - val_recall: 0.8453\n",
      "Epoch 372/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5088 - recall: 0.7966 - val_loss: 0.4198 - val_recall: 0.8287\n",
      "Epoch 373/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5170 - recall: 0.7924 - val_loss: 0.4566 - val_recall: 0.8508\n",
      "Epoch 374/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5188 - recall: 0.7936 - val_loss: 0.4253 - val_recall: 0.8343\n",
      "Epoch 375/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5148 - recall: 0.7912 - val_loss: 0.4449 - val_recall: 0.8453\n",
      "Epoch 376/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5074 - recall: 0.7906 - val_loss: 0.4536 - val_recall: 0.8453\n",
      "Epoch 377/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5236 - recall: 0.8027 - val_loss: 0.4480 - val_recall: 0.8343\n",
      "Epoch 378/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5129 - recall: 0.7996 - val_loss: 0.4225 - val_recall: 0.8398\n",
      "Epoch 379/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5121 - recall: 0.7990 - val_loss: 0.4428 - val_recall: 0.8177\n",
      "Epoch 380/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5092 - recall: 0.7881 - val_loss: 0.4187 - val_recall: 0.8122\n",
      "Epoch 381/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5181 - recall: 0.7930 - val_loss: 0.4424 - val_recall: 0.8453\n",
      "Epoch 382/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5222 - recall: 0.7857 - val_loss: 0.4566 - val_recall: 0.8398\n",
      "Epoch 383/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5093 - recall: 0.7984 - val_loss: 0.4333 - val_recall: 0.8177\n",
      "Epoch 384/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5167 - recall: 0.7833 - val_loss: 0.4211 - val_recall: 0.8232\n",
      "Epoch 385/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5084 - recall: 0.7893 - val_loss: 0.4304 - val_recall: 0.8232\n",
      "Epoch 386/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5159 - recall: 0.7960 - val_loss: 0.4468 - val_recall: 0.8564\n",
      "Epoch 387/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5113 - recall: 0.8057 - val_loss: 0.4458 - val_recall: 0.8232\n",
      "Epoch 388/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5122 - recall: 0.7857 - val_loss: 0.4559 - val_recall: 0.8398\n",
      "Epoch 389/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5185 - recall: 0.7621 - val_loss: 0.4465 - val_recall: 0.8453\n",
      "Epoch 390/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5172 - recall: 0.7754 - val_loss: 0.4503 - val_recall: 0.8398\n",
      "Epoch 391/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5091 - recall: 0.7215 - val_loss: 0.4706 - val_recall: 0.8619\n",
      "Epoch 392/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5169 - recall: 0.7536 - val_loss: 0.4551 - val_recall: 0.8564\n",
      "Epoch 393/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5120 - recall: 0.7712 - val_loss: 0.4329 - val_recall: 0.8011\n",
      "Epoch 394/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5133 - recall: 0.6749 - val_loss: 0.4239 - val_recall: 0.8066\n",
      "Epoch 395/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5085 - recall: 0.7088 - val_loss: 0.4527 - val_recall: 0.8729\n",
      "Epoch 396/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5173 - recall: 0.7936 - val_loss: 0.4543 - val_recall: 0.8508\n",
      "Epoch 397/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5089 - recall: 0.7912 - val_loss: 0.4287 - val_recall: 0.8453\n",
      "Epoch 398/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5076 - recall: 0.7875 - val_loss: 0.4271 - val_recall: 0.8398\n",
      "Epoch 399/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5144 - recall: 0.7803 - val_loss: 0.4346 - val_recall: 0.8619\n",
      "Epoch 400/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5150 - recall: 0.7942 - val_loss: 0.4307 - val_recall: 0.8619\n",
      "Epoch 401/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5140 - recall: 0.7906 - val_loss: 0.4571 - val_recall: 0.8674\n",
      "Epoch 402/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5163 - recall: 0.7960 - val_loss: 0.4977 - val_recall: 0.9061\n",
      "Epoch 403/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5161 - recall: 0.8105 - val_loss: 0.4521 - val_recall: 0.8508\n",
      "Epoch 404/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5102 - recall: 0.7845 - val_loss: 0.4495 - val_recall: 0.8674\n",
      "Epoch 405/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5129 - recall: 0.7742 - val_loss: 0.4453 - val_recall: 0.8674\n",
      "Epoch 406/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5128 - recall: 0.7984 - val_loss: 0.4574 - val_recall: 0.8729\n",
      "Epoch 407/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5097 - recall: 0.7797 - val_loss: 0.4470 - val_recall: 0.8564\n",
      "Epoch 408/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7797 - val_loss: 0.4635 - val_recall: 0.8785\n",
      "Epoch 409/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5180 - recall: 0.7760 - val_loss: 0.4213 - val_recall: 0.8398\n",
      "Epoch 410/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5170 - recall: 0.7839 - val_loss: 0.4570 - val_recall: 0.8564\n",
      "Epoch 411/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5099 - recall: 0.7748 - val_loss: 0.4258 - val_recall: 0.8619\n",
      "Epoch 412/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5102 - recall: 0.7857 - val_loss: 0.4370 - val_recall: 0.8508\n",
      "Epoch 413/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5151 - recall: 0.7785 - val_loss: 0.4665 - val_recall: 0.8674\n",
      "Epoch 414/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5187 - recall: 0.7797 - val_loss: 0.4506 - val_recall: 0.8398\n",
      "Epoch 415/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5074 - recall: 0.7936 - val_loss: 0.4275 - val_recall: 0.8232\n",
      "Epoch 416/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.7887 - val_loss: 0.4863 - val_recall: 0.8785\n",
      "Epoch 417/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5023 - recall: 0.8087 - val_loss: 0.4566 - val_recall: 0.8619\n",
      "Epoch 418/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5147 - recall: 0.7936 - val_loss: 0.4637 - val_recall: 0.8619\n",
      "Epoch 419/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5217 - recall: 0.8057 - val_loss: 0.4626 - val_recall: 0.8508\n",
      "Epoch 420/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5152 - recall: 0.7912 - val_loss: 0.4202 - val_recall: 0.8066\n",
      "Epoch 421/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5143 - recall: 0.7766 - val_loss: 0.4310 - val_recall: 0.8508\n",
      "Epoch 422/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5146 - recall: 0.7948 - val_loss: 0.4344 - val_recall: 0.8453\n",
      "Epoch 423/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5184 - recall: 0.8087 - val_loss: 0.4402 - val_recall: 0.8343\n",
      "Epoch 424/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5047 - recall: 0.8111 - val_loss: 0.4620 - val_recall: 0.8564\n",
      "Epoch 425/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5097 - recall: 0.7893 - val_loss: 0.4362 - val_recall: 0.8232\n",
      "Epoch 426/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5198 - recall: 0.7718 - val_loss: 0.4527 - val_recall: 0.7956\n",
      "Epoch 427/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5148 - recall: 0.6870 - val_loss: 0.4453 - val_recall: 0.8343\n",
      "Epoch 428/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5154 - recall: 0.7912 - val_loss: 0.4517 - val_recall: 0.8453\n",
      "Epoch 429/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5218 - recall: 0.7954 - val_loss: 0.4371 - val_recall: 0.8232\n",
      "Epoch 430/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5145 - recall: 0.7893 - val_loss: 0.4503 - val_recall: 0.8287\n",
      "Epoch 431/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5160 - recall: 0.6604 - val_loss: 0.4499 - val_recall: 0.8232\n",
      "Epoch 432/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5132 - recall: 0.6725 - val_loss: 0.4412 - val_recall: 0.8453\n",
      "Epoch 433/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5131 - recall: 0.7567 - val_loss: 0.4509 - val_recall: 0.7956\n",
      "Epoch 434/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5168 - recall: 0.6634 - val_loss: 0.4610 - val_recall: 0.8232\n",
      "Epoch 435/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5140 - recall: 0.6955 - val_loss: 0.4319 - val_recall: 0.8343\n",
      "Epoch 436/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5155 - recall: 0.7936 - val_loss: 0.4224 - val_recall: 0.8066\n",
      "Epoch 437/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5133 - recall: 0.7930 - val_loss: 0.4386 - val_recall: 0.8232\n",
      "Epoch 438/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5164 - recall: 0.7669 - val_loss: 0.4282 - val_recall: 0.8398\n",
      "Epoch 439/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.7924 - val_loss: 0.4337 - val_recall: 0.8508\n",
      "Epoch 440/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5078 - recall: 0.7966 - val_loss: 0.4281 - val_recall: 0.8232\n",
      "Epoch 441/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5063 - recall: 0.7924 - val_loss: 0.4348 - val_recall: 0.8674\n",
      "Epoch 442/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5081 - recall: 0.7887 - val_loss: 0.4449 - val_recall: 0.8564\n",
      "Epoch 443/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5181 - recall: 0.8075 - val_loss: 0.4356 - val_recall: 0.8674\n",
      "Epoch 444/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5175 - recall: 0.7918 - val_loss: 0.4321 - val_recall: 0.8398\n",
      "Epoch 445/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5064 - recall: 0.7863 - val_loss: 0.4364 - val_recall: 0.8564\n",
      "Epoch 446/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5067 - recall: 0.7797 - val_loss: 0.4392 - val_recall: 0.8729\n",
      "Epoch 447/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5178 - recall: 0.8002 - val_loss: 0.4457 - val_recall: 0.8729\n",
      "Epoch 448/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5154 - recall: 0.7960 - val_loss: 0.4508 - val_recall: 0.8785\n",
      "Epoch 449/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5158 - recall: 0.8002 - val_loss: 0.4451 - val_recall: 0.8619\n",
      "Epoch 450/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5094 - recall: 0.7930 - val_loss: 0.4497 - val_recall: 0.8785\n",
      "Epoch 451/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5134 - recall: 0.7972 - val_loss: 0.4447 - val_recall: 0.8619\n",
      "Epoch 452/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5071 - recall: 0.8099 - val_loss: 0.4182 - val_recall: 0.8398\n",
      "Epoch 453/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5158 - recall: 0.7948 - val_loss: 0.4566 - val_recall: 0.8729\n",
      "Epoch 454/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5152 - recall: 0.7954 - val_loss: 0.4501 - val_recall: 0.8729\n",
      "Epoch 455/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5103 - recall: 0.7900 - val_loss: 0.4346 - val_recall: 0.8619\n",
      "Epoch 456/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5154 - recall: 0.7900 - val_loss: 0.4602 - val_recall: 0.8729\n",
      "Epoch 457/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5123 - recall: 0.8087 - val_loss: 0.4720 - val_recall: 0.8895\n",
      "Epoch 458/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5096 - recall: 0.8057 - val_loss: 0.4411 - val_recall: 0.8785\n",
      "Epoch 459/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5181 - recall: 0.8008 - val_loss: 0.4356 - val_recall: 0.8729\n",
      "Epoch 460/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5145 - recall: 0.7942 - val_loss: 0.4356 - val_recall: 0.8785\n",
      "Epoch 461/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5118 - recall: 0.8015 - val_loss: 0.4614 - val_recall: 0.8895\n",
      "Epoch 462/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5174 - recall: 0.8075 - val_loss: 0.4433 - val_recall: 0.8453\n",
      "Epoch 463/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5119 - recall: 0.7857 - val_loss: 0.4758 - val_recall: 0.8840\n",
      "Epoch 464/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5130 - recall: 0.7954 - val_loss: 0.4353 - val_recall: 0.8564\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5201 - recall: 0.7785 - val_loss: 0.4569 - val_recall: 0.8674\n",
      "Epoch 466/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5151 - recall: 0.8008 - val_loss: 0.4620 - val_recall: 0.8619\n",
      "Epoch 467/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5119 - recall: 0.8021 - val_loss: 0.4398 - val_recall: 0.8453\n",
      "Epoch 468/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5186 - recall: 0.8002 - val_loss: 0.4596 - val_recall: 0.8674\n",
      "Epoch 469/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5111 - recall: 0.7948 - val_loss: 0.4368 - val_recall: 0.8508\n",
      "Epoch 470/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5125 - recall: 0.7803 - val_loss: 0.4317 - val_recall: 0.8398\n",
      "Epoch 471/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5092 - recall: 0.8093 - val_loss: 0.4443 - val_recall: 0.8619\n",
      "Epoch 472/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5102 - recall: 0.8027 - val_loss: 0.4475 - val_recall: 0.8785\n",
      "Epoch 473/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5149 - recall: 0.8081 - val_loss: 0.4733 - val_recall: 0.8840\n",
      "Epoch 474/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.8069 - val_loss: 0.4445 - val_recall: 0.8564\n",
      "Epoch 475/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5079 - recall: 0.8093 - val_loss: 0.4489 - val_recall: 0.8674\n",
      "Epoch 476/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5122 - recall: 0.7918 - val_loss: 0.4476 - val_recall: 0.8674\n",
      "Epoch 477/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5132 - recall: 0.7851 - val_loss: 0.4427 - val_recall: 0.8508\n",
      "Epoch 478/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5090 - recall: 0.7887 - val_loss: 0.4454 - val_recall: 0.8674\n",
      "Epoch 479/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5091 - recall: 0.8008 - val_loss: 0.4361 - val_recall: 0.8453\n",
      "Epoch 480/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5182 - recall: 0.8051 - val_loss: 0.4399 - val_recall: 0.8122\n",
      "Epoch 481/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5122 - recall: 0.7996 - val_loss: 0.4279 - val_recall: 0.8122\n",
      "Epoch 482/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5005 - recall: 0.7978 - val_loss: 0.4553 - val_recall: 0.8508\n",
      "Epoch 483/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5148 - recall: 0.7863 - val_loss: 0.4554 - val_recall: 0.8508\n",
      "Epoch 484/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5126 - recall: 0.8002 - val_loss: 0.4471 - val_recall: 0.8122\n",
      "Epoch 485/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5165 - recall: 0.8166 - val_loss: 0.4539 - val_recall: 0.8453\n",
      "Epoch 486/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5143 - recall: 0.8057 - val_loss: 0.4552 - val_recall: 0.8343\n",
      "Epoch 487/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5112 - recall: 0.7984 - val_loss: 0.4191 - val_recall: 0.8232\n",
      "Epoch 488/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5166 - recall: 0.7906 - val_loss: 0.4496 - val_recall: 0.8564\n",
      "Epoch 489/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5064 - recall: 0.7863 - val_loss: 0.4342 - val_recall: 0.8287\n",
      "Epoch 490/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5056 - recall: 0.8111 - val_loss: 0.4321 - val_recall: 0.8343\n",
      "Epoch 491/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5103 - recall: 0.7821 - val_loss: 0.4592 - val_recall: 0.8674\n",
      "Epoch 492/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5113 - recall: 0.7936 - val_loss: 0.4281 - val_recall: 0.8453\n",
      "Epoch 493/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5159 - recall: 0.7990 - val_loss: 0.4596 - val_recall: 0.8674\n",
      "Epoch 494/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5104 - recall: 0.7924 - val_loss: 0.4594 - val_recall: 0.8840\n",
      "Epoch 495/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5059 - recall: 0.8178 - val_loss: 0.4426 - val_recall: 0.8398\n",
      "Epoch 496/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5069 - recall: 0.8075 - val_loss: 0.4250 - val_recall: 0.8177\n",
      "Epoch 497/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5065 - recall: 0.8136 - val_loss: 0.4421 - val_recall: 0.8177\n",
      "Epoch 498/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5039 - recall: 0.8015 - val_loss: 0.4208 - val_recall: 0.8122\n",
      "Epoch 499/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5063 - recall: 0.8027 - val_loss: 0.4440 - val_recall: 0.8343\n",
      "Epoch 500/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5153 - recall: 0.8002 - val_loss: 0.4517 - val_recall: 0.8619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16392ac7af0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, \n",
    "          epochs = 500, verbose = 1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.699   0.565     0.684       0.663\n",
       "1 0.686   0.635     0.674       0.729\n",
       "2 0.680   0.595     0.668       0.796\n",
       "3 0.673   0.623     0.634       0.713\n",
       "4 0.664   0.640     0.633       0.757"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "[[570 226]\n",
      " [ 32 172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82       796\n",
      "           1       0.43      0.84      0.57       204\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.69      0.78      0.69      1000\n",
      "weighted avg       0.84      0.74      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Early Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the \"val_loss\" as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.001)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.6992 - recall: 0.5648 - val_loss: 0.6844 - val_recall: 0.6630\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6858 - recall: 0.6350 - val_loss: 0.6743 - val_recall: 0.7293\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6803 - recall: 0.5950 - val_loss: 0.6681 - val_recall: 0.7956\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6727 - recall: 0.6235 - val_loss: 0.6343 - val_recall: 0.7127\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6639 - recall: 0.6398 - val_loss: 0.6327 - val_recall: 0.7569\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6541 - recall: 0.6519 - val_loss: 0.6238 - val_recall: 0.7514\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6577 - recall: 0.6737 - val_loss: 0.6255 - val_recall: 0.7348\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6433 - recall: 0.7028 - val_loss: 0.5988 - val_recall: 0.7127\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6391 - recall: 0.6870 - val_loss: 0.5854 - val_recall: 0.6961\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6357 - recall: 0.6834 - val_loss: 0.5975 - val_recall: 0.7459\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6297 - recall: 0.6786 - val_loss: 0.5829 - val_recall: 0.7293\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6194 - recall: 0.6695 - val_loss: 0.5780 - val_recall: 0.7348\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6138 - recall: 0.6634 - val_loss: 0.5628 - val_recall: 0.7293\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6090 - recall: 0.6707 - val_loss: 0.5473 - val_recall: 0.7348\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6132 - recall: 0.6223 - val_loss: 0.5471 - val_recall: 0.7624\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6030 - recall: 0.6610 - val_loss: 0.5417 - val_recall: 0.7735\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5979 - recall: 0.6919 - val_loss: 0.5407 - val_recall: 0.7901\n",
      "Epoch 18/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5890 - recall: 0.6828 - val_loss: 0.5408 - val_recall: 0.7956\n",
      "Epoch 19/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5852 - recall: 0.6901 - val_loss: 0.5314 - val_recall: 0.7845\n",
      "Epoch 20/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5859 - recall: 0.6580 - val_loss: 0.5045 - val_recall: 0.7680\n",
      "Epoch 21/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5821 - recall: 0.6622 - val_loss: 0.5391 - val_recall: 0.8232\n",
      "Epoch 22/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5762 - recall: 0.6398 - val_loss: 0.5301 - val_recall: 0.8177\n",
      "Epoch 23/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5775 - recall: 0.6689 - val_loss: 0.5360 - val_recall: 0.8398\n",
      "Epoch 24/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5701 - recall: 0.6646 - val_loss: 0.5079 - val_recall: 0.8122\n",
      "Epoch 25/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5652 - recall: 0.6798 - val_loss: 0.4930 - val_recall: 0.8066\n",
      "Epoch 26/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5646 - recall: 0.6634 - val_loss: 0.5104 - val_recall: 0.8232\n",
      "Epoch 27/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5693 - recall: 0.6665 - val_loss: 0.4939 - val_recall: 0.8066\n",
      "Epoch 28/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5533 - recall: 0.6883 - val_loss: 0.4654 - val_recall: 0.7901\n",
      "Epoch 29/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5568 - recall: 0.7094 - val_loss: 0.4983 - val_recall: 0.8508\n",
      "Epoch 30/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5539 - recall: 0.7173 - val_loss: 0.4499 - val_recall: 0.7901\n",
      "Epoch 31/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5492 - recall: 0.7385 - val_loss: 0.4482 - val_recall: 0.8011\n",
      "Epoch 32/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5496 - recall: 0.7167 - val_loss: 0.4695 - val_recall: 0.8287\n",
      "Epoch 33/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5563 - recall: 0.7076 - val_loss: 0.4951 - val_recall: 0.8232\n",
      "Epoch 34/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5480 - recall: 0.7470 - val_loss: 0.4577 - val_recall: 0.8177\n",
      "Epoch 35/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5489 - recall: 0.7167 - val_loss: 0.4634 - val_recall: 0.8232\n",
      "Epoch 36/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5480 - recall: 0.7137 - val_loss: 0.4714 - val_recall: 0.8398\n",
      "Epoch 37/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5481 - recall: 0.7409 - val_loss: 0.5132 - val_recall: 0.8564\n",
      "Epoch 38/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5491 - recall: 0.7270 - val_loss: 0.4640 - val_recall: 0.8122\n",
      "Epoch 39/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5436 - recall: 0.7318 - val_loss: 0.4871 - val_recall: 0.8564\n",
      "Epoch 40/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5452 - recall: 0.7294 - val_loss: 0.4500 - val_recall: 0.8122\n",
      "Epoch 41/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5434 - recall: 0.7137 - val_loss: 0.4702 - val_recall: 0.8287\n",
      "Epoch 42/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5479 - recall: 0.7173 - val_loss: 0.4623 - val_recall: 0.8232\n",
      "Epoch 43/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5401 - recall: 0.7324 - val_loss: 0.4485 - val_recall: 0.8066\n",
      "Epoch 44/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5441 - recall: 0.7288 - val_loss: 0.4829 - val_recall: 0.8564\n",
      "Epoch 45/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5338 - recall: 0.7361 - val_loss: 0.4635 - val_recall: 0.8453\n",
      "Epoch 46/500\n",
      "248/254 [============================>.] - ETA: 0s - loss: 0.5439 - recall: 0.7228Restoring model weights from the end of the best epoch: 31.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5447 - recall: 0.7234 - val_loss: 0.4484 - val_recall: 0.8066\n",
      "Epoch 46: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1639af723a0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, \n",
    "          epochs = 500, verbose = 1, callbacks=[early_stop], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.699   0.565     0.684       0.663\n",
       "1 0.686   0.635     0.674       0.729\n",
       "2 0.680   0.595     0.668       0.796\n",
       "3 0.673   0.623     0.634       0.713\n",
       "4 0.664   0.640     0.633       0.757"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "[[610 186]\n",
      " [ 54 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       796\n",
      "           1       0.45      0.74      0.56       204\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.68      0.75      0.70      1000\n",
      "weighted avg       0.82      0.76      0.78      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the \"val_recall\" as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "seed=101\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Adam(lr = 0.005)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_recall\", mode = \"max\", verbose = 1, patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "254/254 [==============================] - 2s 3ms/step - loss: 0.6992 - recall: 0.5648 - val_loss: 0.6844 - val_recall: 0.6630\n",
      "Epoch 2/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6858 - recall: 0.6350 - val_loss: 0.6743 - val_recall: 0.7293\n",
      "Epoch 3/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6803 - recall: 0.5950 - val_loss: 0.6681 - val_recall: 0.7956\n",
      "Epoch 4/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6727 - recall: 0.6235 - val_loss: 0.6343 - val_recall: 0.7127\n",
      "Epoch 5/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6639 - recall: 0.6398 - val_loss: 0.6327 - val_recall: 0.7569\n",
      "Epoch 6/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6541 - recall: 0.6519 - val_loss: 0.6238 - val_recall: 0.7514\n",
      "Epoch 7/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6577 - recall: 0.6737 - val_loss: 0.6255 - val_recall: 0.7348\n",
      "Epoch 8/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6433 - recall: 0.7028 - val_loss: 0.5988 - val_recall: 0.7127\n",
      "Epoch 9/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6391 - recall: 0.6870 - val_loss: 0.5854 - val_recall: 0.6961\n",
      "Epoch 10/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6357 - recall: 0.6834 - val_loss: 0.5975 - val_recall: 0.7459\n",
      "Epoch 11/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6297 - recall: 0.6786 - val_loss: 0.5829 - val_recall: 0.7293\n",
      "Epoch 12/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6194 - recall: 0.6695 - val_loss: 0.5780 - val_recall: 0.7348\n",
      "Epoch 13/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6138 - recall: 0.6634 - val_loss: 0.5628 - val_recall: 0.7293\n",
      "Epoch 14/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6090 - recall: 0.6707 - val_loss: 0.5473 - val_recall: 0.7348\n",
      "Epoch 15/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6132 - recall: 0.6223 - val_loss: 0.5471 - val_recall: 0.7624\n",
      "Epoch 16/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.6030 - recall: 0.6610 - val_loss: 0.5417 - val_recall: 0.7735\n",
      "Epoch 17/500\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5979 - recall: 0.6919 - val_loss: 0.5407 - val_recall: 0.7901\n",
      "Epoch 18/500\n",
      "246/254 [============================>.] - ETA: 0s - loss: 0.5902 - recall: 0.6836Restoring model weights from the end of the best epoch: 3.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5890 - recall: 0.6828 - val_loss: 0.5408 - val_recall: 0.7956\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163b07f8340>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_split = 0.1, batch_size = 32, \n",
    "          epochs = 500, verbose = 1, callbacks=[early_stop], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  recall  val_loss  val_recall\n",
       "0 0.699   0.565     0.684       0.663\n",
       "1 0.686   0.635     0.674       0.729\n",
       "2 0.680   0.595     0.668       0.796\n",
       "3 0.673   0.623     0.634       0.713\n",
       "4 0.664   0.640     0.633       0.757"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "[[469 327]\n",
      " [ 62 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.59      0.71       796\n",
      "           1       0.30      0.70      0.42       204\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.59      0.64      0.56      1000\n",
      "weighted avg       0.76      0.61      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer, learn_rate):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 36, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 18, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 9, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer(learn_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = KerasClassifier(build_fn = build_classifier, validation_split = 0.1, epochs = 200)\n",
    "\n",
    "parameters = {'batch_size': [32, 64],\n",
    "              'optimizer': [Adam, RMSprop, Adadelta, Nadam],\n",
    "              'learn_rate': [0.001, 0.003, 0.005]}\n",
    "\n",
    "grid_model = GridSearchCV(estimator = classifier_model,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 3,\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.fit(X_train, y_train, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid_model.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"params\"]].sort_values(by=\"rank_test_score\")\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model\n",
    "\n",
    "- Plot the model history to observe the changing of metrics\n",
    "- Make prediction to see \"confusion matrix\" and \"classification report\"\n",
    "- Check ROC (Receiver Operating Curve) and AUC (Area Under Curve) for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = grid_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model and Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler, open(\"scaler_churn\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(36, activation = \"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(18, activation = \"relu\"))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "opt = Nadam(learning_rate=0.003)\n",
    "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = X_train, y = y_train, validation_data = (X_test, y_test), batch_size = 32, epochs = 1000, verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"loss : \", loss)\n",
    "print(\"accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "#y_pred = model.predict_classes(X_test) for tf 2.5.0\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_churn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq10ovAX6daY"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_customer = df.drop('Exited', axis = 1).iloc[0:1, :]\n",
    "single_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_customer = scaler_cancer.transform(single_customer)\n",
    "single_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_churn.predict(single_customer) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKBWWuNpSuP7DHsa+Zpo3l",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
